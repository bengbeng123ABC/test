{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import  DecisionTreeClassifier,export_graphviz\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\2675975050.py:1: DtypeWarning: Columns (48,51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"train.csv\")\n",
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\2675975050.py:3: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  data1.info(verbose=True,null_counts=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23432 entries, 0 to 23431\n",
      "Data columns (total 657 columns):\n",
      " #    Column                 Non-Null Count  Dtype  \n",
      "---   ------                 --------------  -----  \n",
      " 0    pax_name               23432 non-null  object \n",
      " 1    pax_passport           23432 non-null  object \n",
      " 2    seg_route_from         23432 non-null  object \n",
      " 3    seg_route_to           23432 non-null  object \n",
      " 4    seg_flight             23432 non-null  object \n",
      " 5    seg_cabin              23431 non-null  object \n",
      " 6    seg_dep_time           23432 non-null  object \n",
      " 7    pax_fcny               23398 non-null  float64\n",
      " 8    pax_tax                23342 non-null  float64\n",
      " 9    emd_lable              7202 non-null   float64\n",
      " 10   emd_lable2             1475 non-null   float64\n",
      " 11   gender                 23432 non-null  object \n",
      " 12   age                    23432 non-null  object \n",
      " 13   birth_date             23432 non-null  object \n",
      " 14   residence_country      23432 non-null  object \n",
      " 15   nation_name            23432 non-null  object \n",
      " 16   city_name              23428 non-null  object \n",
      " 17   province_name          23432 non-null  object \n",
      " 18   marital_stat           23432 non-null  object \n",
      " 19   ffp_nbr                4411 non-null   float64\n",
      " 20   member_level           23432 non-null  object \n",
      " 21   often_city             0 non-null      float64\n",
      " 22   enroll_chnl            23432 non-null  object \n",
      " 23   cabin_hf_cnt_m3        17 non-null     float64\n",
      " 24   cabin_hf_cnt_m6        24 non-null     float64\n",
      " 25   cabin_hf_cnt_y1        39 non-null     float64\n",
      " 26   cabin_hf_cnt_y2        126 non-null    float64\n",
      " 27   cabin_hf_cnt_y3        171 non-null    float64\n",
      " 28   cabin_f_cnt_m3         2 non-null      float64\n",
      " 29   cabin_f_cnt_m6         11 non-null     float64\n",
      " 30   cabin_f_cnt_y1         56 non-null     float64\n",
      " 31   cabin_f_cnt_y2         172 non-null    float64\n",
      " 32   cabin_f_cnt_y3         213 non-null    float64\n",
      " 33   cabin_hy_cnt_m3        239 non-null    float64\n",
      " 34   cabin_hy_cnt_m6        466 non-null    float64\n",
      " 35   cabin_hy_cnt_y1        975 non-null    float64\n",
      " 36   cabin_hy_cnt_y2        2488 non-null   float64\n",
      " 37   cabin_hy_cnt_y3        3480 non-null   float64\n",
      " 38   cabin_y_cnt_m3         635 non-null    float64\n",
      " 39   cabin_y_cnt_m6         1043 non-null   float64\n",
      " 40   cabin_y_cnt_y1         2206 non-null   float64\n",
      " 41   cabin_y_cnt_y2         5963 non-null   float64\n",
      " 42   cabin_y_cnt_y3         7336 non-null   float64\n",
      " 43   cabin_c_cnt_m3         175 non-null    float64\n",
      " 44   cabin_c_cnt_m6         299 non-null    float64\n",
      " 45   cabin_c_cnt_y1         560 non-null    float64\n",
      " 46   cabin_c_cnt_y2         1106 non-null   float64\n",
      " 47   cabin_c_cnt_y3         1327 non-null   float64\n",
      " 48   pref_aircraft_m3_1     22434 non-null  object \n",
      " 49   pref_aircraft_m3_2     23432 non-null  object \n",
      " 50   pref_aircraft_m3_3     23432 non-null  object \n",
      " 51   pref_aircraft_m3_4     22420 non-null  object \n",
      " 52   pref_aircraft_m3_5     22419 non-null  object \n",
      " 53   pref_aircraft_m6_1     23432 non-null  object \n",
      " 54   pref_aircraft_m6_2     23432 non-null  object \n",
      " 55   pref_aircraft_m6_3     23432 non-null  object \n",
      " 56   pref_aircraft_m6_4     23432 non-null  object \n",
      " 57   pref_aircraft_m6_5     23432 non-null  object \n",
      " 58   pref_aircraft_y1_1     23432 non-null  object \n",
      " 59   pref_aircraft_y1_2     23432 non-null  object \n",
      " 60   pref_aircraft_y1_3     23432 non-null  object \n",
      " 61   pref_aircraft_y1_4     23432 non-null  object \n",
      " 62   pref_aircraft_y1_5     23432 non-null  object \n",
      " 63   pref_aircraft_y2_1     23432 non-null  object \n",
      " 64   pref_aircraft_y2_2     23432 non-null  object \n",
      " 65   pref_aircraft_y2_3     23432 non-null  object \n",
      " 66   pref_aircraft_y2_4     23432 non-null  object \n",
      " 67   pref_aircraft_y2_5     23432 non-null  object \n",
      " 68   pref_aircraft_y3_1     23432 non-null  object \n",
      " 69   pref_aircraft_y3_2     23432 non-null  object \n",
      " 70   pref_aircraft_y3_3     23432 non-null  object \n",
      " 71   pref_aircraft_y3_4     23432 non-null  object \n",
      " 72   pref_aircraft_y3_5     23432 non-null  object \n",
      " 73   seat_window_cnt_m3     380 non-null    float64\n",
      " 74   seat_window_cnt_m6     631 non-null    float64\n",
      " 75   seat_window_cnt_y1     1349 non-null   float64\n",
      " 76   seat_window_cnt_y2     3918 non-null   float64\n",
      " 77   seat_window_cnt_y3     5045 non-null   float64\n",
      " 78   seat_walkway_cnt_m3    590 non-null    float64\n",
      " 79   seat_walkway_cnt_m6    1019 non-null   float64\n",
      " 80   seat_walkway_cnt_y1    2200 non-null   float64\n",
      " 81   seat_walkway_cnt_y2    5739 non-null   float64\n",
      " 82   seat_walkway_cnt_y3    7313 non-null   float64\n",
      " 83   seat_middle_cnt_m3     240 non-null    float64\n",
      " 84   seat_middle_cnt_m6     485 non-null    float64\n",
      " 85   seat_middle_cnt_y1     1222 non-null   float64\n",
      " 86   seat_middle_cnt_y2     3653 non-null   float64\n",
      " 87   seat_middle_cnt_y3     4850 non-null   float64\n",
      " 88   seat_safe_cnt_m3       0 non-null      float64\n",
      " 89   seat_safe_cnt_m6       0 non-null      float64\n",
      " 90   seat_safe_cnt_y1       0 non-null      float64\n",
      " 91   seat_safe_cnt_y2       0 non-null      float64\n",
      " 92   seat_safe_cnt_y3       0 non-null      float64\n",
      " 93   prebuy_d_cnt_m3_d3     96 non-null     float64\n",
      " 94   prebuy_d_cnt_m3_d7     70 non-null     float64\n",
      " 95   prebuy_d_cnt_m3_d14    73 non-null     float64\n",
      " 96   prebuy_d_cnt_m3_d30    63 non-null     float64\n",
      " 97   prebuy_d_cnt_m3_d99    111 non-null    float64\n",
      " 98   prebuy_d_cnt_m6_d3     167 non-null    float64\n",
      " 99   prebuy_d_cnt_m6_d7     124 non-null    float64\n",
      " 100  prebuy_d_cnt_m6_d14    137 non-null    float64\n",
      " 101  prebuy_d_cnt_m6_d30    102 non-null    float64\n",
      " 102  prebuy_d_cnt_m6_d99    221 non-null    float64\n",
      " 103  prebuy_d_cnt_y1_d3     300 non-null    float64\n",
      " 104  prebuy_d_cnt_y1_d7     222 non-null    float64\n",
      " 105  prebuy_d_cnt_y1_d14    254 non-null    float64\n",
      " 106  prebuy_d_cnt_y1_d30    282 non-null    float64\n",
      " 107  prebuy_d_cnt_y1_d99    551 non-null    float64\n",
      " 108  prebuy_d_cnt_y2_d3     589 non-null    float64\n",
      " 109  prebuy_d_cnt_y2_d7     470 non-null    float64\n",
      " 110  prebuy_d_cnt_y2_d14    572 non-null    float64\n",
      " 111  prebuy_d_cnt_y2_d30    723 non-null    float64\n",
      " 112  prebuy_d_cnt_y2_d99    1553 non-null   float64\n",
      " 113  prebuy_d_cnt_y3_d3     785 non-null    float64\n",
      " 114  prebuy_d_cnt_y3_d7     650 non-null    float64\n",
      " 115  prebuy_d_cnt_y3_d14    805 non-null    float64\n",
      " 116  prebuy_d_cnt_y3_d30    1032 non-null   float64\n",
      " 117  prebuy_d_cnt_y3_d99    1903 non-null   float64\n",
      " 118  prebuy_i_cnt_m3_d3     51 non-null     float64\n",
      " 119  prebuy_i_cnt_m3_d7     68 non-null     float64\n",
      " 120  prebuy_i_cnt_m3_d14    108 non-null    float64\n",
      " 121  prebuy_i_cnt_m3_d30    163 non-null    float64\n",
      " 122  prebuy_i_cnt_m3_d99    579 non-null    float64\n",
      " 123  prebuy_i_cnt_m6_d3     111 non-null    float64\n",
      " 124  prebuy_i_cnt_m6_d7     129 non-null    float64\n",
      " 125  prebuy_i_cnt_m6_d14    222 non-null    float64\n",
      " 126  prebuy_i_cnt_m6_d30    355 non-null    float64\n",
      " 127  prebuy_i_cnt_m6_d99    965 non-null    float64\n",
      " 128  prebuy_i_cnt_y1_d3     319 non-null    float64\n",
      " 129  prebuy_i_cnt_y1_d7     290 non-null    float64\n",
      " 130  prebuy_i_cnt_y1_d14    531 non-null    float64\n",
      " 131  prebuy_i_cnt_y1_d30    736 non-null    float64\n",
      " 132  prebuy_i_cnt_y1_d99    2326 non-null   float64\n",
      " 133  prebuy_i_cnt_y2_d3     941 non-null    float64\n",
      " 134  prebuy_i_cnt_y2_d7     894 non-null    float64\n",
      " 135  prebuy_i_cnt_y2_d14    1264 non-null   float64\n",
      " 136  prebuy_i_cnt_y2_d30    2109 non-null   float64\n",
      " 137  prebuy_i_cnt_y2_d99    6276 non-null   float64\n",
      " 138  prebuy_i_cnt_y3_d3     1405 non-null   float64\n",
      " 139  prebuy_i_cnt_y3_d7     1325 non-null   float64\n",
      " 140  prebuy_i_cnt_y3_d14    1873 non-null   float64\n",
      " 141  prebuy_i_cnt_y3_d30    3102 non-null   float64\n",
      " 142  prebuy_i_cnt_y3_d99    7766 non-null   float64\n",
      " 143  pref_orig_m3_1         23432 non-null  object \n",
      " 144  pref_orig_m3_2         23432 non-null  object \n",
      " 145  pref_orig_m3_3         23432 non-null  object \n",
      " 146  pref_orig_m3_4         23432 non-null  object \n",
      " 147  pref_orig_m3_5         23432 non-null  object \n",
      " 148  pref_orig_m6_1         23432 non-null  object \n",
      " 149  pref_orig_m6_2         23432 non-null  object \n",
      " 150  pref_orig_m6_3         23432 non-null  object \n",
      " 151  pref_orig_m6_4         23432 non-null  object \n",
      " 152  pref_orig_m6_5         23432 non-null  object \n",
      " 153  pref_orig_y1_1         23432 non-null  object \n",
      " 154  pref_orig_y1_2         23432 non-null  object \n",
      " 155  pref_orig_y1_3         23432 non-null  object \n",
      " 156  pref_orig_y1_4         23432 non-null  object \n",
      " 157  pref_orig_y1_5         23432 non-null  object \n",
      " 158  pref_orig_y2_1         23432 non-null  object \n",
      " 159  pref_orig_y2_2         23432 non-null  object \n",
      " 160  pref_orig_y2_3         23432 non-null  object \n",
      " 161  pref_orig_y2_4         23432 non-null  object \n",
      " 162  pref_orig_y2_5         23432 non-null  object \n",
      " 163  pref_orig_y3_1         23432 non-null  object \n",
      " 164  pref_orig_y3_2         23432 non-null  object \n",
      " 165  pref_orig_y3_3         23432 non-null  object \n",
      " 166  pref_orig_y3_4         23432 non-null  object \n",
      " 167  pref_orig_y3_5         23432 non-null  object \n",
      " 168  pref_line_m3_1         23432 non-null  object \n",
      " 169  pref_line_m3_2         23432 non-null  object \n",
      " 170  pref_line_m3_3         23432 non-null  object \n",
      " 171  pref_line_m3_4         23432 non-null  object \n",
      " 172  pref_line_m3_5         23432 non-null  object \n",
      " 173  pref_line_m6_1         23432 non-null  object \n",
      " 174  pref_line_m6_2         23432 non-null  object \n",
      " 175  pref_line_m6_3         23432 non-null  object \n",
      " 176  pref_line_m6_4         23432 non-null  object \n",
      " 177  pref_line_m6_5         23432 non-null  object \n",
      " 178  pref_line_y1_1         23432 non-null  object \n",
      " 179  pref_line_y1_2         23432 non-null  object \n",
      " 180  pref_line_y1_3         23432 non-null  object \n",
      " 181  pref_line_y1_4         23432 non-null  object \n",
      " 182  pref_line_y1_5         23432 non-null  object \n",
      " 183  pref_line_y2_1         23432 non-null  object \n",
      " 184  pref_line_y2_2         23432 non-null  object \n",
      " 185  pref_line_y2_3         23432 non-null  object \n",
      " 186  pref_line_y2_4         23432 non-null  object \n",
      " 187  pref_line_y2_5         23432 non-null  object \n",
      " 188  pref_line_y3_1         23432 non-null  object \n",
      " 189  pref_line_y3_2         23432 non-null  object \n",
      " 190  pref_line_y3_3         23432 non-null  object \n",
      " 191  pref_line_y3_4         23432 non-null  object \n",
      " 192  pref_line_y3_5         23432 non-null  object \n",
      " 193  pref_city_m3_1         23432 non-null  object \n",
      " 194  pref_city_m3_2         23432 non-null  object \n",
      " 195  pref_city_m3_3         23432 non-null  object \n",
      " 196  pref_city_m3_4         23432 non-null  object \n",
      " 197  pref_city_m3_5         23432 non-null  object \n",
      " 198  pref_city_m6_1         23432 non-null  object \n",
      " 199  pref_city_m6_2         23432 non-null  object \n",
      " 200  pref_city_m6_3         23432 non-null  object \n",
      " 201  pref_city_m6_4         23432 non-null  object \n",
      " 202  pref_city_m6_5         23432 non-null  object \n",
      " 203  pref_city_y1_1         23432 non-null  object \n",
      " 204  pref_city_y1_2         23432 non-null  object \n",
      " 205  pref_city_y1_3         23432 non-null  object \n",
      " 206  pref_city_y1_4         23432 non-null  object \n",
      " 207  pref_city_y1_5         23432 non-null  object \n",
      " 208  pref_city_y2_1         23432 non-null  object \n",
      " 209  pref_city_y2_2         23432 non-null  object \n",
      " 210  pref_city_y2_3         23432 non-null  object \n",
      " 211  pref_city_y2_4         23432 non-null  object \n",
      " 212  pref_city_y2_5         23432 non-null  object \n",
      " 213  pref_city_y3_1         23432 non-null  object \n",
      " 214  pref_city_y3_2         23432 non-null  object \n",
      " 215  pref_city_y3_3         23432 non-null  object \n",
      " 216  pref_city_y3_4         23432 non-null  object \n",
      " 217  pref_city_y3_5         23432 non-null  object \n",
      " 218  pref_month_m3_1        774 non-null    float64\n",
      " 219  pref_month_m3_2        774 non-null    float64\n",
      " 220  pref_month_m3_3        604 non-null    float64\n",
      " 221  pref_month_m3_4        548 non-null    float64\n",
      " 222  pref_month_m3_5        534 non-null    float64\n",
      " 223  pref_month_m6_1        1268 non-null   float64\n",
      " 224  pref_month_m6_2        1268 non-null   float64\n",
      " 225  pref_month_m6_3        962 non-null    float64\n",
      " 226  pref_month_m6_4        873 non-null    float64\n",
      " 227  pref_month_m6_5        828 non-null    float64\n",
      " 228  pref_month_y1_1        2562 non-null   float64\n",
      " 229  pref_month_y1_2        2562 non-null   float64\n",
      " 230  pref_month_y1_3        1815 non-null   float64\n",
      " 231  pref_month_y1_4        1595 non-null   float64\n",
      " 232  pref_month_y1_5        1483 non-null   float64\n",
      " 233  pref_month_y2_1        6425 non-null   float64\n",
      " 234  pref_month_y2_2        6425 non-null   float64\n",
      " 235  pref_month_y2_3        4052 non-null   float64\n",
      " 236  pref_month_y2_4        3334 non-null   float64\n",
      " 237  pref_month_y2_5        2964 non-null   float64\n",
      " 238  pref_month_y3_1        7813 non-null   float64\n",
      " 239  pref_month_y3_2        7813 non-null   float64\n",
      " 240  pref_month_y3_3        4962 non-null   float64\n",
      " 241  pref_month_y3_4        4054 non-null   float64\n",
      " 242  pref_month_y3_5        3450 non-null   float64\n",
      " 243  workday_cnt_m3         0 non-null      float64\n",
      " 244  workday_cnt_m6         0 non-null      float64\n",
      " 245  workday_cnt_y1         0 non-null      float64\n",
      " 246  workday_cnt_y2         0 non-null      float64\n",
      " 247  workday_cnt_y3         0 non-null      float64\n",
      " 248  weekend_cnt_m3         0 non-null      float64\n",
      " 249  weekend_cnt_m6         0 non-null      float64\n",
      " 250  weekend_cnt_y1         0 non-null      float64\n",
      " 251  weekend_cnt_y2         0 non-null      float64\n",
      " 252  weekend_cnt_y3         0 non-null      float64\n",
      " 253  holiday_cnt_m3         0 non-null      float64\n",
      " 254  holiday_cnt_m6         0 non-null      float64\n",
      " 255  holiday_cnt_y1         0 non-null      float64\n",
      " 256  holiday_cnt_y2         0 non-null      float64\n",
      " 257  holiday_cnt_y3         0 non-null      float64\n",
      " 258  close_holiday_cnt_m3   0 non-null      float64\n",
      " 259  close_holiday_cnt_m6   0 non-null      float64\n",
      " 260  close_holiday_cnt_y1   0 non-null      float64\n",
      " 261  close_holiday_cnt_y2   0 non-null      float64\n",
      " 262  close_holiday_cnt_y3   0 non-null      float64\n",
      " 263  flt_cnt_m3             776 non-null    float64\n",
      " 264  flt_cnt_m6             1256 non-null   float64\n",
      " 265  flt_cnt_y1             2491 non-null   float64\n",
      " 266  flt_cnt_y2             6379 non-null   float64\n",
      " 267  flt_cnt_y3             7813 non-null   float64\n",
      " 268  recent_flt_day         23432 non-null  object \n",
      " 269  next_flt_day           383 non-null    float64\n",
      " 270  birth_interval_day     0 non-null      float64\n",
      " 271  dist_cnt_y1            5195 non-null   float64\n",
      " 272  dist_cnt_y2            0 non-null      float64\n",
      " 273  dist_cnt_y3            9254 non-null   float64\n",
      " 274  flt_nature_cnt_y1      5201 non-null   float64\n",
      " 275  flt_nature_cnt_y2      0 non-null      float64\n",
      " 276  flt_nature_cnt_y3      9256 non-null   float64\n",
      " 277  avg_dist_cnt_m3        981 non-null    float64\n",
      " 278  avg_dist_cnt_m6        1678 non-null   float64\n",
      " 279  avg_dist_cnt_y1        3733 non-null   float64\n",
      " 280  avg_dist_cnt_y2        7177 non-null   float64\n",
      " 281  avg_dist_cnt_y3        7813 non-null   float64\n",
      " 282  complain_valid_cnt_m3  51 non-null     float64\n",
      " 283  complain_valid_cnt_m6  58 non-null     float64\n",
      " 284  complain_valid_cnt_y1  63 non-null     float64\n",
      " 285  complain_valid_cnt_y2  74 non-null     float64\n",
      " 286  complain_valid_cnt_y3  99 non-null     float64\n",
      " 287  bag_cnt_m3             17 non-null     float64\n",
      " 288  bag_cnt_m6             26 non-null     float64\n",
      " 289  bag_cnt_y1             59 non-null     float64\n",
      " 290  bag_cnt_y2             105 non-null    float64\n",
      " 291  bag_cnt_y3             131 non-null    float64\n",
      " 292  cabin_upgrd_cnt_m3     37 non-null     float64\n",
      " 293  cabin_upgrd_cnt_m6     74 non-null     float64\n",
      " 294  cabin_upgrd_cnt_y1     160 non-null    float64\n",
      " 295  cabin_upgrd_cnt_y2     273 non-null    float64\n",
      " 296  cabin_upgrd_cnt_y3     348 non-null    float64\n",
      " 297  select_seat_cnt_m3     0 non-null      float64\n",
      " 298  select_seat_cnt_m6     0 non-null      float64\n",
      " 299  select_seat_cnt_y1     100 non-null    float64\n",
      " 300  select_seat_cnt_y2     477 non-null    float64\n",
      " 301  select_seat_cnt_y3     596 non-null    float64\n",
      " 302  dist_d_cnt_m3          260 non-null    float64\n",
      " 303  dist_d_cnt_m6          463 non-null    float64\n",
      " 304  dist_d_cnt_y1          893 non-null    float64\n",
      " 305  dist_d_cnt_y2          1996 non-null   float64\n",
      " 306  dist_d_cnt_y3          2426 non-null   float64\n",
      " 307  dist_i_cnt_m3          814 non-null    float64\n",
      " 308  dist_i_cnt_m6          1367 non-null   float64\n",
      " 309  dist_i_cnt_y1          2851 non-null   float64\n",
      " 310  dist_i_cnt_y2          7330 non-null   float64\n",
      " 311  dist_i_cnt_y3          9194 non-null   float64\n",
      " 312  dist_all_cnt_m3        936 non-null    float64\n",
      " 313  dist_all_cnt_m6        1527 non-null   float64\n",
      " 314  dist_all_cnt_y1        3022 non-null   float64\n",
      " 315  dist_all_cnt_y2        7427 non-null   float64\n",
      " 316  dist_all_cnt_y3        9254 non-null   float64\n",
      " 317  cabin_hd_cnt_m3        73 non-null     float64\n",
      " 318  cabin_hd_cnt_m6        137 non-null    float64\n",
      " 319  cabin_hd_cnt_y1        239 non-null    float64\n",
      " 320  cabin_hd_cnt_y2        337 non-null    float64\n",
      " 321  cabin_hd_cnt_y3        396 non-null    float64\n",
      " 322  cabin_hi_cnt_m3        175 non-null    float64\n",
      " 323  cabin_hi_cnt_m6        290 non-null    float64\n",
      " 324  cabin_hi_cnt_y1        558 non-null    float64\n",
      " 325  cabin_hi_cnt_y2        1109 non-null   float64\n",
      " 326  cabin_hi_cnt_y3        1323 non-null   float64\n",
      " 327  flt_leg_cnt_m3         936 non-null    float64\n",
      " 328  flt_leg_cnt_m6         1527 non-null   float64\n",
      " 329  flt_leg_cnt_y1         3022 non-null   float64\n",
      " 330  flt_leg_cnt_y2         7429 non-null   float64\n",
      " 331  flt_leg_cnt_y3         9256 non-null   float64\n",
      " 332  flt_leg_i_cnt_m3       814 non-null    float64\n",
      " 333  flt_leg_i_cnt_m6       1367 non-null   float64\n",
      " 334  flt_leg_i_cnt_y1       2851 non-null   float64\n",
      " 335  flt_leg_i_cnt_y2       7332 non-null   float64\n",
      " 336  flt_leg_i_cnt_y3       9196 non-null   float64\n",
      " 337  flt_leg_d_cnt_m3       260 non-null    float64\n",
      " 338  flt_leg_d_cnt_m6       463 non-null    float64\n",
      " 339  flt_leg_d_cnt_y1       893 non-null    float64\n",
      " 340  flt_leg_d_cnt_y2       1996 non-null   float64\n",
      " 341  flt_leg_d_cnt_y3       2426 non-null   float64\n",
      " 342  flt_cancel_cnt_m3      0 non-null      float64\n",
      " 343  flt_cancel_cnt_m6      0 non-null      float64\n",
      " 344  flt_cancel_cnt_y1      0 non-null      float64\n",
      " 345  flt_cancel_cnt_y2      0 non-null      float64\n",
      " 346  flt_cancel_cnt_y3      11 non-null     float64\n",
      " 347  flt_delay_cnt_m3       131 non-null    float64\n",
      " 348  flt_delay_cnt_m6       381 non-null    float64\n",
      " 349  flt_delay_cnt_y1       1028 non-null   float64\n",
      " 350  flt_delay_cnt_y2       3249 non-null   float64\n",
      " 351  flt_delay_cnt_y3       4586 non-null   float64\n",
      " 352  flt_delay_time_m3      3200 non-null   float64\n",
      " 353  flt_delay_time_m6      3172 non-null   float64\n",
      " 354  flt_delay_time_y1      3104 non-null   float64\n",
      " 355  flt_delay_time_y2      2650 non-null   float64\n",
      " 356  flt_delay_time_y3      1994 non-null   float64\n",
      " 357  rest_cnt_m3            0 non-null      float64\n",
      " 358  rest_cnt_m6            0 non-null      float64\n",
      " 359  rest_cnt_y1            0 non-null      float64\n",
      " 360  rest_cnt_y2            0 non-null      float64\n",
      " 361  rest_cnt_y3            0 non-null      float64\n",
      " 362  pref_orig_city_m3      23432 non-null  object \n",
      " 363  pref_orig_city_m6      23432 non-null  object \n",
      " 364  pref_orig_city_y1      23432 non-null  object \n",
      " 365  pref_orig_city_y2      23432 non-null  object \n",
      " 366  pref_orig_city_y3      23432 non-null  object \n",
      " 367  pref_dest_city_m3      23432 non-null  object \n",
      " 368  pref_dest_city_m6      23432 non-null  object \n",
      " 369  pref_dest_city_y1      23432 non-null  object \n",
      " 370  pref_dest_city_y2      23432 non-null  object \n",
      " 371  pref_dest_city_y3      23432 non-null  object \n",
      " 372  cabin_fall_cnt_m3      1 non-null      float64\n",
      " 373  cabin_fall_cnt_m6      2 non-null      float64\n",
      " 374  cabin_fall_cnt_y1      2 non-null      float64\n",
      " 375  cabin_fall_cnt_y2      4 non-null      float64\n",
      " 376  cabin_fall_cnt_y3      17 non-null     float64\n",
      " 377  flt_bag_cnt_m3         797 non-null    float64\n",
      " 378  flt_bag_cnt_m6         1317 non-null   float64\n",
      " 379  flt_bag_cnt_y1         2697 non-null   float64\n",
      " 380  flt_bag_cnt_y2         6655 non-null   float64\n",
      " 381  flt_bag_cnt_y3         8299 non-null   float64\n",
      " 382  complain_cnt_m3        71 non-null     float64\n",
      " 383  complain_cnt_m6        78 non-null     float64\n",
      " 384  complain_cnt_y1        85 non-null     float64\n",
      " 385  complain_cnt_y2        99 non-null     float64\n",
      " 386  complain_cnt_y3        128 non-null    float64\n",
      " 387  noshow_rate_m3         35 non-null     float64\n",
      " 388  noshow_rate_m6         49 non-null     float64\n",
      " 389  noshow_rate_y1         90 non-null     float64\n",
      " 390  noshow_rate_y2         236 non-null    float64\n",
      " 391  noshow_rate_y3         294 non-null    float64\n",
      " 392  tkt_3y_amt             9185 non-null   float64\n",
      " 393  tkt_avg_amt            0 non-null      float64\n",
      " 394  tkt_d_amt_m3           236 non-null    float64\n",
      " 395  tkt_d_amt_m6           425 non-null    float64\n",
      " 396  tkt_d_amt_y1           848 non-null    float64\n",
      " 397  tkt_d_amt_y2           1945 non-null   float64\n",
      " 398  tkt_d_amt_y3           2379 non-null   float64\n",
      " 399  tkt_i_amt_m3           609 non-null    float64\n",
      " 400  tkt_i_amt_m6           1044 non-null   float64\n",
      " 401  tkt_i_amt_y1           2249 non-null   float64\n",
      " 402  tkt_i_amt_y2           6230 non-null   float64\n",
      " 403  tkt_i_amt_y3           7724 non-null   float64\n",
      " 404  tkt_all_amt_m3         721 non-null    float64\n",
      " 405  tkt_all_amt_m6         1184 non-null   float64\n",
      " 406  tkt_all_amt_y1         2398 non-null   float64\n",
      " 407  tkt_all_amt_y2         6320 non-null   float64\n",
      " 408  tkt_all_amt_y3         7778 non-null   float64\n",
      " 409  tkt_avg_amt_m3         721 non-null    float64\n",
      " 410  tkt_avg_amt_m6         1184 non-null   float64\n",
      " 411  tkt_avg_amt_y1         2398 non-null   float64\n",
      " 412  tkt_avg_amt_y2         6320 non-null   float64\n",
      " 413  tkt_avg_amt_y3         7778 non-null   float64\n",
      " 414  tkt_avg_disc_m3        0 non-null      float64\n",
      " 415  tkt_avg_disc_m6        0 non-null      float64\n",
      " 416  tkt_avg_disc_y1        0 non-null      float64\n",
      " 417  tkt_avg_disc_y2        0 non-null      float64\n",
      " 418  tkt_avg_disc_y3        0 non-null      float64\n",
      " 419  tkt_return_cnt_m3      9 non-null      float64\n",
      " 420  tkt_return_cnt_m6      70 non-null     float64\n",
      " 421  tkt_return_cnt_y1      168 non-null    float64\n",
      " 422  tkt_return_cnt_y2      359 non-null    float64\n",
      " 423  tkt_return_cnt_y3      466 non-null    float64\n",
      " 424  tkt_book_cnt_m3        105 non-null    float64\n",
      " 425  tkt_book_cnt_m6        484 non-null    float64\n",
      " 426  tkt_book_cnt_y1        912 non-null    float64\n",
      " 427  tkt_book_cnt_y2        2152 non-null   float64\n",
      " 428  tkt_book_cnt_y3        2671 non-null   float64\n",
      " 429  tkt_return_all_cnt_m3  12 non-null     float64\n",
      " 430  tkt_return_all_cnt_m6  124 non-null    float64\n",
      " 431  tkt_return_all_cnt_y1  241 non-null    float64\n",
      " 432  tkt_return_all_cnt_y2  439 non-null    float64\n",
      " 433  tkt_return_all_cnt_y3  511 non-null    float64\n",
      " 434  tkt_avg_interval_m3    49 non-null     float64\n",
      " 435  tkt_avg_interval_m6    134 non-null    float64\n",
      " 436  tkt_avg_interval_y1    354 non-null    float64\n",
      " 437  tkt_avg_interval_y2    792 non-null    float64\n",
      " 438  tkt_avg_interval_y3    1093 non-null   float64\n",
      " 439  pit_all_amt            2561 non-null   float64\n",
      " 440  pit_out_amt            13 non-null     float64\n",
      " 441  pit_accu_non_cnt       601 non-null    float64\n",
      " 442  pit_accu_air_cnt       2524 non-null   float64\n",
      " 443  pit_accu_air_amt       2524 non-null   float64\n",
      " 444  pit_accu_non_amt       485 non-null    float64\n",
      " 445  pit_now_cons_amt       2561 non-null   float64\n",
      " 446  pit_next_level_dist    2153 non-null   float64\n",
      " 447  pit_next_level_leg     10 non-null     float64\n",
      " 448  mdl_mcv                7569 non-null   float64\n",
      " 449  mdl_lost_idx           0 non-null      float64\n",
      " 450  mdl_influence          1279 non-null   float64\n",
      " 451  mdl_loyal              0 non-null      float64\n",
      " 452  pit_accu_amt_m3        132 non-null    float64\n",
      " 453  pit_accu_amt_m6        591 non-null    float64\n",
      " 454  pit_accu_amt_y1        1203 non-null   float64\n",
      " 455  pit_accu_amt_y2        2289 non-null   float64\n",
      " 456  pit_accu_amt_y3        2543 non-null   float64\n",
      " 457  pit_cons_amt_m3        21 non-null     float64\n",
      " 458  pit_cons_amt_m6        170 non-null    float64\n",
      " 459  pit_cons_amt_y1        286 non-null    float64\n",
      " 460  pit_cons_amt_y2        863 non-null    float64\n",
      " 461  pit_cons_amt_y3        935 non-null    float64\n",
      " 462  pit_avg_accu_amt_m3    109 non-null    float64\n",
      " 463  pit_avg_accu_amt_m6    537 non-null    float64\n",
      " 464  pit_avg_accu_amt_y1    1011 non-null   float64\n",
      " 465  pit_avg_accu_amt_y2    1901 non-null   float64\n",
      " 466  pit_avg_accu_amt_y3    2086 non-null   float64\n",
      " 467  pit_avg_cons_amt_m3    21 non-null     float64\n",
      " 468  pit_avg_cons_amt_m6    170 non-null    float64\n",
      " 469  pit_avg_cons_amt_y1    286 non-null    float64\n",
      " 470  pit_avg_cons_amt_y2    863 non-null    float64\n",
      " 471  pit_avg_cons_amt_y3    935 non-null    float64\n",
      " 472  pit_accu_cnt_m3        132 non-null    float64\n",
      " 473  pit_accu_cnt_m6        0 non-null      float64\n",
      " 474  pit_accu_cnt_y1        0 non-null      float64\n",
      " 475  pit_accu_cnt_y2        0 non-null      float64\n",
      " 476  pit_accu_cnt_y3        0 non-null      float64\n",
      " 477  pit_cons_cnt_m3        21 non-null     float64\n",
      " 478  pit_cons_cnt_m6        170 non-null    float64\n",
      " 479  pit_cons_cnt_y1        286 non-null    float64\n",
      " 480  pit_cons_cnt_y2        863 non-null    float64\n",
      " 481  pit_cons_cnt_y3        935 non-null    float64\n",
      " 482  pit_add_air_amt_m3     93 non-null     float64\n",
      " 483  pit_add_air_amt_m6     531 non-null    float64\n",
      " 484  pit_add_air_amt_y1     1005 non-null   float64\n",
      " 485  pit_add_air_amt_y2     1894 non-null   float64\n",
      " 486  pit_add_air_amt_y3     2078 non-null   float64\n",
      " 487  pit_add_non_amt_m3     18 non-null     float64\n",
      " 488  pit_add_non_amt_m6     80 non-null     float64\n",
      " 489  pit_add_non_amt_y1     124 non-null    float64\n",
      " 490  pit_add_non_amt_y2     246 non-null    float64\n",
      " 491  pit_add_non_amt_y3     726 non-null    float64\n",
      " 492  pit_add_buy_amt_m3     0 non-null      float64\n",
      " 493  pit_add_buy_amt_m6     0 non-null      float64\n",
      " 494  pit_add_buy_amt_y1     1 non-null      float64\n",
      " 495  pit_add_buy_amt_y2     8 non-null      float64\n",
      " 496  pit_add_buy_amt_y3     10 non-null     float64\n",
      " 497  pit_add_mnl_amt_m3     0 non-null      float64\n",
      " 498  pit_add_mnl_amt_m6     0 non-null      float64\n",
      " 499  pit_add_mnl_amt_y1     0 non-null      float64\n",
      " 500  pit_add_mnl_amt_y2     0 non-null      float64\n",
      " 501  pit_add_mnl_amt_y3     0 non-null      float64\n",
      " 502  pit_add_ech_amt_m3     0 non-null      float64\n",
      " 503  pit_add_ech_amt_m6     0 non-null      float64\n",
      " 504  pit_add_ech_amt_y1     0 non-null      float64\n",
      " 505  pit_add_ech_amt_y2     0 non-null      float64\n",
      " 506  pit_add_ech_amt_y3     0 non-null      float64\n",
      " 507  pit_add_oth_amt_m3     0 non-null      float64\n",
      " 508  pit_add_oth_amt_m6     0 non-null      float64\n",
      " 509  pit_add_oth_amt_y1     0 non-null      float64\n",
      " 510  pit_add_oth_amt_y2     0 non-null      float64\n",
      " 511  pit_add_oth_amt_y3     0 non-null      float64\n",
      " 512  pit_des_tkt_amt_m3     0 non-null      float64\n",
      " 513  pit_des_tkt_amt_m6     0 non-null      float64\n",
      " 514  pit_des_tkt_amt_y1     0 non-null      float64\n",
      " 515  pit_des_tkt_amt_y2     0 non-null      float64\n",
      " 516  pit_des_tkt_amt_y3     0 non-null      float64\n",
      " 517  pit_des_bag_amt_m3     0 non-null      float64\n",
      " 518  pit_des_bag_amt_m6     0 non-null      float64\n",
      " 519  pit_des_bag_amt_y1     0 non-null      float64\n",
      " 520  pit_des_bag_amt_y2     0 non-null      float64\n",
      " 521  pit_des_bag_amt_y3     0 non-null      float64\n",
      " 522  pit_des_upg_amt_m3     1 non-null      float64\n",
      " 523  pit_des_upg_amt_m6     29 non-null     float64\n",
      " 524  pit_des_upg_amt_y1     44 non-null     float64\n",
      " 525  pit_des_upg_amt_y2     63 non-null     float64\n",
      " 526  pit_des_upg_amt_y3     68 non-null     float64\n",
      " 527  pit_des_mall_amt_m3    0 non-null      float64\n",
      " 528  pit_des_mall_amt_m6    21 non-null     float64\n",
      " 529  pit_des_mall_amt_y1    40 non-null     float64\n",
      " 530  pit_des_mall_amt_y2    89 non-null     float64\n",
      " 531  pit_des_mall_amt_y3    108 non-null    float64\n",
      " 532  pit_des_selt_amt_m3    0 non-null      float64\n",
      " 533  pit_des_selt_amt_m6    0 non-null      float64\n",
      " 534  pit_des_selt_amt_y1    0 non-null      float64\n",
      " 535  pit_des_selt_amt_y2    0 non-null      float64\n",
      " 536  pit_des_selt_amt_y3    0 non-null      float64\n",
      " 537  pit_des_out_amt_m3     16 non-null     float64\n",
      " 538  pit_des_out_amt_m6     22 non-null     float64\n",
      " 539  pit_des_out_amt_y1     50 non-null     float64\n",
      " 540  pit_des_out_amt_y2     598 non-null    float64\n",
      " 541  pit_des_out_amt_y3     673 non-null    float64\n",
      " 542  pit_des_oth_amt_m3     0 non-null      float64\n",
      " 543  pit_des_oth_amt_m6     0 non-null      float64\n",
      " 544  pit_des_oth_amt_y1     0 non-null      float64\n",
      " 545  pit_des_oth_amt_y2     0 non-null      float64\n",
      " 546  pit_des_oth_amt_y3     0 non-null      float64\n",
      " 547  pit_add_air_cnt_m3     93 non-null     float64\n",
      " 548  pit_add_air_cnt_m6     531 non-null    float64\n",
      " 549  pit_add_air_cnt_y1     1005 non-null   float64\n",
      " 550  pit_add_air_cnt_y2     1894 non-null   float64\n",
      " 551  pit_add_air_cnt_y3     2078 non-null   float64\n",
      " 552  pit_add_non_cnt_m3     21 non-null     float64\n",
      " 553  pit_add_non_cnt_m6     92 non-null     float64\n",
      " 554  pit_add_non_cnt_y1     135 non-null    float64\n",
      " 555  pit_add_non_cnt_y2     239 non-null    float64\n",
      " 556  pit_add_non_cnt_y3     591 non-null    float64\n",
      " 557  pit_add_buy_cnt_m3     0 non-null      float64\n",
      " 558  pit_add_buy_cnt_m6     0 non-null      float64\n",
      " 559  pit_add_buy_cnt_y1     1 non-null      float64\n",
      " 560  pit_add_buy_cnt_y2     8 non-null      float64\n",
      " 561  pit_add_buy_cnt_y3     10 non-null     float64\n",
      " 562  pit_add_mnl_cnt_m3     0 non-null      float64\n",
      " 563  pit_add_mnl_cnt_m6     0 non-null      float64\n",
      " 564  pit_add_mnl_cnt_y1     0 non-null      float64\n",
      " 565  pit_add_mnl_cnt_y2     0 non-null      float64\n",
      " 566  pit_add_mnl_cnt_y3     0 non-null      float64\n",
      " 567  pit_add_ech_cnt_m3     0 non-null      float64\n",
      " 568  pit_add_ech_cnt_m6     0 non-null      float64\n",
      " 569  pit_add_ech_cnt_y1     0 non-null      float64\n",
      " 570  pit_add_ech_cnt_y2     0 non-null      float64\n",
      " 571  pit_add_ech_cnt_y3     0 non-null      float64\n",
      " 572  pit_add_oth_cnt_m3     0 non-null      float64\n",
      " 573  pit_add_oth_cnt_m6     0 non-null      float64\n",
      " 574  pit_add_oth_cnt_y1     0 non-null      float64\n",
      " 575  pit_add_oth_cnt_y2     0 non-null      float64\n",
      " 576  pit_add_oth_cnt_y3     0 non-null      float64\n",
      " 577  pit_des_tkt_cnt_m3     0 non-null      float64\n",
      " 578  pit_des_tkt_cnt_m6     0 non-null      float64\n",
      " 579  pit_des_tkt_cnt_y1     0 non-null      float64\n",
      " 580  pit_des_tkt_cnt_y2     0 non-null      float64\n",
      " 581  pit_des_tkt_cnt_y3     0 non-null      float64\n",
      " 582  pit_des_bag_cnt_m3     0 non-null      float64\n",
      " 583  pit_des_bag_cnt_m6     0 non-null      float64\n",
      " 584  pit_des_bag_cnt_y1     0 non-null      float64\n",
      " 585  pit_des_bag_cnt_y2     0 non-null      float64\n",
      " 586  pit_des_bag_cnt_y3     0 non-null      float64\n",
      " 587  pit_des_upg_cnt_m3     1 non-null      float64\n",
      " 588  pit_des_upg_cnt_m6     29 non-null     float64\n",
      " 589  pit_des_upg_cnt_y1     44 non-null     float64\n",
      " 590  pit_des_upg_cnt_y2     63 non-null     float64\n",
      " 591  pit_des_upg_cnt_y3     68 non-null     float64\n",
      " 592  pit_des_mall_cnt_m3    1 non-null      float64\n",
      " 593  pit_des_mall_cnt_m6    26 non-null     float64\n",
      " 594  pit_des_mall_cnt_y1    55 non-null     float64\n",
      " 595  pit_des_mall_cnt_y2    112 non-null    float64\n",
      " 596  pit_des_mall_cnt_y3    133 non-null    float64\n",
      " 597  pit_des_selt_cnt_m3    0 non-null      float64\n",
      " 598  pit_des_selt_cnt_m6    0 non-null      float64\n",
      " 599  pit_des_selt_cnt_y1    0 non-null      float64\n",
      " 600  pit_des_selt_cnt_y2    0 non-null      float64\n",
      " 601  pit_des_selt_cnt_y3    0 non-null      float64\n",
      " 602  pit_des_out_cnt_m3     6 non-null      float64\n",
      " 603  pit_des_out_cnt_m6     10 non-null     float64\n",
      " 604  pit_des_out_cnt_y1     34 non-null     float64\n",
      " 605  pit_des_out_cnt_y2     472 non-null    float64\n",
      " 606  pit_des_out_cnt_y3     533 non-null    float64\n",
      " 607  pit_des_oth_cnt_m3     0 non-null      float64\n",
      " 608  pit_des_oth_cnt_m6     0 non-null      float64\n",
      " 609  pit_des_oth_cnt_y1     0 non-null      float64\n",
      " 610  pit_des_oth_cnt_y2     0 non-null      float64\n",
      " 611  pit_des_oth_cnt_y3     0 non-null      float64\n",
      " 612  pit_avg_amt_m3         125 non-null    float64\n",
      " 613  pit_avg_amt_m6         580 non-null    float64\n",
      " 614  pit_avg_amt_y1         1193 non-null   float64\n",
      " 615  pit_avg_amt_y2         2285 non-null   float64\n",
      " 616  pit_avg_amt_y3         2538 non-null   float64\n",
      " 617  pit_avg_interval_m3    31 non-null     float64\n",
      " 618  pit_avg_interval_m6    359 non-null    float64\n",
      " 619  pit_avg_interval_y1    786 non-null    float64\n",
      " 620  pit_avg_interval_y2    1716 non-null   float64\n",
      " 621  pit_avg_interval_y3    1840 non-null   float64\n",
      " 622  pit_ech_avg_amt_m3     18 non-null     float64\n",
      " 623  pit_ech_avg_amt_m6     111 non-null    float64\n",
      " 624  pit_ech_avg_amt_y1     205 non-null    float64\n",
      " 625  pit_ech_avg_amt_y2     311 non-null    float64\n",
      " 626  pit_ech_avg_amt_y3     345 non-null    float64\n",
      " 627  pit_out_avg_amt_m3     6 non-null      float64\n",
      " 628  pit_out_avg_amt_m6     10 non-null     float64\n",
      " 629  pit_out_avg_amt_y1     34 non-null     float64\n",
      " 630  pit_out_avg_amt_y2     472 non-null    float64\n",
      " 631  pit_out_avg_amt_y3     533 non-null    float64\n",
      " 632  pit_income_cnt_m3      132 non-null    float64\n",
      " 633  pit_income_cnt_m6      591 non-null    float64\n",
      " 634  pit_income_cnt_y1      1203 non-null   float64\n",
      " 635  pit_income_cnt_y2      2289 non-null   float64\n",
      " 636  pit_income_cnt_y3      2543 non-null   float64\n",
      " 637  pit_pay_cnt_m3         24 non-null     float64\n",
      " 638  pit_pay_cnt_m6         121 non-null    float64\n",
      " 639  pit_pay_cnt_y1         233 non-null    float64\n",
      " 640  pit_pay_cnt_y2         699 non-null    float64\n",
      " 641  pit_pay_cnt_y3         765 non-null    float64\n",
      " 642  pit_income_avg_amt_m3  109 non-null    float64\n",
      " 643  pit_income_avg_amt_m6  537 non-null    float64\n",
      " 644  pit_income_avg_amt_y1  1011 non-null   float64\n",
      " 645  pit_income_avg_amt_y2  1901 non-null   float64\n",
      " 646  pit_income_avg_amt_y3  2086 non-null   float64\n",
      " 647  pit_pay_avg_amt_m3     21 non-null     float64\n",
      " 648  pit_pay_avg_amt_m6     170 non-null    float64\n",
      " 649  pit_pay_avg_amt_y1     286 non-null    float64\n",
      " 650  pit_pay_avg_amt_y2     863 non-null    float64\n",
      " 651  pit_pay_avg_amt_y3     935 non-null    float64\n",
      " 652  pit_add_chnl_m3        23432 non-null  object \n",
      " 653  pit_add_chnl_m6        23432 non-null  object \n",
      " 654  pit_add_chnl_y1        23432 non-null  object \n",
      " 655  pit_add_chnl_y2        23432 non-null  object \n",
      " 656  pit_add_chnl_y3        23432 non-null  object \n",
      "dtypes: float64(524), object(133)\n",
      "memory usage: 117.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data1 = data.replace(0,np.nan)\n",
    "data1.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\3008618231.py:1: DtypeWarning: Columns (46,47,56,57,141,142,266,340,360,437,650,651) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv(\"test.csv\")\n",
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\3008618231.py:3: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  test1.info(verbose=True,null_counts=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6771 entries, 0 to 6770\n",
      "Data columns (total 657 columns):\n",
      " #    Column                 Non-Null Count  Dtype  \n",
      "---   ------                 --------------  -----  \n",
      " 0    pax_name               6771 non-null   object \n",
      " 1    pax_passport           6771 non-null   object \n",
      " 2    seg_route_from         6771 non-null   object \n",
      " 3    seg_route_to           6771 non-null   object \n",
      " 4    seg_flight             6771 non-null   object \n",
      " 5    seg_cabin              6771 non-null   object \n",
      " 6    seg_dep_time           6771 non-null   object \n",
      " 7    pax_fcny               6767 non-null   float64\n",
      " 8    pax_tax                6770 non-null   float64\n",
      " 9    emd_lable              0 non-null      float64\n",
      " 10   emd_lable2             0 non-null      float64\n",
      " 11   gender                 6771 non-null   object \n",
      " 12   age                    6771 non-null   object \n",
      " 13   birth_date             6771 non-null   object \n",
      " 14   residence_country      6771 non-null   object \n",
      " 15   nation_name            6771 non-null   object \n",
      " 16   city_name              6771 non-null   object \n",
      " 17   province_name          6771 non-null   object \n",
      " 18   marital_stat           6771 non-null   object \n",
      " 19   ffp_nbr                6771 non-null   object \n",
      " 20   member_level           6771 non-null   object \n",
      " 21   often_city             6771 non-null   object \n",
      " 22   enroll_chnl            6771 non-null   object \n",
      " 23   cabin_hf_cnt_m3        0 non-null      float64\n",
      " 24   cabin_hf_cnt_m6        4 non-null      float64\n",
      " 25   cabin_hf_cnt_y1        12 non-null     float64\n",
      " 26   cabin_hf_cnt_y2        19 non-null     float64\n",
      " 27   cabin_hf_cnt_y3        15 non-null     float64\n",
      " 28   cabin_f_cnt_m3         6 non-null      float64\n",
      " 29   cabin_f_cnt_m6         7 non-null      float64\n",
      " 30   cabin_f_cnt_y1         13 non-null     float64\n",
      " 31   cabin_f_cnt_y2         30 non-null     float64\n",
      " 32   cabin_f_cnt_y3         39 non-null     float64\n",
      " 33   cabin_hy_cnt_m3        61 non-null     float64\n",
      " 34   cabin_hy_cnt_m6        110 non-null    float64\n",
      " 35   cabin_hy_cnt_y1        175 non-null    float64\n",
      " 36   cabin_hy_cnt_y2        304 non-null    float64\n",
      " 37   cabin_hy_cnt_y3        381 non-null    float64\n",
      " 38   cabin_y_cnt_m3         220 non-null    float64\n",
      " 39   cabin_y_cnt_m6         357 non-null    float64\n",
      " 40   cabin_y_cnt_y1         467 non-null    float64\n",
      " 41   cabin_y_cnt_y2         610 non-null    float64\n",
      " 42   cabin_y_cnt_y3         649 non-null    float64\n",
      " 43   cabin_c_cnt_m3         71 non-null     float64\n",
      " 44   cabin_c_cnt_m6         108 non-null    float64\n",
      " 45   cabin_c_cnt_y1         131 non-null    float64\n",
      " 46   cabin_c_cnt_y2         1170 non-null   object \n",
      " 47   cabin_c_cnt_y3         2786 non-null   object \n",
      " 48   pref_aircraft_m3_1     6771 non-null   object \n",
      " 49   pref_aircraft_m3_2     6771 non-null   object \n",
      " 50   pref_aircraft_m3_3     6771 non-null   object \n",
      " 51   pref_aircraft_m3_4     6771 non-null   object \n",
      " 52   pref_aircraft_m3_5     6771 non-null   object \n",
      " 53   pref_aircraft_m6_1     6771 non-null   object \n",
      " 54   pref_aircraft_m6_2     6771 non-null   object \n",
      " 55   pref_aircraft_m6_3     6771 non-null   object \n",
      " 56   pref_aircraft_m6_4     5770 non-null   object \n",
      " 57   pref_aircraft_m6_5     5769 non-null   object \n",
      " 58   pref_aircraft_y1_1     6771 non-null   object \n",
      " 59   pref_aircraft_y1_2     6771 non-null   object \n",
      " 60   pref_aircraft_y1_3     6771 non-null   object \n",
      " 61   pref_aircraft_y1_4     6771 non-null   object \n",
      " 62   pref_aircraft_y1_5     6771 non-null   object \n",
      " 63   pref_aircraft_y2_1     6771 non-null   object \n",
      " 64   pref_aircraft_y2_2     6771 non-null   object \n",
      " 65   pref_aircraft_y2_3     6771 non-null   object \n",
      " 66   pref_aircraft_y2_4     6771 non-null   object \n",
      " 67   pref_aircraft_y2_5     6771 non-null   object \n",
      " 68   pref_aircraft_y3_1     6771 non-null   object \n",
      " 69   pref_aircraft_y3_2     6771 non-null   object \n",
      " 70   pref_aircraft_y3_3     6771 non-null   object \n",
      " 71   pref_aircraft_y3_4     6771 non-null   object \n",
      " 72   pref_aircraft_y3_5     6771 non-null   object \n",
      " 73   seat_window_cnt_m3     124 non-null    float64\n",
      " 74   seat_window_cnt_m6     205 non-null    float64\n",
      " 75   seat_window_cnt_y1     288 non-null    float64\n",
      " 76   seat_window_cnt_y2     433 non-null    float64\n",
      " 77   seat_window_cnt_y3     482 non-null    float64\n",
      " 78   seat_walkway_cnt_m3    187 non-null    float64\n",
      " 79   seat_walkway_cnt_m6    311 non-null    float64\n",
      " 80   seat_walkway_cnt_y1    441 non-null    float64\n",
      " 81   seat_walkway_cnt_y2    601 non-null    float64\n",
      " 82   seat_walkway_cnt_y3    642 non-null    float64\n",
      " 83   seat_middle_cnt_m3     74 non-null     float64\n",
      " 84   seat_middle_cnt_m6     132 non-null    float64\n",
      " 85   seat_middle_cnt_y1     215 non-null    float64\n",
      " 86   seat_middle_cnt_y2     367 non-null    float64\n",
      " 87   seat_middle_cnt_y3     418 non-null    float64\n",
      " 88   seat_safe_cnt_m3       0 non-null      float64\n",
      " 89   seat_safe_cnt_m6       0 non-null      float64\n",
      " 90   seat_safe_cnt_y1       0 non-null      float64\n",
      " 91   seat_safe_cnt_y2       0 non-null      float64\n",
      " 92   seat_safe_cnt_y3       7 non-null      float64\n",
      " 93   prebuy_d_cnt_m3_d3     20 non-null     float64\n",
      " 94   prebuy_d_cnt_m3_d7     8 non-null      float64\n",
      " 95   prebuy_d_cnt_m3_d14    14 non-null     float64\n",
      " 96   prebuy_d_cnt_m3_d30    26 non-null     float64\n",
      " 97   prebuy_d_cnt_m3_d99    52 non-null     float64\n",
      " 98   prebuy_d_cnt_m6_d3     37 non-null     float64\n",
      " 99   prebuy_d_cnt_m6_d7     25 non-null     float64\n",
      " 100  prebuy_d_cnt_m6_d14    29 non-null     float64\n",
      " 101  prebuy_d_cnt_m6_d30    42 non-null     float64\n",
      " 102  prebuy_d_cnt_m6_d99    91 non-null     float64\n",
      " 103  prebuy_d_cnt_y1_d3     64 non-null     float64\n",
      " 104  prebuy_d_cnt_y1_d7     42 non-null     float64\n",
      " 105  prebuy_d_cnt_y1_d14    58 non-null     float64\n",
      " 106  prebuy_d_cnt_y1_d30    67 non-null     float64\n",
      " 107  prebuy_d_cnt_y1_d99    132 non-null    float64\n",
      " 108  prebuy_d_cnt_y2_d3     102 non-null    float64\n",
      " 109  prebuy_d_cnt_y2_d7     93 non-null     float64\n",
      " 110  prebuy_d_cnt_y2_d14    107 non-null    float64\n",
      " 111  prebuy_d_cnt_y2_d30    111 non-null    float64\n",
      " 112  prebuy_d_cnt_y2_d99    195 non-null    float64\n",
      " 113  prebuy_d_cnt_y3_d3     127 non-null    float64\n",
      " 114  prebuy_d_cnt_y3_d7     124 non-null    float64\n",
      " 115  prebuy_d_cnt_y3_d14    136 non-null    float64\n",
      " 116  prebuy_d_cnt_y3_d30    142 non-null    float64\n",
      " 117  prebuy_d_cnt_y3_d99    215 non-null    float64\n",
      " 118  prebuy_i_cnt_m3_d3     25 non-null     float64\n",
      " 119  prebuy_i_cnt_m3_d7     14 non-null     float64\n",
      " 120  prebuy_i_cnt_m3_d14    38 non-null     float64\n",
      " 121  prebuy_i_cnt_m3_d30    65 non-null     float64\n",
      " 122  prebuy_i_cnt_m3_d99    152 non-null    float64\n",
      " 123  prebuy_i_cnt_m6_d3     49 non-null     float64\n",
      " 124  prebuy_i_cnt_m6_d7     33 non-null     float64\n",
      " 125  prebuy_i_cnt_m6_d14    70 non-null     float64\n",
      " 126  prebuy_i_cnt_m6_d30    121 non-null    float64\n",
      " 127  prebuy_i_cnt_m6_d99    270 non-null    float64\n",
      " 128  prebuy_i_cnt_y1_d3     88 non-null     float64\n",
      " 129  prebuy_i_cnt_y1_d7     65 non-null     float64\n",
      " 130  prebuy_i_cnt_y1_d14    113 non-null    float64\n",
      " 131  prebuy_i_cnt_y1_d30    203 non-null    float64\n",
      " 132  prebuy_i_cnt_y1_d99    394 non-null    float64\n",
      " 133  prebuy_i_cnt_y2_d3     135 non-null    float64\n",
      " 134  prebuy_i_cnt_y2_d7     123 non-null    float64\n",
      " 135  prebuy_i_cnt_y2_d14    178 non-null    float64\n",
      " 136  prebuy_i_cnt_y2_d30    310 non-null    float64\n",
      " 137  prebuy_i_cnt_y2_d99    579 non-null    float64\n",
      " 138  prebuy_i_cnt_y3_d3     181 non-null    float64\n",
      " 139  prebuy_i_cnt_y3_d7     163 non-null    float64\n",
      " 140  prebuy_i_cnt_y3_d14    221 non-null    float64\n",
      " 141  prebuy_i_cnt_y3_d30    1294 non-null   object \n",
      " 142  prebuy_i_cnt_y3_d99    5825 non-null   object \n",
      " 143  pref_orig_m3_1         6771 non-null   object \n",
      " 144  pref_orig_m3_2         6771 non-null   object \n",
      " 145  pref_orig_m3_3         6771 non-null   object \n",
      " 146  pref_orig_m3_4         6771 non-null   object \n",
      " 147  pref_orig_m3_5         6771 non-null   object \n",
      " 148  pref_orig_m6_1         6771 non-null   object \n",
      " 149  pref_orig_m6_2         6771 non-null   object \n",
      " 150  pref_orig_m6_3         6771 non-null   object \n",
      " 151  pref_orig_m6_4         6771 non-null   object \n",
      " 152  pref_orig_m6_5         6771 non-null   object \n",
      " 153  pref_orig_y1_1         6771 non-null   object \n",
      " 154  pref_orig_y1_2         6771 non-null   object \n",
      " 155  pref_orig_y1_3         6771 non-null   object \n",
      " 156  pref_orig_y1_4         6771 non-null   object \n",
      " 157  pref_orig_y1_5         6771 non-null   object \n",
      " 158  pref_orig_y2_1         6771 non-null   object \n",
      " 159  pref_orig_y2_2         6771 non-null   object \n",
      " 160  pref_orig_y2_3         6771 non-null   object \n",
      " 161  pref_orig_y2_4         6771 non-null   object \n",
      " 162  pref_orig_y2_5         6771 non-null   object \n",
      " 163  pref_orig_y3_1         6771 non-null   object \n",
      " 164  pref_orig_y3_2         6771 non-null   object \n",
      " 165  pref_orig_y3_3         6771 non-null   object \n",
      " 166  pref_orig_y3_4         6771 non-null   object \n",
      " 167  pref_orig_y3_5         6771 non-null   object \n",
      " 168  pref_line_m3_1         6771 non-null   object \n",
      " 169  pref_line_m3_2         6771 non-null   object \n",
      " 170  pref_line_m3_3         6771 non-null   object \n",
      " 171  pref_line_m3_4         6771 non-null   object \n",
      " 172  pref_line_m3_5         6771 non-null   object \n",
      " 173  pref_line_m6_1         6771 non-null   object \n",
      " 174  pref_line_m6_2         6771 non-null   object \n",
      " 175  pref_line_m6_3         6771 non-null   object \n",
      " 176  pref_line_m6_4         6771 non-null   object \n",
      " 177  pref_line_m6_5         6771 non-null   object \n",
      " 178  pref_line_y1_1         6771 non-null   object \n",
      " 179  pref_line_y1_2         6771 non-null   object \n",
      " 180  pref_line_y1_3         6771 non-null   object \n",
      " 181  pref_line_y1_4         6771 non-null   object \n",
      " 182  pref_line_y1_5         6771 non-null   object \n",
      " 183  pref_line_y2_1         6771 non-null   object \n",
      " 184  pref_line_y2_2         6771 non-null   object \n",
      " 185  pref_line_y2_3         6771 non-null   object \n",
      " 186  pref_line_y2_4         6771 non-null   object \n",
      " 187  pref_line_y2_5         6771 non-null   object \n",
      " 188  pref_line_y3_1         6771 non-null   object \n",
      " 189  pref_line_y3_2         6771 non-null   object \n",
      " 190  pref_line_y3_3         6771 non-null   object \n",
      " 191  pref_line_y3_4         6771 non-null   object \n",
      " 192  pref_line_y3_5         6771 non-null   object \n",
      " 193  pref_city_m3_1         6771 non-null   object \n",
      " 194  pref_city_m3_2         6771 non-null   object \n",
      " 195  pref_city_m3_3         6771 non-null   object \n",
      " 196  pref_city_m3_4         6771 non-null   object \n",
      " 197  pref_city_m3_5         6771 non-null   object \n",
      " 198  pref_city_m6_1         6771 non-null   object \n",
      " 199  pref_city_m6_2         6771 non-null   object \n",
      " 200  pref_city_m6_3         6771 non-null   object \n",
      " 201  pref_city_m6_4         6771 non-null   object \n",
      " 202  pref_city_m6_5         6771 non-null   object \n",
      " 203  pref_city_y1_1         6771 non-null   object \n",
      " 204  pref_city_y1_2         6771 non-null   object \n",
      " 205  pref_city_y1_3         6771 non-null   object \n",
      " 206  pref_city_y1_4         6771 non-null   object \n",
      " 207  pref_city_y1_5         6771 non-null   object \n",
      " 208  pref_city_y2_1         6771 non-null   object \n",
      " 209  pref_city_y2_2         6771 non-null   object \n",
      " 210  pref_city_y2_3         6771 non-null   object \n",
      " 211  pref_city_y2_4         6771 non-null   object \n",
      " 212  pref_city_y2_5         6771 non-null   object \n",
      " 213  pref_city_y3_1         6771 non-null   object \n",
      " 214  pref_city_y3_2         6771 non-null   object \n",
      " 215  pref_city_y3_3         6771 non-null   object \n",
      " 216  pref_city_y3_4         6771 non-null   object \n",
      " 217  pref_city_y3_5         6771 non-null   object \n",
      " 218  pref_month_m3_1        246 non-null    float64\n",
      " 219  pref_month_m3_2        239 non-null    float64\n",
      " 220  pref_month_m3_3        169 non-null    float64\n",
      " 221  pref_month_m3_4        166 non-null    float64\n",
      " 222  pref_month_m3_5        180 non-null    float64\n",
      " 223  pref_month_m6_1        403 non-null    float64\n",
      " 224  pref_month_m6_2        393 non-null    float64\n",
      " 225  pref_month_m6_3        281 non-null    float64\n",
      " 226  pref_month_m6_4        248 non-null    float64\n",
      " 227  pref_month_m6_5        262 non-null    float64\n",
      " 228  pref_month_y1_1        509 non-null    float64\n",
      " 229  pref_month_y1_2        499 non-null    float64\n",
      " 230  pref_month_y1_3        353 non-null    float64\n",
      " 231  pref_month_y1_4        289 non-null    float64\n",
      " 232  pref_month_y1_5        281 non-null    float64\n",
      " 233  pref_month_y2_1        658 non-null    float64\n",
      " 234  pref_month_y2_2        651 non-null    float64\n",
      " 235  pref_month_y2_3        437 non-null    float64\n",
      " 236  pref_month_y2_4        333 non-null    float64\n",
      " 237  pref_month_y2_5        285 non-null    float64\n",
      " 238  pref_month_y3_1        732 non-null    float64\n",
      " 239  pref_month_y3_2        723 non-null    float64\n",
      " 240  pref_month_y3_3        513 non-null    float64\n",
      " 241  pref_month_y3_4        377 non-null    float64\n",
      " 242  pref_month_y3_5        272 non-null    float64\n",
      " 243  workday_cnt_m3         0 non-null      float64\n",
      " 244  workday_cnt_m6         0 non-null      float64\n",
      " 245  workday_cnt_y1         0 non-null      float64\n",
      " 246  workday_cnt_y2         0 non-null      float64\n",
      " 247  workday_cnt_y3         0 non-null      float64\n",
      " 248  weekend_cnt_m3         0 non-null      float64\n",
      " 249  weekend_cnt_m6         0 non-null      float64\n",
      " 250  weekend_cnt_y1         0 non-null      float64\n",
      " 251  weekend_cnt_y2         0 non-null      float64\n",
      " 252  weekend_cnt_y3         0 non-null      float64\n",
      " 253  holiday_cnt_m3         0 non-null      float64\n",
      " 254  holiday_cnt_m6         0 non-null      float64\n",
      " 255  holiday_cnt_y1         0 non-null      float64\n",
      " 256  holiday_cnt_y2         0 non-null      float64\n",
      " 257  holiday_cnt_y3         0 non-null      float64\n",
      " 258  close_holiday_cnt_m3   0 non-null      float64\n",
      " 259  close_holiday_cnt_m6   0 non-null      float64\n",
      " 260  close_holiday_cnt_y1   0 non-null      float64\n",
      " 261  close_holiday_cnt_y2   2 non-null      float64\n",
      " 262  close_holiday_cnt_y3   22 non-null     float64\n",
      " 263  flt_cnt_m3             259 non-null    float64\n",
      " 264  flt_cnt_m6             407 non-null    float64\n",
      " 265  flt_cnt_y1             515 non-null    float64\n",
      " 266  flt_cnt_y2             2441 non-null   object \n",
      " 267  flt_cnt_y3             6771 non-null   object \n",
      " 268  recent_flt_day         6771 non-null   object \n",
      " 269  next_flt_day           85 non-null     float64\n",
      " 270  birth_interval_day     45 non-null     float64\n",
      " 271  dist_cnt_y1            460 non-null    float64\n",
      " 272  dist_cnt_y2            63 non-null     float64\n",
      " 273  dist_cnt_y3            830 non-null    float64\n",
      " 274  flt_nature_cnt_y1      461 non-null    float64\n",
      " 275  flt_nature_cnt_y2      60 non-null     float64\n",
      " 276  flt_nature_cnt_y3      810 non-null    float64\n",
      " 277  avg_dist_cnt_m3        346 non-null    float64\n",
      " 278  avg_dist_cnt_m6        462 non-null    float64\n",
      " 279  avg_dist_cnt_y1        557 non-null    float64\n",
      " 280  avg_dist_cnt_y2        687 non-null    float64\n",
      " 281  avg_dist_cnt_y3        685 non-null    float64\n",
      " 282  complain_valid_cnt_m3  1 non-null      float64\n",
      " 283  complain_valid_cnt_m6  2 non-null      float64\n",
      " 284  complain_valid_cnt_y1  3 non-null      float64\n",
      " 285  complain_valid_cnt_y2  4 non-null      float64\n",
      " 286  complain_valid_cnt_y3  2 non-null      float64\n",
      " 287  bag_cnt_m3             1 non-null      float64\n",
      " 288  bag_cnt_m6             2 non-null      float64\n",
      " 289  bag_cnt_y1             6 non-null      float64\n",
      " 290  bag_cnt_y2             13 non-null     float64\n",
      " 291  bag_cnt_y3             13 non-null     float64\n",
      " 292  cabin_upgrd_cnt_m3     18 non-null     float64\n",
      " 293  cabin_upgrd_cnt_m6     29 non-null     float64\n",
      " 294  cabin_upgrd_cnt_y1     35 non-null     float64\n",
      " 295  cabin_upgrd_cnt_y2     50 non-null     float64\n",
      " 296  cabin_upgrd_cnt_y3     44 non-null     float64\n",
      " 297  select_seat_cnt_m3     2 non-null      float64\n",
      " 298  select_seat_cnt_m6     3 non-null      float64\n",
      " 299  select_seat_cnt_y1     11 non-null     float64\n",
      " 300  select_seat_cnt_y2     40 non-null     float64\n",
      " 301  select_seat_cnt_y3     52 non-null     float64\n",
      " 302  dist_d_cnt_m3          102 non-null    float64\n",
      " 303  dist_d_cnt_m6          159 non-null    float64\n",
      " 304  dist_d_cnt_y1          216 non-null    float64\n",
      " 305  dist_d_cnt_y2          288 non-null    float64\n",
      " 306  dist_d_cnt_y3          330 non-null    float64\n",
      " 307  dist_i_cnt_m3          247 non-null    float64\n",
      " 308  dist_i_cnt_m6          401 non-null    float64\n",
      " 309  dist_i_cnt_y1          553 non-null    float64\n",
      " 310  dist_i_cnt_y2          726 non-null    float64\n",
      " 311  dist_i_cnt_y3          791 non-null    float64\n",
      " 312  dist_all_cnt_m3        267 non-null    float64\n",
      " 313  dist_all_cnt_m6        425 non-null    float64\n",
      " 314  dist_all_cnt_y1        568 non-null    float64\n",
      " 315  dist_all_cnt_y2        745 non-null    float64\n",
      " 316  dist_all_cnt_y3        786 non-null    float64\n",
      " 317  cabin_hd_cnt_m3        34 non-null     float64\n",
      " 318  cabin_hd_cnt_m6        53 non-null     float64\n",
      " 319  cabin_hd_cnt_y1        65 non-null     float64\n",
      " 320  cabin_hd_cnt_y2        73 non-null     float64\n",
      " 321  cabin_hd_cnt_y3        77 non-null     float64\n",
      " 322  cabin_hi_cnt_m3        65 non-null     float64\n",
      " 323  cabin_hi_cnt_m6        104 non-null    float64\n",
      " 324  cabin_hi_cnt_y1        126 non-null    float64\n",
      " 325  cabin_hi_cnt_y2        170 non-null    float64\n",
      " 326  cabin_hi_cnt_y3        191 non-null    float64\n",
      " 327  flt_leg_cnt_m3         267 non-null    float64\n",
      " 328  flt_leg_cnt_m6         425 non-null    float64\n",
      " 329  flt_leg_cnt_y1         568 non-null    float64\n",
      " 330  flt_leg_cnt_y2         748 non-null    float64\n",
      " 331  flt_leg_cnt_y3         813 non-null    float64\n",
      " 332  flt_leg_i_cnt_m3       247 non-null    float64\n",
      " 333  flt_leg_i_cnt_m6       401 non-null    float64\n",
      " 334  flt_leg_i_cnt_y1       553 non-null    float64\n",
      " 335  flt_leg_i_cnt_y2       723 non-null    float64\n",
      " 336  flt_leg_i_cnt_y3       767 non-null    float64\n",
      " 337  flt_leg_d_cnt_m3       102 non-null    float64\n",
      " 338  flt_leg_d_cnt_m6       159 non-null    float64\n",
      " 339  flt_leg_d_cnt_y1       216 non-null    float64\n",
      " 340  flt_leg_d_cnt_y2       1235 non-null   object \n",
      " 341  flt_leg_d_cnt_y3       6771 non-null   object \n",
      " 342  flt_cancel_cnt_m3      0 non-null      float64\n",
      " 343  flt_cancel_cnt_m6      0 non-null      float64\n",
      " 344  flt_cancel_cnt_y1      0 non-null      float64\n",
      " 345  flt_cancel_cnt_y2      0 non-null      float64\n",
      " 346  flt_cancel_cnt_y3      7 non-null      float64\n",
      " 347  flt_delay_cnt_m3       61 non-null     float64\n",
      " 348  flt_delay_cnt_m6       136 non-null    float64\n",
      " 349  flt_delay_cnt_y1       228 non-null    float64\n",
      " 350  flt_delay_cnt_y2       381 non-null    float64\n",
      " 351  flt_delay_cnt_y3       469 non-null    float64\n",
      " 352  flt_delay_time_m3      336 non-null    float64\n",
      " 353  flt_delay_time_m6      330 non-null    float64\n",
      " 354  flt_delay_time_y1      325 non-null    float64\n",
      " 355  flt_delay_time_y2      292 non-null    float64\n",
      " 356  flt_delay_time_y3      232 non-null    float64\n",
      " 357  rest_cnt_m3            0 non-null      float64\n",
      " 358  rest_cnt_m6            0 non-null      float64\n",
      " 359  rest_cnt_y1            0 non-null      float64\n",
      " 360  rest_cnt_y2            2048 non-null   object \n",
      " 361  rest_cnt_y3            6771 non-null   object \n",
      " 362  pref_orig_city_m3      6771 non-null   object \n",
      " 363  pref_orig_city_m6      6771 non-null   object \n",
      " 364  pref_orig_city_y1      6771 non-null   object \n",
      " 365  pref_orig_city_y2      6771 non-null   object \n",
      " 366  pref_orig_city_y3      6771 non-null   object \n",
      " 367  pref_dest_city_m3      6771 non-null   object \n",
      " 368  pref_dest_city_m6      6771 non-null   object \n",
      " 369  pref_dest_city_y1      6771 non-null   object \n",
      " 370  pref_dest_city_y2      6771 non-null   object \n",
      " 371  pref_dest_city_y3      6771 non-null   object \n",
      " 372  cabin_fall_cnt_m3      0 non-null      float64\n",
      " 373  cabin_fall_cnt_m6      0 non-null      float64\n",
      " 374  cabin_fall_cnt_y1      0 non-null      float64\n",
      " 375  cabin_fall_cnt_y2      3 non-null      float64\n",
      " 376  cabin_fall_cnt_y3      28 non-null     float64\n",
      " 377  flt_bag_cnt_m3         224 non-null    float64\n",
      " 378  flt_bag_cnt_m6         352 non-null    float64\n",
      " 379  flt_bag_cnt_y1         485 non-null    float64\n",
      " 380  flt_bag_cnt_y2         674 non-null    float64\n",
      " 381  flt_bag_cnt_y3         709 non-null    float64\n",
      " 382  complain_cnt_m3        8 non-null      float64\n",
      " 383  complain_cnt_m6        11 non-null     float64\n",
      " 384  complain_cnt_y1        12 non-null     float64\n",
      " 385  complain_cnt_y2        14 non-null     float64\n",
      " 386  complain_cnt_y3        11 non-null     float64\n",
      " 387  noshow_rate_m3         3 non-null      float64\n",
      " 388  noshow_rate_m6         5 non-null      float64\n",
      " 389  noshow_rate_y1         7 non-null      float64\n",
      " 390  noshow_rate_y2         17 non-null     float64\n",
      " 391  noshow_rate_y3         73 non-null     float64\n",
      " 392  tkt_3y_amt             752 non-null    float64\n",
      " 393  tkt_avg_amt            4 non-null      float64\n",
      " 394  tkt_d_amt_m3           94 non-null     float64\n",
      " 395  tkt_d_amt_m6           145 non-null    float64\n",
      " 396  tkt_d_amt_y1           204 non-null    float64\n",
      " 397  tkt_d_amt_y2           274 non-null    float64\n",
      " 398  tkt_d_amt_y3           304 non-null    float64\n",
      " 399  tkt_i_amt_m3           233 non-null    float64\n",
      " 400  tkt_i_amt_m6           375 non-null    float64\n",
      " 401  tkt_i_amt_y1           488 non-null    float64\n",
      " 402  tkt_i_amt_y2           625 non-null    float64\n",
      " 403  tkt_i_amt_y3           669 non-null    float64\n",
      " 404  tkt_all_amt_m3         249 non-null    float64\n",
      " 405  tkt_all_amt_m6         392 non-null    float64\n",
      " 406  tkt_all_amt_y1         505 non-null    float64\n",
      " 407  tkt_all_amt_y2         645 non-null    float64\n",
      " 408  tkt_all_amt_y3         689 non-null    float64\n",
      " 409  tkt_avg_amt_m3         249 non-null    float64\n",
      " 410  tkt_avg_amt_m6         392 non-null    float64\n",
      " 411  tkt_avg_amt_y1         505 non-null    float64\n",
      " 412  tkt_avg_amt_y2         643 non-null    float64\n",
      " 413  tkt_avg_amt_y3         669 non-null    float64\n",
      " 414  tkt_avg_disc_m3        0 non-null      float64\n",
      " 415  tkt_avg_disc_m6        0 non-null      float64\n",
      " 416  tkt_avg_disc_y1        0 non-null      float64\n",
      " 417  tkt_avg_disc_y2        0 non-null      float64\n",
      " 418  tkt_avg_disc_y3        2 non-null      float64\n",
      " 419  tkt_return_cnt_m3      8 non-null      float64\n",
      " 420  tkt_return_cnt_m6      22 non-null     float64\n",
      " 421  tkt_return_cnt_y1      48 non-null     float64\n",
      " 422  tkt_return_cnt_y2      55 non-null     float64\n",
      " 423  tkt_return_cnt_y3      50 non-null     float64\n",
      " 424  tkt_book_cnt_m3        39 non-null     float64\n",
      " 425  tkt_book_cnt_m6        111 non-null    float64\n",
      " 426  tkt_book_cnt_y1        188 non-null    float64\n",
      " 427  tkt_book_cnt_y2        213 non-null    float64\n",
      " 428  tkt_book_cnt_y3        184 non-null    float64\n",
      " 429  tkt_return_all_cnt_m3  10 non-null     float64\n",
      " 430  tkt_return_all_cnt_m6  19 non-null     float64\n",
      " 431  tkt_return_all_cnt_y1  35 non-null     float64\n",
      " 432  tkt_return_all_cnt_y2  40 non-null     float64\n",
      " 433  tkt_return_all_cnt_y3  29 non-null     float64\n",
      " 434  tkt_avg_interval_m3    23 non-null     float64\n",
      " 435  tkt_avg_interval_m6    43 non-null     float64\n",
      " 436  tkt_avg_interval_y1    62 non-null     float64\n",
      " 437  tkt_avg_interval_y2    1095 non-null   object \n",
      " 438  tkt_avg_interval_y3    6771 non-null   object \n",
      " 439  pit_all_amt            181 non-null    float64\n",
      " 440  pit_out_amt            18 non-null     float64\n",
      " 441  pit_accu_non_cnt       83 non-null     float64\n",
      " 442  pit_accu_air_cnt       231 non-null    float64\n",
      " 443  pit_accu_air_amt       189 non-null    float64\n",
      " 444  pit_accu_non_amt       70 non-null     float64\n",
      " 445  pit_now_cons_amt       211 non-null    float64\n",
      " 446  pit_next_level_dist    160 non-null    float64\n",
      " 447  pit_next_level_leg     45 non-null     float64\n",
      " 448  mdl_mcv                668 non-null    float64\n",
      " 449  mdl_lost_idx           23 non-null     float64\n",
      " 450  mdl_influence          154 non-null    float64\n",
      " 451  mdl_loyal              14 non-null     float64\n",
      " 452  pit_accu_amt_m3        54 non-null     float64\n",
      " 453  pit_accu_amt_m6        123 non-null    float64\n",
      " 454  pit_accu_amt_y1        171 non-null    float64\n",
      " 455  pit_accu_amt_y2        207 non-null    float64\n",
      " 456  pit_accu_amt_y3        176 non-null    float64\n",
      " 457  pit_cons_amt_m3        16 non-null     float64\n",
      " 458  pit_cons_amt_m6        24 non-null     float64\n",
      " 459  pit_cons_amt_y1        46 non-null     float64\n",
      " 460  pit_cons_amt_y2        78 non-null     float64\n",
      " 461  pit_cons_amt_y3        58 non-null     float64\n",
      " 462  pit_avg_accu_amt_m3    33 non-null     float64\n",
      " 463  pit_avg_accu_amt_m6    108 non-null    float64\n",
      " 464  pit_avg_accu_amt_y1    144 non-null    float64\n",
      " 465  pit_avg_accu_amt_y2    172 non-null    float64\n",
      " 466  pit_avg_accu_amt_y3    149 non-null    float64\n",
      " 467  pit_avg_cons_amt_m3    16 non-null     float64\n",
      " 468  pit_avg_cons_amt_m6    24 non-null     float64\n",
      " 469  pit_avg_cons_amt_y1    46 non-null     float64\n",
      " 470  pit_avg_cons_amt_y2    79 non-null     float64\n",
      " 471  pit_avg_cons_amt_y3    62 non-null     float64\n",
      " 472  pit_accu_cnt_m3        18 non-null     float64\n",
      " 473  pit_accu_cnt_m6        0 non-null      float64\n",
      " 474  pit_accu_cnt_y1        0 non-null      float64\n",
      " 475  pit_accu_cnt_y2        0 non-null      float64\n",
      " 476  pit_accu_cnt_y3        3 non-null      float64\n",
      " 477  pit_cons_cnt_m3        16 non-null     float64\n",
      " 478  pit_cons_cnt_m6        24 non-null     float64\n",
      " 479  pit_cons_cnt_y1        46 non-null     float64\n",
      " 480  pit_cons_cnt_y2        78 non-null     float64\n",
      " 481  pit_cons_cnt_y3        57 non-null     float64\n",
      " 482  pit_add_air_amt_m3     31 non-null     float64\n",
      " 483  pit_add_air_amt_m6     108 non-null    float64\n",
      " 484  pit_add_air_amt_y1     144 non-null    float64\n",
      " 485  pit_add_air_amt_y2     172 non-null    float64\n",
      " 486  pit_add_air_amt_y3     146 non-null    float64\n",
      " 487  pit_add_non_amt_m3     5 non-null      float64\n",
      " 488  pit_add_non_amt_m6     17 non-null     float64\n",
      " 489  pit_add_non_amt_y1     32 non-null     float64\n",
      " 490  pit_add_non_amt_y2     46 non-null     float64\n",
      " 491  pit_add_non_amt_y3     39 non-null     float64\n",
      " 492  pit_add_buy_amt_m3     0 non-null      float64\n",
      " 493  pit_add_buy_amt_m6     0 non-null      float64\n",
      " 494  pit_add_buy_amt_y1     1 non-null      float64\n",
      " 495  pit_add_buy_amt_y2     1 non-null      float64\n",
      " 496  pit_add_buy_amt_y3     1 non-null      float64\n",
      " 497  pit_add_mnl_amt_m3     0 non-null      float64\n",
      " 498  pit_add_mnl_amt_m6     0 non-null      float64\n",
      " 499  pit_add_mnl_amt_y1     0 non-null      float64\n",
      " 500  pit_add_mnl_amt_y2     0 non-null      float64\n",
      " 501  pit_add_mnl_amt_y3     0 non-null      float64\n",
      " 502  pit_add_ech_amt_m3     0 non-null      float64\n",
      " 503  pit_add_ech_amt_m6     0 non-null      float64\n",
      " 504  pit_add_ech_amt_y1     0 non-null      float64\n",
      " 505  pit_add_ech_amt_y2     0 non-null      float64\n",
      " 506  pit_add_ech_amt_y3     0 non-null      float64\n",
      " 507  pit_add_oth_amt_m3     0 non-null      float64\n",
      " 508  pit_add_oth_amt_m6     0 non-null      float64\n",
      " 509  pit_add_oth_amt_y1     0 non-null      float64\n",
      " 510  pit_add_oth_amt_y2     0 non-null      float64\n",
      " 511  pit_add_oth_amt_y3     0 non-null      float64\n",
      " 512  pit_des_tkt_amt_m3     0 non-null      float64\n",
      " 513  pit_des_tkt_amt_m6     0 non-null      float64\n",
      " 514  pit_des_tkt_amt_y1     0 non-null      float64\n",
      " 515  pit_des_tkt_amt_y2     0 non-null      float64\n",
      " 516  pit_des_tkt_amt_y3     0 non-null      float64\n",
      " 517  pit_des_bag_amt_m3     0 non-null      float64\n",
      " 518  pit_des_bag_amt_m6     0 non-null      float64\n",
      " 519  pit_des_bag_amt_y1     0 non-null      float64\n",
      " 520  pit_des_bag_amt_y2     0 non-null      float64\n",
      " 521  pit_des_bag_amt_y3     0 non-null      float64\n",
      " 522  pit_des_upg_amt_m3     5 non-null      float64\n",
      " 523  pit_des_upg_amt_m6     9 non-null      float64\n",
      " 524  pit_des_upg_amt_y1     13 non-null     float64\n",
      " 525  pit_des_upg_amt_y2     13 non-null     float64\n",
      " 526  pit_des_upg_amt_y3     6 non-null      float64\n",
      " 527  pit_des_mall_amt_m3    0 non-null      float64\n",
      " 528  pit_des_mall_amt_m6    3 non-null      float64\n",
      " 529  pit_des_mall_amt_y1    7 non-null      float64\n",
      " 530  pit_des_mall_amt_y2    9 non-null      float64\n",
      " 531  pit_des_mall_amt_y3    7 non-null      float64\n",
      " 532  pit_des_selt_amt_m3    0 non-null      float64\n",
      " 533  pit_des_selt_amt_m6    0 non-null      float64\n",
      " 534  pit_des_selt_amt_y1    0 non-null      float64\n",
      " 535  pit_des_selt_amt_y2    0 non-null      float64\n",
      " 536  pit_des_selt_amt_y3    1 non-null      float64\n",
      " 537  pit_des_out_amt_m3     1 non-null      float64\n",
      " 538  pit_des_out_amt_m6     1 non-null      float64\n",
      " 539  pit_des_out_amt_y1     13 non-null     float64\n",
      " 540  pit_des_out_amt_y2     47 non-null     float64\n",
      " 541  pit_des_out_amt_y3     31 non-null     float64\n",
      " 542  pit_des_oth_amt_m3     0 non-null      float64\n",
      " 543  pit_des_oth_amt_m6     0 non-null      float64\n",
      " 544  pit_des_oth_amt_y1     0 non-null      float64\n",
      " 545  pit_des_oth_amt_y2     1 non-null      float64\n",
      " 546  pit_des_oth_amt_y3     6 non-null      float64\n",
      " 547  pit_add_air_cnt_m3     31 non-null     float64\n",
      " 548  pit_add_air_cnt_m6     108 non-null    float64\n",
      " 549  pit_add_air_cnt_y1     144 non-null    float64\n",
      " 550  pit_add_air_cnt_y2     172 non-null    float64\n",
      " 551  pit_add_air_cnt_y3     149 non-null    float64\n",
      " 552  pit_add_non_cnt_m3     8 non-null      float64\n",
      " 553  pit_add_non_cnt_m6     15 non-null     float64\n",
      " 554  pit_add_non_cnt_y1     24 non-null     float64\n",
      " 555  pit_add_non_cnt_y2     34 non-null     float64\n",
      " 556  pit_add_non_cnt_y3     28 non-null     float64\n",
      " 557  pit_add_buy_cnt_m3     0 non-null      float64\n",
      " 558  pit_add_buy_cnt_m6     0 non-null      float64\n",
      " 559  pit_add_buy_cnt_y1     1 non-null      float64\n",
      " 560  pit_add_buy_cnt_y2     1 non-null      float64\n",
      " 561  pit_add_buy_cnt_y3     1 non-null      float64\n",
      " 562  pit_add_mnl_cnt_m3     0 non-null      float64\n",
      " 563  pit_add_mnl_cnt_m6     0 non-null      float64\n",
      " 564  pit_add_mnl_cnt_y1     0 non-null      float64\n",
      " 565  pit_add_mnl_cnt_y2     0 non-null      float64\n",
      " 566  pit_add_mnl_cnt_y3     0 non-null      float64\n",
      " 567  pit_add_ech_cnt_m3     0 non-null      float64\n",
      " 568  pit_add_ech_cnt_m6     0 non-null      float64\n",
      " 569  pit_add_ech_cnt_y1     0 non-null      float64\n",
      " 570  pit_add_ech_cnt_y2     0 non-null      float64\n",
      " 571  pit_add_ech_cnt_y3     0 non-null      float64\n",
      " 572  pit_add_oth_cnt_m3     0 non-null      float64\n",
      " 573  pit_add_oth_cnt_m6     0 non-null      float64\n",
      " 574  pit_add_oth_cnt_y1     0 non-null      float64\n",
      " 575  pit_add_oth_cnt_y2     0 non-null      float64\n",
      " 576  pit_add_oth_cnt_y3     0 non-null      float64\n",
      " 577  pit_des_tkt_cnt_m3     0 non-null      float64\n",
      " 578  pit_des_tkt_cnt_m6     0 non-null      float64\n",
      " 579  pit_des_tkt_cnt_y1     0 non-null      float64\n",
      " 580  pit_des_tkt_cnt_y2     0 non-null      float64\n",
      " 581  pit_des_tkt_cnt_y3     0 non-null      float64\n",
      " 582  pit_des_bag_cnt_m3     0 non-null      float64\n",
      " 583  pit_des_bag_cnt_m6     0 non-null      float64\n",
      " 584  pit_des_bag_cnt_y1     0 non-null      float64\n",
      " 585  pit_des_bag_cnt_y2     0 non-null      float64\n",
      " 586  pit_des_bag_cnt_y3     0 non-null      float64\n",
      " 587  pit_des_upg_cnt_m3     5 non-null      float64\n",
      " 588  pit_des_upg_cnt_m6     9 non-null      float64\n",
      " 589  pit_des_upg_cnt_y1     13 non-null     float64\n",
      " 590  pit_des_upg_cnt_y2     13 non-null     float64\n",
      " 591  pit_des_upg_cnt_y3     6 non-null      float64\n",
      " 592  pit_des_mall_cnt_m3    0 non-null      float64\n",
      " 593  pit_des_mall_cnt_m6    3 non-null      float64\n",
      " 594  pit_des_mall_cnt_y1    5 non-null      float64\n",
      " 595  pit_des_mall_cnt_y2    8 non-null      float64\n",
      " 596  pit_des_mall_cnt_y3    5 non-null      float64\n",
      " 597  pit_des_selt_cnt_m3    0 non-null      float64\n",
      " 598  pit_des_selt_cnt_m6    0 non-null      float64\n",
      " 599  pit_des_selt_cnt_y1    0 non-null      float64\n",
      " 600  pit_des_selt_cnt_y2    0 non-null      float64\n",
      " 601  pit_des_selt_cnt_y3    0 non-null      float64\n",
      " 602  pit_des_out_cnt_m3     0 non-null      float64\n",
      " 603  pit_des_out_cnt_m6     1 non-null      float64\n",
      " 604  pit_des_out_cnt_y1     5 non-null      float64\n",
      " 605  pit_des_out_cnt_y2     28 non-null     float64\n",
      " 606  pit_des_out_cnt_y3     29 non-null     float64\n",
      " 607  pit_des_oth_cnt_m3     0 non-null      float64\n",
      " 608  pit_des_oth_cnt_m6     0 non-null      float64\n",
      " 609  pit_des_oth_cnt_y1     0 non-null      float64\n",
      " 610  pit_des_oth_cnt_y2     2 non-null      float64\n",
      " 611  pit_des_oth_cnt_y3     14 non-null     float64\n",
      " 612  pit_avg_amt_m3         53 non-null     float64\n",
      " 613  pit_avg_amt_m6         123 non-null    float64\n",
      " 614  pit_avg_amt_y1         171 non-null    float64\n",
      " 615  pit_avg_amt_y2         207 non-null    float64\n",
      " 616  pit_avg_amt_y3         177 non-null    float64\n",
      " 617  pit_avg_interval_m3    18 non-null     float64\n",
      " 618  pit_avg_interval_m6    70 non-null     float64\n",
      " 619  pit_avg_interval_y1    119 non-null    float64\n",
      " 620  pit_avg_interval_y2    150 non-null    float64\n",
      " 621  pit_avg_interval_y3    130 non-null    float64\n",
      " 622  pit_ech_avg_amt_m3     15 non-null     float64\n",
      " 623  pit_ech_avg_amt_m6     28 non-null     float64\n",
      " 624  pit_ech_avg_amt_y1     38 non-null     float64\n",
      " 625  pit_ech_avg_amt_y2     41 non-null     float64\n",
      " 626  pit_ech_avg_amt_y3     28 non-null     float64\n",
      " 627  pit_out_avg_amt_m3     0 non-null      float64\n",
      " 628  pit_out_avg_amt_m6     1 non-null      float64\n",
      " 629  pit_out_avg_amt_y1     5 non-null      float64\n",
      " 630  pit_out_avg_amt_y2     30 non-null     float64\n",
      " 631  pit_out_avg_amt_y3     43 non-null     float64\n",
      " 632  pit_income_cnt_m3      54 non-null     float64\n",
      " 633  pit_income_cnt_m6      123 non-null    float64\n",
      " 634  pit_income_cnt_y1      171 non-null    float64\n",
      " 635  pit_income_cnt_y2      207 non-null    float64\n",
      " 636  pit_income_cnt_y3      174 non-null    float64\n",
      " 637  pit_pay_cnt_m3         15 non-null     float64\n",
      " 638  pit_pay_cnt_m6         29 non-null     float64\n",
      " 639  pit_pay_cnt_y1         40 non-null     float64\n",
      " 640  pit_pay_cnt_y2         55 non-null     float64\n",
      " 641  pit_pay_cnt_y3         51 non-null     float64\n",
      " 642  pit_income_avg_amt_m3  33 non-null     float64\n",
      " 643  pit_income_avg_amt_m6  108 non-null    float64\n",
      " 644  pit_income_avg_amt_y1  144 non-null    float64\n",
      " 645  pit_income_avg_amt_y2  172 non-null    float64\n",
      " 646  pit_income_avg_amt_y3  149 non-null    float64\n",
      " 647  pit_pay_avg_amt_m3     16 non-null     float64\n",
      " 648  pit_pay_avg_amt_m6     24 non-null     float64\n",
      " 649  pit_pay_avg_amt_y1     46 non-null     float64\n",
      " 650  pit_pay_avg_amt_y2     2084 non-null   object \n",
      " 651  pit_pay_avg_amt_y3     4733 non-null   object \n",
      " 652  pit_add_chnl_m3        6771 non-null   object \n",
      " 653  pit_add_chnl_m6        6771 non-null   object \n",
      " 654  pit_add_chnl_y1        6771 non-null   object \n",
      " 655  pit_add_chnl_y2        6765 non-null   object \n",
      " 656  pit_add_chnl_y3        6675 non-null   object \n",
      "dtypes: float64(508), object(149)\n",
      "memory usage: 33.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test1 = test.replace(0,np.nan)\n",
    "test1.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保留除了object和datetime类型的之外的特征因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23432 entries, 0 to 23431\n",
      "Data columns (total 527 columns):\n",
      " #    Column                 Non-Null Count  Dtype  \n",
      "---   ------                 --------------  -----  \n",
      " 0    seg_route_to           23432 non-null  int64  \n",
      " 1    seg_flight             23432 non-null  int64  \n",
      " 2    seg_cabin              23432 non-null  float64\n",
      " 3    pax_fcny               23432 non-null  float64\n",
      " 4    pax_tax                23432 non-null  float64\n",
      " 5    emd_lable2             23432 non-null  float64\n",
      " 6    ffp_nbr                23432 non-null  float64\n",
      " 7    often_city             23432 non-null  float64\n",
      " 8    cabin_hf_cnt_m3        23432 non-null  float64\n",
      " 9    cabin_hf_cnt_m6        23432 non-null  float64\n",
      " 10   cabin_hf_cnt_y1        23432 non-null  float64\n",
      " 11   cabin_hf_cnt_y2        23432 non-null  float64\n",
      " 12   cabin_hf_cnt_y3        23432 non-null  float64\n",
      " 13   cabin_f_cnt_m3         23432 non-null  float64\n",
      " 14   cabin_f_cnt_m6         23432 non-null  float64\n",
      " 15   cabin_f_cnt_y1         23432 non-null  float64\n",
      " 16   cabin_f_cnt_y2         23432 non-null  float64\n",
      " 17   cabin_f_cnt_y3         23432 non-null  float64\n",
      " 18   cabin_hy_cnt_m3        23432 non-null  float64\n",
      " 19   cabin_hy_cnt_m6        23432 non-null  float64\n",
      " 20   cabin_hy_cnt_y1        23432 non-null  float64\n",
      " 21   cabin_hy_cnt_y2        23432 non-null  float64\n",
      " 22   cabin_hy_cnt_y3        23432 non-null  float64\n",
      " 23   cabin_y_cnt_m3         23432 non-null  float64\n",
      " 24   cabin_y_cnt_m6         23432 non-null  float64\n",
      " 25   cabin_y_cnt_y1         23432 non-null  float64\n",
      " 26   cabin_y_cnt_y2         23432 non-null  float64\n",
      " 27   cabin_y_cnt_y3         23432 non-null  float64\n",
      " 28   cabin_c_cnt_m3         23432 non-null  float64\n",
      " 29   cabin_c_cnt_m6         23432 non-null  float64\n",
      " 30   cabin_c_cnt_y1         23432 non-null  float64\n",
      " 31   cabin_c_cnt_y2         23432 non-null  float64\n",
      " 32   cabin_c_cnt_y3         23432 non-null  float64\n",
      " 33   seat_window_cnt_m3     23432 non-null  float64\n",
      " 34   seat_window_cnt_m6     23432 non-null  float64\n",
      " 35   seat_window_cnt_y1     23432 non-null  float64\n",
      " 36   seat_window_cnt_y2     23432 non-null  float64\n",
      " 37   seat_window_cnt_y3     23432 non-null  float64\n",
      " 38   seat_walkway_cnt_m3    23432 non-null  float64\n",
      " 39   seat_walkway_cnt_m6    23432 non-null  float64\n",
      " 40   seat_walkway_cnt_y1    23432 non-null  float64\n",
      " 41   seat_walkway_cnt_y2    23432 non-null  float64\n",
      " 42   seat_walkway_cnt_y3    23432 non-null  float64\n",
      " 43   seat_middle_cnt_m3     23432 non-null  float64\n",
      " 44   seat_middle_cnt_m6     23432 non-null  float64\n",
      " 45   seat_middle_cnt_y1     23432 non-null  float64\n",
      " 46   seat_middle_cnt_y2     23432 non-null  float64\n",
      " 47   seat_middle_cnt_y3     23432 non-null  float64\n",
      " 48   seat_safe_cnt_m3       23432 non-null  float64\n",
      " 49   seat_safe_cnt_m6       23432 non-null  float64\n",
      " 50   seat_safe_cnt_y1       23432 non-null  float64\n",
      " 51   seat_safe_cnt_y2       23432 non-null  float64\n",
      " 52   seat_safe_cnt_y3       23432 non-null  float64\n",
      " 53   prebuy_d_cnt_m3_d3     23432 non-null  float64\n",
      " 54   prebuy_d_cnt_m3_d7     23432 non-null  float64\n",
      " 55   prebuy_d_cnt_m3_d14    23432 non-null  float64\n",
      " 56   prebuy_d_cnt_m3_d30    23432 non-null  float64\n",
      " 57   prebuy_d_cnt_m3_d99    23432 non-null  float64\n",
      " 58   prebuy_d_cnt_m6_d3     23432 non-null  float64\n",
      " 59   prebuy_d_cnt_m6_d7     23432 non-null  float64\n",
      " 60   prebuy_d_cnt_m6_d14    23432 non-null  float64\n",
      " 61   prebuy_d_cnt_m6_d30    23432 non-null  float64\n",
      " 62   prebuy_d_cnt_m6_d99    23432 non-null  float64\n",
      " 63   prebuy_d_cnt_y1_d3     23432 non-null  float64\n",
      " 64   prebuy_d_cnt_y1_d7     23432 non-null  float64\n",
      " 65   prebuy_d_cnt_y1_d14    23432 non-null  float64\n",
      " 66   prebuy_d_cnt_y1_d30    23432 non-null  float64\n",
      " 67   prebuy_d_cnt_y1_d99    23432 non-null  float64\n",
      " 68   prebuy_d_cnt_y2_d3     23432 non-null  float64\n",
      " 69   prebuy_d_cnt_y2_d7     23432 non-null  float64\n",
      " 70   prebuy_d_cnt_y2_d14    23432 non-null  float64\n",
      " 71   prebuy_d_cnt_y2_d30    23432 non-null  float64\n",
      " 72   prebuy_d_cnt_y2_d99    23432 non-null  float64\n",
      " 73   prebuy_d_cnt_y3_d3     23432 non-null  float64\n",
      " 74   prebuy_d_cnt_y3_d7     23432 non-null  float64\n",
      " 75   prebuy_d_cnt_y3_d14    23432 non-null  float64\n",
      " 76   prebuy_d_cnt_y3_d30    23432 non-null  float64\n",
      " 77   prebuy_d_cnt_y3_d99    23432 non-null  float64\n",
      " 78   prebuy_i_cnt_m3_d3     23432 non-null  float64\n",
      " 79   prebuy_i_cnt_m3_d7     23432 non-null  float64\n",
      " 80   prebuy_i_cnt_m3_d14    23432 non-null  float64\n",
      " 81   prebuy_i_cnt_m3_d30    23432 non-null  float64\n",
      " 82   prebuy_i_cnt_m3_d99    23432 non-null  float64\n",
      " 83   prebuy_i_cnt_m6_d3     23432 non-null  float64\n",
      " 84   prebuy_i_cnt_m6_d7     23432 non-null  float64\n",
      " 85   prebuy_i_cnt_m6_d14    23432 non-null  float64\n",
      " 86   prebuy_i_cnt_m6_d30    23432 non-null  float64\n",
      " 87   prebuy_i_cnt_m6_d99    23432 non-null  float64\n",
      " 88   prebuy_i_cnt_y1_d3     23432 non-null  float64\n",
      " 89   prebuy_i_cnt_y1_d7     23432 non-null  float64\n",
      " 90   prebuy_i_cnt_y1_d14    23432 non-null  float64\n",
      " 91   prebuy_i_cnt_y1_d30    23432 non-null  float64\n",
      " 92   prebuy_i_cnt_y1_d99    23432 non-null  float64\n",
      " 93   prebuy_i_cnt_y2_d3     23432 non-null  float64\n",
      " 94   prebuy_i_cnt_y2_d7     23432 non-null  float64\n",
      " 95   prebuy_i_cnt_y2_d14    23432 non-null  float64\n",
      " 96   prebuy_i_cnt_y2_d30    23432 non-null  float64\n",
      " 97   prebuy_i_cnt_y2_d99    23432 non-null  float64\n",
      " 98   prebuy_i_cnt_y3_d3     23432 non-null  float64\n",
      " 99   prebuy_i_cnt_y3_d7     23432 non-null  float64\n",
      " 100  prebuy_i_cnt_y3_d14    23432 non-null  float64\n",
      " 101  prebuy_i_cnt_y3_d30    23432 non-null  float64\n",
      " 102  prebuy_i_cnt_y3_d99    23432 non-null  float64\n",
      " 103  pref_month_m3_1        23432 non-null  float64\n",
      " 104  pref_month_m3_2        23432 non-null  float64\n",
      " 105  pref_month_m3_3        23432 non-null  float64\n",
      " 106  pref_month_m3_4        23432 non-null  float64\n",
      " 107  pref_month_m3_5        23432 non-null  float64\n",
      " 108  pref_month_m6_1        23432 non-null  float64\n",
      " 109  pref_month_m6_2        23432 non-null  float64\n",
      " 110  pref_month_m6_3        23432 non-null  float64\n",
      " 111  pref_month_m6_4        23432 non-null  float64\n",
      " 112  pref_month_m6_5        23432 non-null  float64\n",
      " 113  pref_month_y1_1        23432 non-null  float64\n",
      " 114  pref_month_y1_2        23432 non-null  float64\n",
      " 115  pref_month_y1_3        23432 non-null  float64\n",
      " 116  pref_month_y1_4        23432 non-null  float64\n",
      " 117  pref_month_y1_5        23432 non-null  float64\n",
      " 118  pref_month_y2_1        23432 non-null  float64\n",
      " 119  pref_month_y2_2        23432 non-null  float64\n",
      " 120  pref_month_y2_3        23432 non-null  float64\n",
      " 121  pref_month_y2_4        23432 non-null  float64\n",
      " 122  pref_month_y2_5        23432 non-null  float64\n",
      " 123  pref_month_y3_1        23432 non-null  float64\n",
      " 124  pref_month_y3_2        23432 non-null  float64\n",
      " 125  pref_month_y3_3        23432 non-null  float64\n",
      " 126  pref_month_y3_4        23432 non-null  float64\n",
      " 127  pref_month_y3_5        23432 non-null  float64\n",
      " 128  workday_cnt_m3         23432 non-null  float64\n",
      " 129  workday_cnt_m6         23432 non-null  float64\n",
      " 130  workday_cnt_y1         23432 non-null  float64\n",
      " 131  workday_cnt_y2         23432 non-null  float64\n",
      " 132  workday_cnt_y3         23432 non-null  float64\n",
      " 133  weekend_cnt_m3         23432 non-null  float64\n",
      " 134  weekend_cnt_m6         23432 non-null  float64\n",
      " 135  weekend_cnt_y1         23432 non-null  float64\n",
      " 136  weekend_cnt_y2         23432 non-null  float64\n",
      " 137  weekend_cnt_y3         23432 non-null  float64\n",
      " 138  holiday_cnt_m3         23432 non-null  float64\n",
      " 139  holiday_cnt_m6         23432 non-null  float64\n",
      " 140  holiday_cnt_y1         23432 non-null  float64\n",
      " 141  holiday_cnt_y2         23432 non-null  float64\n",
      " 142  holiday_cnt_y3         23432 non-null  float64\n",
      " 143  close_holiday_cnt_m3   23432 non-null  float64\n",
      " 144  close_holiday_cnt_m6   23432 non-null  float64\n",
      " 145  close_holiday_cnt_y1   23432 non-null  float64\n",
      " 146  close_holiday_cnt_y2   23432 non-null  float64\n",
      " 147  close_holiday_cnt_y3   23432 non-null  float64\n",
      " 148  flt_cnt_m3             23432 non-null  float64\n",
      " 149  flt_cnt_m6             23432 non-null  float64\n",
      " 150  flt_cnt_y1             23432 non-null  float64\n",
      " 151  flt_cnt_y2             23432 non-null  float64\n",
      " 152  flt_cnt_y3             23432 non-null  float64\n",
      " 153  next_flt_day           23432 non-null  float64\n",
      " 154  birth_interval_day     23432 non-null  float64\n",
      " 155  dist_cnt_y1            23432 non-null  float64\n",
      " 156  dist_cnt_y2            23432 non-null  float64\n",
      " 157  dist_cnt_y3            23432 non-null  float64\n",
      " 158  flt_nature_cnt_y1      23432 non-null  float64\n",
      " 159  flt_nature_cnt_y2      23432 non-null  float64\n",
      " 160  flt_nature_cnt_y3      23432 non-null  float64\n",
      " 161  avg_dist_cnt_m3        23432 non-null  float64\n",
      " 162  avg_dist_cnt_m6        23432 non-null  float64\n",
      " 163  avg_dist_cnt_y1        23432 non-null  float64\n",
      " 164  avg_dist_cnt_y2        23432 non-null  float64\n",
      " 165  avg_dist_cnt_y3        23432 non-null  float64\n",
      " 166  complain_valid_cnt_m3  23432 non-null  float64\n",
      " 167  complain_valid_cnt_m6  23432 non-null  float64\n",
      " 168  complain_valid_cnt_y1  23432 non-null  float64\n",
      " 169  complain_valid_cnt_y2  23432 non-null  float64\n",
      " 170  complain_valid_cnt_y3  23432 non-null  float64\n",
      " 171  bag_cnt_m3             23432 non-null  float64\n",
      " 172  bag_cnt_m6             23432 non-null  float64\n",
      " 173  bag_cnt_y1             23432 non-null  float64\n",
      " 174  bag_cnt_y2             23432 non-null  float64\n",
      " 175  bag_cnt_y3             23432 non-null  float64\n",
      " 176  cabin_upgrd_cnt_m3     23432 non-null  float64\n",
      " 177  cabin_upgrd_cnt_m6     23432 non-null  float64\n",
      " 178  cabin_upgrd_cnt_y1     23432 non-null  float64\n",
      " 179  cabin_upgrd_cnt_y2     23432 non-null  float64\n",
      " 180  cabin_upgrd_cnt_y3     23432 non-null  float64\n",
      " 181  select_seat_cnt_m3     23432 non-null  float64\n",
      " 182  select_seat_cnt_m6     23432 non-null  float64\n",
      " 183  select_seat_cnt_y1     23432 non-null  float64\n",
      " 184  select_seat_cnt_y2     23432 non-null  float64\n",
      " 185  select_seat_cnt_y3     23432 non-null  float64\n",
      " 186  dist_d_cnt_m3          23432 non-null  float64\n",
      " 187  dist_d_cnt_m6          23432 non-null  float64\n",
      " 188  dist_d_cnt_y1          23432 non-null  float64\n",
      " 189  dist_d_cnt_y2          23432 non-null  float64\n",
      " 190  dist_d_cnt_y3          23432 non-null  float64\n",
      " 191  dist_i_cnt_m3          23432 non-null  float64\n",
      " 192  dist_i_cnt_m6          23432 non-null  float64\n",
      " 193  dist_i_cnt_y1          23432 non-null  float64\n",
      " 194  dist_i_cnt_y2          23432 non-null  float64\n",
      " 195  dist_i_cnt_y3          23432 non-null  float64\n",
      " 196  dist_all_cnt_m3        23432 non-null  float64\n",
      " 197  dist_all_cnt_m6        23432 non-null  float64\n",
      " 198  dist_all_cnt_y1        23432 non-null  float64\n",
      " 199  dist_all_cnt_y2        23432 non-null  float64\n",
      " 200  dist_all_cnt_y3        23432 non-null  float64\n",
      " 201  cabin_hd_cnt_m3        23432 non-null  float64\n",
      " 202  cabin_hd_cnt_m6        23432 non-null  float64\n",
      " 203  cabin_hd_cnt_y1        23432 non-null  float64\n",
      " 204  cabin_hd_cnt_y2        23432 non-null  float64\n",
      " 205  cabin_hd_cnt_y3        23432 non-null  float64\n",
      " 206  cabin_hi_cnt_m3        23432 non-null  float64\n",
      " 207  cabin_hi_cnt_m6        23432 non-null  float64\n",
      " 208  cabin_hi_cnt_y1        23432 non-null  float64\n",
      " 209  cabin_hi_cnt_y2        23432 non-null  float64\n",
      " 210  cabin_hi_cnt_y3        23432 non-null  float64\n",
      " 211  flt_leg_cnt_m3         23432 non-null  float64\n",
      " 212  flt_leg_cnt_m6         23432 non-null  float64\n",
      " 213  flt_leg_cnt_y1         23432 non-null  float64\n",
      " 214  flt_leg_cnt_y2         23432 non-null  float64\n",
      " 215  flt_leg_cnt_y3         23432 non-null  float64\n",
      " 216  flt_leg_i_cnt_m3       23432 non-null  float64\n",
      " 217  flt_leg_i_cnt_m6       23432 non-null  float64\n",
      " 218  flt_leg_i_cnt_y1       23432 non-null  float64\n",
      " 219  flt_leg_i_cnt_y2       23432 non-null  float64\n",
      " 220  flt_leg_i_cnt_y3       23432 non-null  float64\n",
      " 221  flt_leg_d_cnt_m3       23432 non-null  float64\n",
      " 222  flt_leg_d_cnt_m6       23432 non-null  float64\n",
      " 223  flt_leg_d_cnt_y1       23432 non-null  float64\n",
      " 224  flt_leg_d_cnt_y2       23432 non-null  float64\n",
      " 225  flt_leg_d_cnt_y3       23432 non-null  float64\n",
      " 226  flt_cancel_cnt_m3      23432 non-null  float64\n",
      " 227  flt_cancel_cnt_m6      23432 non-null  float64\n",
      " 228  flt_cancel_cnt_y1      23432 non-null  float64\n",
      " 229  flt_cancel_cnt_y2      23432 non-null  float64\n",
      " 230  flt_cancel_cnt_y3      23432 non-null  float64\n",
      " 231  flt_delay_cnt_m3       23432 non-null  float64\n",
      " 232  flt_delay_cnt_m6       23432 non-null  float64\n",
      " 233  flt_delay_cnt_y1       23432 non-null  float64\n",
      " 234  flt_delay_cnt_y2       23432 non-null  float64\n",
      " 235  flt_delay_cnt_y3       23432 non-null  float64\n",
      " 236  flt_delay_time_m3      23432 non-null  float64\n",
      " 237  flt_delay_time_m6      23432 non-null  float64\n",
      " 238  flt_delay_time_y1      23432 non-null  float64\n",
      " 239  flt_delay_time_y2      23432 non-null  float64\n",
      " 240  flt_delay_time_y3      23432 non-null  float64\n",
      " 241  rest_cnt_m3            23432 non-null  float64\n",
      " 242  rest_cnt_m6            23432 non-null  float64\n",
      " 243  rest_cnt_y1            23432 non-null  float64\n",
      " 244  rest_cnt_y2            23432 non-null  float64\n",
      " 245  rest_cnt_y3            23432 non-null  float64\n",
      " 246  cabin_fall_cnt_m3      23432 non-null  float64\n",
      " 247  cabin_fall_cnt_m6      23432 non-null  float64\n",
      " 248  cabin_fall_cnt_y1      23432 non-null  float64\n",
      " 249  cabin_fall_cnt_y2      23432 non-null  float64\n",
      " 250  cabin_fall_cnt_y3      23432 non-null  float64\n",
      " 251  flt_bag_cnt_m3         23432 non-null  float64\n",
      " 252  flt_bag_cnt_m6         23432 non-null  float64\n",
      " 253  flt_bag_cnt_y1         23432 non-null  float64\n",
      " 254  flt_bag_cnt_y2         23432 non-null  float64\n",
      " 255  flt_bag_cnt_y3         23432 non-null  float64\n",
      " 256  complain_cnt_m3        23432 non-null  float64\n",
      " 257  complain_cnt_m6        23432 non-null  float64\n",
      " 258  complain_cnt_y1        23432 non-null  float64\n",
      " 259  complain_cnt_y2        23432 non-null  float64\n",
      " 260  complain_cnt_y3        23432 non-null  float64\n",
      " 261  noshow_rate_m3         23432 non-null  float64\n",
      " 262  noshow_rate_m6         23432 non-null  float64\n",
      " 263  noshow_rate_y1         23432 non-null  float64\n",
      " 264  noshow_rate_y2         23432 non-null  float64\n",
      " 265  noshow_rate_y3         23432 non-null  float64\n",
      " 266  tkt_3y_amt             23432 non-null  float64\n",
      " 267  tkt_avg_amt            23432 non-null  float64\n",
      " 268  tkt_d_amt_m3           23432 non-null  float64\n",
      " 269  tkt_d_amt_m6           23432 non-null  float64\n",
      " 270  tkt_d_amt_y1           23432 non-null  float64\n",
      " 271  tkt_d_amt_y2           23432 non-null  float64\n",
      " 272  tkt_d_amt_y3           23432 non-null  float64\n",
      " 273  tkt_i_amt_m3           23432 non-null  float64\n",
      " 274  tkt_i_amt_m6           23432 non-null  float64\n",
      " 275  tkt_i_amt_y1           23432 non-null  float64\n",
      " 276  tkt_i_amt_y2           23432 non-null  float64\n",
      " 277  tkt_i_amt_y3           23432 non-null  float64\n",
      " 278  tkt_all_amt_m3         23432 non-null  float64\n",
      " 279  tkt_all_amt_m6         23432 non-null  float64\n",
      " 280  tkt_all_amt_y1         23432 non-null  float64\n",
      " 281  tkt_all_amt_y2         23432 non-null  float64\n",
      " 282  tkt_all_amt_y3         23432 non-null  float64\n",
      " 283  tkt_avg_amt_m3         23432 non-null  float64\n",
      " 284  tkt_avg_amt_m6         23432 non-null  float64\n",
      " 285  tkt_avg_amt_y1         23432 non-null  float64\n",
      " 286  tkt_avg_amt_y2         23432 non-null  float64\n",
      " 287  tkt_avg_amt_y3         23432 non-null  float64\n",
      " 288  tkt_avg_disc_m3        23432 non-null  float64\n",
      " 289  tkt_avg_disc_m6        23432 non-null  float64\n",
      " 290  tkt_avg_disc_y1        23432 non-null  float64\n",
      " 291  tkt_avg_disc_y2        23432 non-null  float64\n",
      " 292  tkt_avg_disc_y3        23432 non-null  float64\n",
      " 293  tkt_return_cnt_m3      23432 non-null  float64\n",
      " 294  tkt_return_cnt_m6      23432 non-null  float64\n",
      " 295  tkt_return_cnt_y1      23432 non-null  float64\n",
      " 296  tkt_return_cnt_y2      23432 non-null  float64\n",
      " 297  tkt_return_cnt_y3      23432 non-null  float64\n",
      " 298  tkt_book_cnt_m3        23432 non-null  float64\n",
      " 299  tkt_book_cnt_m6        23432 non-null  float64\n",
      " 300  tkt_book_cnt_y1        23432 non-null  float64\n",
      " 301  tkt_book_cnt_y2        23432 non-null  float64\n",
      " 302  tkt_book_cnt_y3        23432 non-null  float64\n",
      " 303  tkt_return_all_cnt_m3  23432 non-null  float64\n",
      " 304  tkt_return_all_cnt_m6  23432 non-null  float64\n",
      " 305  tkt_return_all_cnt_y1  23432 non-null  float64\n",
      " 306  tkt_return_all_cnt_y2  23432 non-null  float64\n",
      " 307  tkt_return_all_cnt_y3  23432 non-null  float64\n",
      " 308  tkt_avg_interval_m3    23432 non-null  float64\n",
      " 309  tkt_avg_interval_m6    23432 non-null  float64\n",
      " 310  tkt_avg_interval_y1    23432 non-null  float64\n",
      " 311  tkt_avg_interval_y2    23432 non-null  float64\n",
      " 312  tkt_avg_interval_y3    23432 non-null  float64\n",
      " 313  pit_all_amt            23432 non-null  float64\n",
      " 314  pit_out_amt            23432 non-null  float64\n",
      " 315  pit_accu_non_cnt       23432 non-null  float64\n",
      " 316  pit_accu_air_cnt       23432 non-null  float64\n",
      " 317  pit_accu_air_amt       23432 non-null  float64\n",
      " 318  pit_accu_non_amt       23432 non-null  float64\n",
      " 319  pit_now_cons_amt       23432 non-null  float64\n",
      " 320  pit_next_level_dist    23432 non-null  float64\n",
      " 321  pit_next_level_leg     23432 non-null  float64\n",
      " 322  mdl_mcv                23432 non-null  float64\n",
      " 323  mdl_lost_idx           23432 non-null  float64\n",
      " 324  mdl_influence          23432 non-null  float64\n",
      " 325  mdl_loyal              23432 non-null  float64\n",
      " 326  pit_accu_amt_m3        23432 non-null  float64\n",
      " 327  pit_accu_amt_m6        23432 non-null  float64\n",
      " 328  pit_accu_amt_y1        23432 non-null  float64\n",
      " 329  pit_accu_amt_y2        23432 non-null  float64\n",
      " 330  pit_accu_amt_y3        23432 non-null  float64\n",
      " 331  pit_cons_amt_m3        23432 non-null  float64\n",
      " 332  pit_cons_amt_m6        23432 non-null  float64\n",
      " 333  pit_cons_amt_y1        23432 non-null  float64\n",
      " 334  pit_cons_amt_y2        23432 non-null  float64\n",
      " 335  pit_cons_amt_y3        23432 non-null  float64\n",
      " 336  pit_avg_accu_amt_m3    23432 non-null  float64\n",
      " 337  pit_avg_accu_amt_m6    23432 non-null  float64\n",
      " 338  pit_avg_accu_amt_y1    23432 non-null  float64\n",
      " 339  pit_avg_accu_amt_y2    23432 non-null  float64\n",
      " 340  pit_avg_accu_amt_y3    23432 non-null  float64\n",
      " 341  pit_avg_cons_amt_m3    23432 non-null  float64\n",
      " 342  pit_avg_cons_amt_m6    23432 non-null  float64\n",
      " 343  pit_avg_cons_amt_y1    23432 non-null  float64\n",
      " 344  pit_avg_cons_amt_y2    23432 non-null  float64\n",
      " 345  pit_avg_cons_amt_y3    23432 non-null  float64\n",
      " 346  pit_accu_cnt_m3        23432 non-null  float64\n",
      " 347  pit_accu_cnt_m6        23432 non-null  float64\n",
      " 348  pit_accu_cnt_y1        23432 non-null  float64\n",
      " 349  pit_accu_cnt_y2        23432 non-null  float64\n",
      " 350  pit_accu_cnt_y3        23432 non-null  float64\n",
      " 351  pit_cons_cnt_m3        23432 non-null  float64\n",
      " 352  pit_cons_cnt_m6        23432 non-null  float64\n",
      " 353  pit_cons_cnt_y1        23432 non-null  float64\n",
      " 354  pit_cons_cnt_y2        23432 non-null  float64\n",
      " 355  pit_cons_cnt_y3        23432 non-null  float64\n",
      " 356  pit_add_air_amt_m3     23432 non-null  float64\n",
      " 357  pit_add_air_amt_m6     23432 non-null  float64\n",
      " 358  pit_add_air_amt_y1     23432 non-null  float64\n",
      " 359  pit_add_air_amt_y2     23432 non-null  float64\n",
      " 360  pit_add_air_amt_y3     23432 non-null  float64\n",
      " 361  pit_add_non_amt_m3     23432 non-null  float64\n",
      " 362  pit_add_non_amt_m6     23432 non-null  float64\n",
      " 363  pit_add_non_amt_y1     23432 non-null  float64\n",
      " 364  pit_add_non_amt_y2     23432 non-null  float64\n",
      " 365  pit_add_non_amt_y3     23432 non-null  float64\n",
      " 366  pit_add_buy_amt_m3     23432 non-null  float64\n",
      " 367  pit_add_buy_amt_m6     23432 non-null  float64\n",
      " 368  pit_add_buy_amt_y1     23432 non-null  float64\n",
      " 369  pit_add_buy_amt_y2     23432 non-null  float64\n",
      " 370  pit_add_buy_amt_y3     23432 non-null  float64\n",
      " 371  pit_add_mnl_amt_m3     23432 non-null  float64\n",
      " 372  pit_add_mnl_amt_m6     23432 non-null  float64\n",
      " 373  pit_add_mnl_amt_y1     23432 non-null  float64\n",
      " 374  pit_add_mnl_amt_y2     23432 non-null  float64\n",
      " 375  pit_add_mnl_amt_y3     23432 non-null  float64\n",
      " 376  pit_add_ech_amt_m3     23432 non-null  float64\n",
      " 377  pit_add_ech_amt_m6     23432 non-null  float64\n",
      " 378  pit_add_ech_amt_y1     23432 non-null  float64\n",
      " 379  pit_add_ech_amt_y2     23432 non-null  float64\n",
      " 380  pit_add_ech_amt_y3     23432 non-null  float64\n",
      " 381  pit_add_oth_amt_m3     23432 non-null  float64\n",
      " 382  pit_add_oth_amt_m6     23432 non-null  float64\n",
      " 383  pit_add_oth_amt_y1     23432 non-null  float64\n",
      " 384  pit_add_oth_amt_y2     23432 non-null  float64\n",
      " 385  pit_add_oth_amt_y3     23432 non-null  float64\n",
      " 386  pit_des_tkt_amt_m3     23432 non-null  float64\n",
      " 387  pit_des_tkt_amt_m6     23432 non-null  float64\n",
      " 388  pit_des_tkt_amt_y1     23432 non-null  float64\n",
      " 389  pit_des_tkt_amt_y2     23432 non-null  float64\n",
      " 390  pit_des_tkt_amt_y3     23432 non-null  float64\n",
      " 391  pit_des_bag_amt_m3     23432 non-null  float64\n",
      " 392  pit_des_bag_amt_m6     23432 non-null  float64\n",
      " 393  pit_des_bag_amt_y1     23432 non-null  float64\n",
      " 394  pit_des_bag_amt_y2     23432 non-null  float64\n",
      " 395  pit_des_bag_amt_y3     23432 non-null  float64\n",
      " 396  pit_des_upg_amt_m3     23432 non-null  float64\n",
      " 397  pit_des_upg_amt_m6     23432 non-null  float64\n",
      " 398  pit_des_upg_amt_y1     23432 non-null  float64\n",
      " 399  pit_des_upg_amt_y2     23432 non-null  float64\n",
      " 400  pit_des_upg_amt_y3     23432 non-null  float64\n",
      " 401  pit_des_mall_amt_m3    23432 non-null  float64\n",
      " 402  pit_des_mall_amt_m6    23432 non-null  float64\n",
      " 403  pit_des_mall_amt_y1    23432 non-null  float64\n",
      " 404  pit_des_mall_amt_y2    23432 non-null  float64\n",
      " 405  pit_des_mall_amt_y3    23432 non-null  float64\n",
      " 406  pit_des_selt_amt_m3    23432 non-null  float64\n",
      " 407  pit_des_selt_amt_m6    23432 non-null  float64\n",
      " 408  pit_des_selt_amt_y1    23432 non-null  float64\n",
      " 409  pit_des_selt_amt_y2    23432 non-null  float64\n",
      " 410  pit_des_selt_amt_y3    23432 non-null  float64\n",
      " 411  pit_des_out_amt_m3     23432 non-null  float64\n",
      " 412  pit_des_out_amt_m6     23432 non-null  float64\n",
      " 413  pit_des_out_amt_y1     23432 non-null  float64\n",
      " 414  pit_des_out_amt_y2     23432 non-null  float64\n",
      " 415  pit_des_out_amt_y3     23432 non-null  float64\n",
      " 416  pit_des_oth_amt_m3     23432 non-null  float64\n",
      " 417  pit_des_oth_amt_m6     23432 non-null  float64\n",
      " 418  pit_des_oth_amt_y1     23432 non-null  float64\n",
      " 419  pit_des_oth_amt_y2     23432 non-null  float64\n",
      " 420  pit_des_oth_amt_y3     23432 non-null  float64\n",
      " 421  pit_add_air_cnt_m3     23432 non-null  float64\n",
      " 422  pit_add_air_cnt_m6     23432 non-null  float64\n",
      " 423  pit_add_air_cnt_y1     23432 non-null  float64\n",
      " 424  pit_add_air_cnt_y2     23432 non-null  float64\n",
      " 425  pit_add_air_cnt_y3     23432 non-null  float64\n",
      " 426  pit_add_non_cnt_m3     23432 non-null  float64\n",
      " 427  pit_add_non_cnt_m6     23432 non-null  float64\n",
      " 428  pit_add_non_cnt_y1     23432 non-null  float64\n",
      " 429  pit_add_non_cnt_y2     23432 non-null  float64\n",
      " 430  pit_add_non_cnt_y3     23432 non-null  float64\n",
      " 431  pit_add_buy_cnt_m3     23432 non-null  float64\n",
      " 432  pit_add_buy_cnt_m6     23432 non-null  float64\n",
      " 433  pit_add_buy_cnt_y1     23432 non-null  float64\n",
      " 434  pit_add_buy_cnt_y2     23432 non-null  float64\n",
      " 435  pit_add_buy_cnt_y3     23432 non-null  float64\n",
      " 436  pit_add_mnl_cnt_m3     23432 non-null  float64\n",
      " 437  pit_add_mnl_cnt_m6     23432 non-null  float64\n",
      " 438  pit_add_mnl_cnt_y1     23432 non-null  float64\n",
      " 439  pit_add_mnl_cnt_y2     23432 non-null  float64\n",
      " 440  pit_add_mnl_cnt_y3     23432 non-null  float64\n",
      " 441  pit_add_ech_cnt_m3     23432 non-null  float64\n",
      " 442  pit_add_ech_cnt_m6     23432 non-null  float64\n",
      " 443  pit_add_ech_cnt_y1     23432 non-null  float64\n",
      " 444  pit_add_ech_cnt_y2     23432 non-null  float64\n",
      " 445  pit_add_ech_cnt_y3     23432 non-null  float64\n",
      " 446  pit_add_oth_cnt_m3     23432 non-null  float64\n",
      " 447  pit_add_oth_cnt_m6     23432 non-null  float64\n",
      " 448  pit_add_oth_cnt_y1     23432 non-null  float64\n",
      " 449  pit_add_oth_cnt_y2     23432 non-null  float64\n",
      " 450  pit_add_oth_cnt_y3     23432 non-null  float64\n",
      " 451  pit_des_tkt_cnt_m3     23432 non-null  float64\n",
      " 452  pit_des_tkt_cnt_m6     23432 non-null  float64\n",
      " 453  pit_des_tkt_cnt_y1     23432 non-null  float64\n",
      " 454  pit_des_tkt_cnt_y2     23432 non-null  float64\n",
      " 455  pit_des_tkt_cnt_y3     23432 non-null  float64\n",
      " 456  pit_des_bag_cnt_m3     23432 non-null  float64\n",
      " 457  pit_des_bag_cnt_m6     23432 non-null  float64\n",
      " 458  pit_des_bag_cnt_y1     23432 non-null  float64\n",
      " 459  pit_des_bag_cnt_y2     23432 non-null  float64\n",
      " 460  pit_des_bag_cnt_y3     23432 non-null  float64\n",
      " 461  pit_des_upg_cnt_m3     23432 non-null  float64\n",
      " 462  pit_des_upg_cnt_m6     23432 non-null  float64\n",
      " 463  pit_des_upg_cnt_y1     23432 non-null  float64\n",
      " 464  pit_des_upg_cnt_y2     23432 non-null  float64\n",
      " 465  pit_des_upg_cnt_y3     23432 non-null  float64\n",
      " 466  pit_des_mall_cnt_m3    23432 non-null  float64\n",
      " 467  pit_des_mall_cnt_m6    23432 non-null  float64\n",
      " 468  pit_des_mall_cnt_y1    23432 non-null  float64\n",
      " 469  pit_des_mall_cnt_y2    23432 non-null  float64\n",
      " 470  pit_des_mall_cnt_y3    23432 non-null  float64\n",
      " 471  pit_des_selt_cnt_m3    23432 non-null  float64\n",
      " 472  pit_des_selt_cnt_m6    23432 non-null  float64\n",
      " 473  pit_des_selt_cnt_y1    23432 non-null  float64\n",
      " 474  pit_des_selt_cnt_y2    23432 non-null  float64\n",
      " 475  pit_des_selt_cnt_y3    23432 non-null  float64\n",
      " 476  pit_des_out_cnt_m3     23432 non-null  float64\n",
      " 477  pit_des_out_cnt_m6     23432 non-null  float64\n",
      " 478  pit_des_out_cnt_y1     23432 non-null  float64\n",
      " 479  pit_des_out_cnt_y2     23432 non-null  float64\n",
      " 480  pit_des_out_cnt_y3     23432 non-null  float64\n",
      " 481  pit_des_oth_cnt_m3     23432 non-null  float64\n",
      " 482  pit_des_oth_cnt_m6     23432 non-null  float64\n",
      " 483  pit_des_oth_cnt_y1     23432 non-null  float64\n",
      " 484  pit_des_oth_cnt_y2     23432 non-null  float64\n",
      " 485  pit_des_oth_cnt_y3     23432 non-null  float64\n",
      " 486  pit_avg_amt_m3         23432 non-null  float64\n",
      " 487  pit_avg_amt_m6         23432 non-null  float64\n",
      " 488  pit_avg_amt_y1         23432 non-null  float64\n",
      " 489  pit_avg_amt_y2         23432 non-null  float64\n",
      " 490  pit_avg_amt_y3         23432 non-null  float64\n",
      " 491  pit_avg_interval_m3    23432 non-null  float64\n",
      " 492  pit_avg_interval_m6    23432 non-null  float64\n",
      " 493  pit_avg_interval_y1    23432 non-null  float64\n",
      " 494  pit_avg_interval_y2    23432 non-null  float64\n",
      " 495  pit_avg_interval_y3    23432 non-null  float64\n",
      " 496  pit_ech_avg_amt_m3     23432 non-null  float64\n",
      " 497  pit_ech_avg_amt_m6     23432 non-null  float64\n",
      " 498  pit_ech_avg_amt_y1     23432 non-null  float64\n",
      " 499  pit_ech_avg_amt_y2     23432 non-null  float64\n",
      " 500  pit_ech_avg_amt_y3     23432 non-null  float64\n",
      " 501  pit_out_avg_amt_m3     23432 non-null  float64\n",
      " 502  pit_out_avg_amt_m6     23432 non-null  float64\n",
      " 503  pit_out_avg_amt_y1     23432 non-null  float64\n",
      " 504  pit_out_avg_amt_y2     23432 non-null  float64\n",
      " 505  pit_out_avg_amt_y3     23432 non-null  float64\n",
      " 506  pit_income_cnt_m3      23432 non-null  float64\n",
      " 507  pit_income_cnt_m6      23432 non-null  float64\n",
      " 508  pit_income_cnt_y1      23432 non-null  float64\n",
      " 509  pit_income_cnt_y2      23432 non-null  float64\n",
      " 510  pit_income_cnt_y3      23432 non-null  float64\n",
      " 511  pit_pay_cnt_m3         23432 non-null  float64\n",
      " 512  pit_pay_cnt_m6         23432 non-null  float64\n",
      " 513  pit_pay_cnt_y1         23432 non-null  float64\n",
      " 514  pit_pay_cnt_y2         23432 non-null  float64\n",
      " 515  pit_pay_cnt_y3         23432 non-null  float64\n",
      " 516  pit_income_avg_amt_m3  23432 non-null  float64\n",
      " 517  pit_income_avg_amt_m6  23432 non-null  float64\n",
      " 518  pit_income_avg_amt_y1  23432 non-null  float64\n",
      " 519  pit_income_avg_amt_y2  23432 non-null  float64\n",
      " 520  pit_income_avg_amt_y3  23432 non-null  float64\n",
      " 521  pit_pay_avg_amt_m3     23432 non-null  float64\n",
      " 522  pit_pay_avg_amt_m6     23432 non-null  float64\n",
      " 523  pit_pay_avg_amt_y1     23432 non-null  float64\n",
      " 524  pit_pay_avg_amt_y2     23432 non-null  float64\n",
      " 525  pit_pay_avg_amt_y3     23432 non-null  float64\n",
      " 526  pax_name               23432 non-null  object \n",
      "dtypes: float64(524), int64(2), object(1)\n",
      "memory usage: 94.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\1320876256.py:10: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  data2.info(verbose=True,null_counts=True)\n"
     ]
    }
   ],
   "source": [
    "# 原本的空值替换为数值0，保留除了object和datetime类型的之外的特征因子\n",
    "data1['seg_route_to'] = data1['seg_route_to'].map({'JFK': 1, 'LAX':2, 'SYD':3})\n",
    "data1['seg_cabin'] = data1['seg_cabin'].map({'F': 1, 'J':2, 'W':3,'Y':4,'C':5})\n",
    "data1['seg_flight'] = data1['seg_flight'].map({'AB1000':0,'AB1001': 1,'AB1002':2,'AB1003':3, 'AB1004':4, 'AB1005':5,'AB1006':6,'AB1007': 7, 'AB1008':8,'AB1009':9, 'AB1010':10,'AB1011':11,'AB1012':12,'AB1013':13, 'AB1014':14,'AB1015':15, 'AB1016':16})\n",
    "\n",
    "data2 = data1.replace(np.nan,0)\n",
    "data2 = data2.select_dtypes(exclude=['object','datetime64[ns]'])\n",
    "data2 = data2.drop(['emd_lable'],axis=1)\n",
    "data2['pax_name']=data1['pax_name']\n",
    "data2.info(verbose=True,null_counts=True)\n",
    "# data2.to_csv('trainh.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6771 entries, 0 to 6770\n",
      "Data columns (total 511 columns):\n",
      " #    Column                 Non-Null Count  Dtype  \n",
      "---   ------                 --------------  -----  \n",
      " 0    seg_route_to           6771 non-null   int64  \n",
      " 1    seg_flight             6771 non-null   int64  \n",
      " 2    seg_cabin              6771 non-null   int64  \n",
      " 3    pax_fcny               6771 non-null   float64\n",
      " 4    pax_tax                6771 non-null   float64\n",
      " 5    emd_lable2             6771 non-null   float64\n",
      " 6    cabin_hf_cnt_m3        6771 non-null   float64\n",
      " 7    cabin_hf_cnt_m6        6771 non-null   float64\n",
      " 8    cabin_hf_cnt_y1        6771 non-null   float64\n",
      " 9    cabin_hf_cnt_y2        6771 non-null   float64\n",
      " 10   cabin_hf_cnt_y3        6771 non-null   float64\n",
      " 11   cabin_f_cnt_m3         6771 non-null   float64\n",
      " 12   cabin_f_cnt_m6         6771 non-null   float64\n",
      " 13   cabin_f_cnt_y1         6771 non-null   float64\n",
      " 14   cabin_f_cnt_y2         6771 non-null   float64\n",
      " 15   cabin_f_cnt_y3         6771 non-null   float64\n",
      " 16   cabin_hy_cnt_m3        6771 non-null   float64\n",
      " 17   cabin_hy_cnt_m6        6771 non-null   float64\n",
      " 18   cabin_hy_cnt_y1        6771 non-null   float64\n",
      " 19   cabin_hy_cnt_y2        6771 non-null   float64\n",
      " 20   cabin_hy_cnt_y3        6771 non-null   float64\n",
      " 21   cabin_y_cnt_m3         6771 non-null   float64\n",
      " 22   cabin_y_cnt_m6         6771 non-null   float64\n",
      " 23   cabin_y_cnt_y1         6771 non-null   float64\n",
      " 24   cabin_y_cnt_y2         6771 non-null   float64\n",
      " 25   cabin_y_cnt_y3         6771 non-null   float64\n",
      " 26   cabin_c_cnt_m3         6771 non-null   float64\n",
      " 27   cabin_c_cnt_m6         6771 non-null   float64\n",
      " 28   cabin_c_cnt_y1         6771 non-null   float64\n",
      " 29   seat_window_cnt_m3     6771 non-null   float64\n",
      " 30   seat_window_cnt_m6     6771 non-null   float64\n",
      " 31   seat_window_cnt_y1     6771 non-null   float64\n",
      " 32   seat_window_cnt_y2     6771 non-null   float64\n",
      " 33   seat_window_cnt_y3     6771 non-null   float64\n",
      " 34   seat_walkway_cnt_m3    6771 non-null   float64\n",
      " 35   seat_walkway_cnt_m6    6771 non-null   float64\n",
      " 36   seat_walkway_cnt_y1    6771 non-null   float64\n",
      " 37   seat_walkway_cnt_y2    6771 non-null   float64\n",
      " 38   seat_walkway_cnt_y3    6771 non-null   float64\n",
      " 39   seat_middle_cnt_m3     6771 non-null   float64\n",
      " 40   seat_middle_cnt_m6     6771 non-null   float64\n",
      " 41   seat_middle_cnt_y1     6771 non-null   float64\n",
      " 42   seat_middle_cnt_y2     6771 non-null   float64\n",
      " 43   seat_middle_cnt_y3     6771 non-null   float64\n",
      " 44   seat_safe_cnt_m3       6771 non-null   float64\n",
      " 45   seat_safe_cnt_m6       6771 non-null   float64\n",
      " 46   seat_safe_cnt_y1       6771 non-null   float64\n",
      " 47   seat_safe_cnt_y2       6771 non-null   float64\n",
      " 48   seat_safe_cnt_y3       6771 non-null   float64\n",
      " 49   prebuy_d_cnt_m3_d3     6771 non-null   float64\n",
      " 50   prebuy_d_cnt_m3_d7     6771 non-null   float64\n",
      " 51   prebuy_d_cnt_m3_d14    6771 non-null   float64\n",
      " 52   prebuy_d_cnt_m3_d30    6771 non-null   float64\n",
      " 53   prebuy_d_cnt_m3_d99    6771 non-null   float64\n",
      " 54   prebuy_d_cnt_m6_d3     6771 non-null   float64\n",
      " 55   prebuy_d_cnt_m6_d7     6771 non-null   float64\n",
      " 56   prebuy_d_cnt_m6_d14    6771 non-null   float64\n",
      " 57   prebuy_d_cnt_m6_d30    6771 non-null   float64\n",
      " 58   prebuy_d_cnt_m6_d99    6771 non-null   float64\n",
      " 59   prebuy_d_cnt_y1_d3     6771 non-null   float64\n",
      " 60   prebuy_d_cnt_y1_d7     6771 non-null   float64\n",
      " 61   prebuy_d_cnt_y1_d14    6771 non-null   float64\n",
      " 62   prebuy_d_cnt_y1_d30    6771 non-null   float64\n",
      " 63   prebuy_d_cnt_y1_d99    6771 non-null   float64\n",
      " 64   prebuy_d_cnt_y2_d3     6771 non-null   float64\n",
      " 65   prebuy_d_cnt_y2_d7     6771 non-null   float64\n",
      " 66   prebuy_d_cnt_y2_d14    6771 non-null   float64\n",
      " 67   prebuy_d_cnt_y2_d30    6771 non-null   float64\n",
      " 68   prebuy_d_cnt_y2_d99    6771 non-null   float64\n",
      " 69   prebuy_d_cnt_y3_d3     6771 non-null   float64\n",
      " 70   prebuy_d_cnt_y3_d7     6771 non-null   float64\n",
      " 71   prebuy_d_cnt_y3_d14    6771 non-null   float64\n",
      " 72   prebuy_d_cnt_y3_d30    6771 non-null   float64\n",
      " 73   prebuy_d_cnt_y3_d99    6771 non-null   float64\n",
      " 74   prebuy_i_cnt_m3_d3     6771 non-null   float64\n",
      " 75   prebuy_i_cnt_m3_d7     6771 non-null   float64\n",
      " 76   prebuy_i_cnt_m3_d14    6771 non-null   float64\n",
      " 77   prebuy_i_cnt_m3_d30    6771 non-null   float64\n",
      " 78   prebuy_i_cnt_m3_d99    6771 non-null   float64\n",
      " 79   prebuy_i_cnt_m6_d3     6771 non-null   float64\n",
      " 80   prebuy_i_cnt_m6_d7     6771 non-null   float64\n",
      " 81   prebuy_i_cnt_m6_d14    6771 non-null   float64\n",
      " 82   prebuy_i_cnt_m6_d30    6771 non-null   float64\n",
      " 83   prebuy_i_cnt_m6_d99    6771 non-null   float64\n",
      " 84   prebuy_i_cnt_y1_d3     6771 non-null   float64\n",
      " 85   prebuy_i_cnt_y1_d7     6771 non-null   float64\n",
      " 86   prebuy_i_cnt_y1_d14    6771 non-null   float64\n",
      " 87   prebuy_i_cnt_y1_d30    6771 non-null   float64\n",
      " 88   prebuy_i_cnt_y1_d99    6771 non-null   float64\n",
      " 89   prebuy_i_cnt_y2_d3     6771 non-null   float64\n",
      " 90   prebuy_i_cnt_y2_d7     6771 non-null   float64\n",
      " 91   prebuy_i_cnt_y2_d14    6771 non-null   float64\n",
      " 92   prebuy_i_cnt_y2_d30    6771 non-null   float64\n",
      " 93   prebuy_i_cnt_y2_d99    6771 non-null   float64\n",
      " 94   prebuy_i_cnt_y3_d3     6771 non-null   float64\n",
      " 95   prebuy_i_cnt_y3_d7     6771 non-null   float64\n",
      " 96   prebuy_i_cnt_y3_d14    6771 non-null   float64\n",
      " 97   pref_month_m3_1        6771 non-null   float64\n",
      " 98   pref_month_m3_2        6771 non-null   float64\n",
      " 99   pref_month_m3_3        6771 non-null   float64\n",
      " 100  pref_month_m3_4        6771 non-null   float64\n",
      " 101  pref_month_m3_5        6771 non-null   float64\n",
      " 102  pref_month_m6_1        6771 non-null   float64\n",
      " 103  pref_month_m6_2        6771 non-null   float64\n",
      " 104  pref_month_m6_3        6771 non-null   float64\n",
      " 105  pref_month_m6_4        6771 non-null   float64\n",
      " 106  pref_month_m6_5        6771 non-null   float64\n",
      " 107  pref_month_y1_1        6771 non-null   float64\n",
      " 108  pref_month_y1_2        6771 non-null   float64\n",
      " 109  pref_month_y1_3        6771 non-null   float64\n",
      " 110  pref_month_y1_4        6771 non-null   float64\n",
      " 111  pref_month_y1_5        6771 non-null   float64\n",
      " 112  pref_month_y2_1        6771 non-null   float64\n",
      " 113  pref_month_y2_2        6771 non-null   float64\n",
      " 114  pref_month_y2_3        6771 non-null   float64\n",
      " 115  pref_month_y2_4        6771 non-null   float64\n",
      " 116  pref_month_y2_5        6771 non-null   float64\n",
      " 117  pref_month_y3_1        6771 non-null   float64\n",
      " 118  pref_month_y3_2        6771 non-null   float64\n",
      " 119  pref_month_y3_3        6771 non-null   float64\n",
      " 120  pref_month_y3_4        6771 non-null   float64\n",
      " 121  pref_month_y3_5        6771 non-null   float64\n",
      " 122  workday_cnt_m3         6771 non-null   float64\n",
      " 123  workday_cnt_m6         6771 non-null   float64\n",
      " 124  workday_cnt_y1         6771 non-null   float64\n",
      " 125  workday_cnt_y2         6771 non-null   float64\n",
      " 126  workday_cnt_y3         6771 non-null   float64\n",
      " 127  weekend_cnt_m3         6771 non-null   float64\n",
      " 128  weekend_cnt_m6         6771 non-null   float64\n",
      " 129  weekend_cnt_y1         6771 non-null   float64\n",
      " 130  weekend_cnt_y2         6771 non-null   float64\n",
      " 131  weekend_cnt_y3         6771 non-null   float64\n",
      " 132  holiday_cnt_m3         6771 non-null   float64\n",
      " 133  holiday_cnt_m6         6771 non-null   float64\n",
      " 134  holiday_cnt_y1         6771 non-null   float64\n",
      " 135  holiday_cnt_y2         6771 non-null   float64\n",
      " 136  holiday_cnt_y3         6771 non-null   float64\n",
      " 137  close_holiday_cnt_m3   6771 non-null   float64\n",
      " 138  close_holiday_cnt_m6   6771 non-null   float64\n",
      " 139  close_holiday_cnt_y1   6771 non-null   float64\n",
      " 140  close_holiday_cnt_y2   6771 non-null   float64\n",
      " 141  close_holiday_cnt_y3   6771 non-null   float64\n",
      " 142  flt_cnt_m3             6771 non-null   float64\n",
      " 143  flt_cnt_m6             6771 non-null   float64\n",
      " 144  flt_cnt_y1             6771 non-null   float64\n",
      " 145  next_flt_day           6771 non-null   float64\n",
      " 146  birth_interval_day     6771 non-null   float64\n",
      " 147  dist_cnt_y1            6771 non-null   float64\n",
      " 148  dist_cnt_y2            6771 non-null   float64\n",
      " 149  dist_cnt_y3            6771 non-null   float64\n",
      " 150  flt_nature_cnt_y1      6771 non-null   float64\n",
      " 151  flt_nature_cnt_y2      6771 non-null   float64\n",
      " 152  flt_nature_cnt_y3      6771 non-null   float64\n",
      " 153  avg_dist_cnt_m3        6771 non-null   float64\n",
      " 154  avg_dist_cnt_m6        6771 non-null   float64\n",
      " 155  avg_dist_cnt_y1        6771 non-null   float64\n",
      " 156  avg_dist_cnt_y2        6771 non-null   float64\n",
      " 157  avg_dist_cnt_y3        6771 non-null   float64\n",
      " 158  complain_valid_cnt_m3  6771 non-null   float64\n",
      " 159  complain_valid_cnt_m6  6771 non-null   float64\n",
      " 160  complain_valid_cnt_y1  6771 non-null   float64\n",
      " 161  complain_valid_cnt_y2  6771 non-null   float64\n",
      " 162  complain_valid_cnt_y3  6771 non-null   float64\n",
      " 163  bag_cnt_m3             6771 non-null   float64\n",
      " 164  bag_cnt_m6             6771 non-null   float64\n",
      " 165  bag_cnt_y1             6771 non-null   float64\n",
      " 166  bag_cnt_y2             6771 non-null   float64\n",
      " 167  bag_cnt_y3             6771 non-null   float64\n",
      " 168  cabin_upgrd_cnt_m3     6771 non-null   float64\n",
      " 169  cabin_upgrd_cnt_m6     6771 non-null   float64\n",
      " 170  cabin_upgrd_cnt_y1     6771 non-null   float64\n",
      " 171  cabin_upgrd_cnt_y2     6771 non-null   float64\n",
      " 172  cabin_upgrd_cnt_y3     6771 non-null   float64\n",
      " 173  select_seat_cnt_m3     6771 non-null   float64\n",
      " 174  select_seat_cnt_m6     6771 non-null   float64\n",
      " 175  select_seat_cnt_y1     6771 non-null   float64\n",
      " 176  select_seat_cnt_y2     6771 non-null   float64\n",
      " 177  select_seat_cnt_y3     6771 non-null   float64\n",
      " 178  dist_d_cnt_m3          6771 non-null   float64\n",
      " 179  dist_d_cnt_m6          6771 non-null   float64\n",
      " 180  dist_d_cnt_y1          6771 non-null   float64\n",
      " 181  dist_d_cnt_y2          6771 non-null   float64\n",
      " 182  dist_d_cnt_y3          6771 non-null   float64\n",
      " 183  dist_i_cnt_m3          6771 non-null   float64\n",
      " 184  dist_i_cnt_m6          6771 non-null   float64\n",
      " 185  dist_i_cnt_y1          6771 non-null   float64\n",
      " 186  dist_i_cnt_y2          6771 non-null   float64\n",
      " 187  dist_i_cnt_y3          6771 non-null   float64\n",
      " 188  dist_all_cnt_m3        6771 non-null   float64\n",
      " 189  dist_all_cnt_m6        6771 non-null   float64\n",
      " 190  dist_all_cnt_y1        6771 non-null   float64\n",
      " 191  dist_all_cnt_y2        6771 non-null   float64\n",
      " 192  dist_all_cnt_y3        6771 non-null   float64\n",
      " 193  cabin_hd_cnt_m3        6771 non-null   float64\n",
      " 194  cabin_hd_cnt_m6        6771 non-null   float64\n",
      " 195  cabin_hd_cnt_y1        6771 non-null   float64\n",
      " 196  cabin_hd_cnt_y2        6771 non-null   float64\n",
      " 197  cabin_hd_cnt_y3        6771 non-null   float64\n",
      " 198  cabin_hi_cnt_m3        6771 non-null   float64\n",
      " 199  cabin_hi_cnt_m6        6771 non-null   float64\n",
      " 200  cabin_hi_cnt_y1        6771 non-null   float64\n",
      " 201  cabin_hi_cnt_y2        6771 non-null   float64\n",
      " 202  cabin_hi_cnt_y3        6771 non-null   float64\n",
      " 203  flt_leg_cnt_m3         6771 non-null   float64\n",
      " 204  flt_leg_cnt_m6         6771 non-null   float64\n",
      " 205  flt_leg_cnt_y1         6771 non-null   float64\n",
      " 206  flt_leg_cnt_y2         6771 non-null   float64\n",
      " 207  flt_leg_cnt_y3         6771 non-null   float64\n",
      " 208  flt_leg_i_cnt_m3       6771 non-null   float64\n",
      " 209  flt_leg_i_cnt_m6       6771 non-null   float64\n",
      " 210  flt_leg_i_cnt_y1       6771 non-null   float64\n",
      " 211  flt_leg_i_cnt_y2       6771 non-null   float64\n",
      " 212  flt_leg_i_cnt_y3       6771 non-null   float64\n",
      " 213  flt_leg_d_cnt_m3       6771 non-null   float64\n",
      " 214  flt_leg_d_cnt_m6       6771 non-null   float64\n",
      " 215  flt_leg_d_cnt_y1       6771 non-null   float64\n",
      " 216  flt_cancel_cnt_m3      6771 non-null   float64\n",
      " 217  flt_cancel_cnt_m6      6771 non-null   float64\n",
      " 218  flt_cancel_cnt_y1      6771 non-null   float64\n",
      " 219  flt_cancel_cnt_y2      6771 non-null   float64\n",
      " 220  flt_cancel_cnt_y3      6771 non-null   float64\n",
      " 221  flt_delay_cnt_m3       6771 non-null   float64\n",
      " 222  flt_delay_cnt_m6       6771 non-null   float64\n",
      " 223  flt_delay_cnt_y1       6771 non-null   float64\n",
      " 224  flt_delay_cnt_y2       6771 non-null   float64\n",
      " 225  flt_delay_cnt_y3       6771 non-null   float64\n",
      " 226  flt_delay_time_m3      6771 non-null   float64\n",
      " 227  flt_delay_time_m6      6771 non-null   float64\n",
      " 228  flt_delay_time_y1      6771 non-null   float64\n",
      " 229  flt_delay_time_y2      6771 non-null   float64\n",
      " 230  flt_delay_time_y3      6771 non-null   float64\n",
      " 231  rest_cnt_m3            6771 non-null   float64\n",
      " 232  rest_cnt_m6            6771 non-null   float64\n",
      " 233  rest_cnt_y1            6771 non-null   float64\n",
      " 234  cabin_fall_cnt_m3      6771 non-null   float64\n",
      " 235  cabin_fall_cnt_m6      6771 non-null   float64\n",
      " 236  cabin_fall_cnt_y1      6771 non-null   float64\n",
      " 237  cabin_fall_cnt_y2      6771 non-null   float64\n",
      " 238  cabin_fall_cnt_y3      6771 non-null   float64\n",
      " 239  flt_bag_cnt_m3         6771 non-null   float64\n",
      " 240  flt_bag_cnt_m6         6771 non-null   float64\n",
      " 241  flt_bag_cnt_y1         6771 non-null   float64\n",
      " 242  flt_bag_cnt_y2         6771 non-null   float64\n",
      " 243  flt_bag_cnt_y3         6771 non-null   float64\n",
      " 244  complain_cnt_m3        6771 non-null   float64\n",
      " 245  complain_cnt_m6        6771 non-null   float64\n",
      " 246  complain_cnt_y1        6771 non-null   float64\n",
      " 247  complain_cnt_y2        6771 non-null   float64\n",
      " 248  complain_cnt_y3        6771 non-null   float64\n",
      " 249  noshow_rate_m3         6771 non-null   float64\n",
      " 250  noshow_rate_m6         6771 non-null   float64\n",
      " 251  noshow_rate_y1         6771 non-null   float64\n",
      " 252  noshow_rate_y2         6771 non-null   float64\n",
      " 253  noshow_rate_y3         6771 non-null   float64\n",
      " 254  tkt_3y_amt             6771 non-null   float64\n",
      " 255  tkt_avg_amt            6771 non-null   float64\n",
      " 256  tkt_d_amt_m3           6771 non-null   float64\n",
      " 257  tkt_d_amt_m6           6771 non-null   float64\n",
      " 258  tkt_d_amt_y1           6771 non-null   float64\n",
      " 259  tkt_d_amt_y2           6771 non-null   float64\n",
      " 260  tkt_d_amt_y3           6771 non-null   float64\n",
      " 261  tkt_i_amt_m3           6771 non-null   float64\n",
      " 262  tkt_i_amt_m6           6771 non-null   float64\n",
      " 263  tkt_i_amt_y1           6771 non-null   float64\n",
      " 264  tkt_i_amt_y2           6771 non-null   float64\n",
      " 265  tkt_i_amt_y3           6771 non-null   float64\n",
      " 266  tkt_all_amt_m3         6771 non-null   float64\n",
      " 267  tkt_all_amt_m6         6771 non-null   float64\n",
      " 268  tkt_all_amt_y1         6771 non-null   float64\n",
      " 269  tkt_all_amt_y2         6771 non-null   float64\n",
      " 270  tkt_all_amt_y3         6771 non-null   float64\n",
      " 271  tkt_avg_amt_m3         6771 non-null   float64\n",
      " 272  tkt_avg_amt_m6         6771 non-null   float64\n",
      " 273  tkt_avg_amt_y1         6771 non-null   float64\n",
      " 274  tkt_avg_amt_y2         6771 non-null   float64\n",
      " 275  tkt_avg_amt_y3         6771 non-null   float64\n",
      " 276  tkt_avg_disc_m3        6771 non-null   float64\n",
      " 277  tkt_avg_disc_m6        6771 non-null   float64\n",
      " 278  tkt_avg_disc_y1        6771 non-null   float64\n",
      " 279  tkt_avg_disc_y2        6771 non-null   float64\n",
      " 280  tkt_avg_disc_y3        6771 non-null   float64\n",
      " 281  tkt_return_cnt_m3      6771 non-null   float64\n",
      " 282  tkt_return_cnt_m6      6771 non-null   float64\n",
      " 283  tkt_return_cnt_y1      6771 non-null   float64\n",
      " 284  tkt_return_cnt_y2      6771 non-null   float64\n",
      " 285  tkt_return_cnt_y3      6771 non-null   float64\n",
      " 286  tkt_book_cnt_m3        6771 non-null   float64\n",
      " 287  tkt_book_cnt_m6        6771 non-null   float64\n",
      " 288  tkt_book_cnt_y1        6771 non-null   float64\n",
      " 289  tkt_book_cnt_y2        6771 non-null   float64\n",
      " 290  tkt_book_cnt_y3        6771 non-null   float64\n",
      " 291  tkt_return_all_cnt_m3  6771 non-null   float64\n",
      " 292  tkt_return_all_cnt_m6  6771 non-null   float64\n",
      " 293  tkt_return_all_cnt_y1  6771 non-null   float64\n",
      " 294  tkt_return_all_cnt_y2  6771 non-null   float64\n",
      " 295  tkt_return_all_cnt_y3  6771 non-null   float64\n",
      " 296  tkt_avg_interval_m3    6771 non-null   float64\n",
      " 297  tkt_avg_interval_m6    6771 non-null   float64\n",
      " 298  tkt_avg_interval_y1    6771 non-null   float64\n",
      " 299  pit_all_amt            6771 non-null   float64\n",
      " 300  pit_out_amt            6771 non-null   float64\n",
      " 301  pit_accu_non_cnt       6771 non-null   float64\n",
      " 302  pit_accu_air_cnt       6771 non-null   float64\n",
      " 303  pit_accu_air_amt       6771 non-null   float64\n",
      " 304  pit_accu_non_amt       6771 non-null   float64\n",
      " 305  pit_now_cons_amt       6771 non-null   float64\n",
      " 306  pit_next_level_dist    6771 non-null   float64\n",
      " 307  pit_next_level_leg     6771 non-null   float64\n",
      " 308  mdl_mcv                6771 non-null   float64\n",
      " 309  mdl_lost_idx           6771 non-null   float64\n",
      " 310  mdl_influence          6771 non-null   float64\n",
      " 311  mdl_loyal              6771 non-null   float64\n",
      " 312  pit_accu_amt_m3        6771 non-null   float64\n",
      " 313  pit_accu_amt_m6        6771 non-null   float64\n",
      " 314  pit_accu_amt_y1        6771 non-null   float64\n",
      " 315  pit_accu_amt_y2        6771 non-null   float64\n",
      " 316  pit_accu_amt_y3        6771 non-null   float64\n",
      " 317  pit_cons_amt_m3        6771 non-null   float64\n",
      " 318  pit_cons_amt_m6        6771 non-null   float64\n",
      " 319  pit_cons_amt_y1        6771 non-null   float64\n",
      " 320  pit_cons_amt_y2        6771 non-null   float64\n",
      " 321  pit_cons_amt_y3        6771 non-null   float64\n",
      " 322  pit_avg_accu_amt_m3    6771 non-null   float64\n",
      " 323  pit_avg_accu_amt_m6    6771 non-null   float64\n",
      " 324  pit_avg_accu_amt_y1    6771 non-null   float64\n",
      " 325  pit_avg_accu_amt_y2    6771 non-null   float64\n",
      " 326  pit_avg_accu_amt_y3    6771 non-null   float64\n",
      " 327  pit_avg_cons_amt_m3    6771 non-null   float64\n",
      " 328  pit_avg_cons_amt_m6    6771 non-null   float64\n",
      " 329  pit_avg_cons_amt_y1    6771 non-null   float64\n",
      " 330  pit_avg_cons_amt_y2    6771 non-null   float64\n",
      " 331  pit_avg_cons_amt_y3    6771 non-null   float64\n",
      " 332  pit_accu_cnt_m3        6771 non-null   float64\n",
      " 333  pit_accu_cnt_m6        6771 non-null   float64\n",
      " 334  pit_accu_cnt_y1        6771 non-null   float64\n",
      " 335  pit_accu_cnt_y2        6771 non-null   float64\n",
      " 336  pit_accu_cnt_y3        6771 non-null   float64\n",
      " 337  pit_cons_cnt_m3        6771 non-null   float64\n",
      " 338  pit_cons_cnt_m6        6771 non-null   float64\n",
      " 339  pit_cons_cnt_y1        6771 non-null   float64\n",
      " 340  pit_cons_cnt_y2        6771 non-null   float64\n",
      " 341  pit_cons_cnt_y3        6771 non-null   float64\n",
      " 342  pit_add_air_amt_m3     6771 non-null   float64\n",
      " 343  pit_add_air_amt_m6     6771 non-null   float64\n",
      " 344  pit_add_air_amt_y1     6771 non-null   float64\n",
      " 345  pit_add_air_amt_y2     6771 non-null   float64\n",
      " 346  pit_add_air_amt_y3     6771 non-null   float64\n",
      " 347  pit_add_non_amt_m3     6771 non-null   float64\n",
      " 348  pit_add_non_amt_m6     6771 non-null   float64\n",
      " 349  pit_add_non_amt_y1     6771 non-null   float64\n",
      " 350  pit_add_non_amt_y2     6771 non-null   float64\n",
      " 351  pit_add_non_amt_y3     6771 non-null   float64\n",
      " 352  pit_add_buy_amt_m3     6771 non-null   float64\n",
      " 353  pit_add_buy_amt_m6     6771 non-null   float64\n",
      " 354  pit_add_buy_amt_y1     6771 non-null   float64\n",
      " 355  pit_add_buy_amt_y2     6771 non-null   float64\n",
      " 356  pit_add_buy_amt_y3     6771 non-null   float64\n",
      " 357  pit_add_mnl_amt_m3     6771 non-null   float64\n",
      " 358  pit_add_mnl_amt_m6     6771 non-null   float64\n",
      " 359  pit_add_mnl_amt_y1     6771 non-null   float64\n",
      " 360  pit_add_mnl_amt_y2     6771 non-null   float64\n",
      " 361  pit_add_mnl_amt_y3     6771 non-null   float64\n",
      " 362  pit_add_ech_amt_m3     6771 non-null   float64\n",
      " 363  pit_add_ech_amt_m6     6771 non-null   float64\n",
      " 364  pit_add_ech_amt_y1     6771 non-null   float64\n",
      " 365  pit_add_ech_amt_y2     6771 non-null   float64\n",
      " 366  pit_add_ech_amt_y3     6771 non-null   float64\n",
      " 367  pit_add_oth_amt_m3     6771 non-null   float64\n",
      " 368  pit_add_oth_amt_m6     6771 non-null   float64\n",
      " 369  pit_add_oth_amt_y1     6771 non-null   float64\n",
      " 370  pit_add_oth_amt_y2     6771 non-null   float64\n",
      " 371  pit_add_oth_amt_y3     6771 non-null   float64\n",
      " 372  pit_des_tkt_amt_m3     6771 non-null   float64\n",
      " 373  pit_des_tkt_amt_m6     6771 non-null   float64\n",
      " 374  pit_des_tkt_amt_y1     6771 non-null   float64\n",
      " 375  pit_des_tkt_amt_y2     6771 non-null   float64\n",
      " 376  pit_des_tkt_amt_y3     6771 non-null   float64\n",
      " 377  pit_des_bag_amt_m3     6771 non-null   float64\n",
      " 378  pit_des_bag_amt_m6     6771 non-null   float64\n",
      " 379  pit_des_bag_amt_y1     6771 non-null   float64\n",
      " 380  pit_des_bag_amt_y2     6771 non-null   float64\n",
      " 381  pit_des_bag_amt_y3     6771 non-null   float64\n",
      " 382  pit_des_upg_amt_m3     6771 non-null   float64\n",
      " 383  pit_des_upg_amt_m6     6771 non-null   float64\n",
      " 384  pit_des_upg_amt_y1     6771 non-null   float64\n",
      " 385  pit_des_upg_amt_y2     6771 non-null   float64\n",
      " 386  pit_des_upg_amt_y3     6771 non-null   float64\n",
      " 387  pit_des_mall_amt_m3    6771 non-null   float64\n",
      " 388  pit_des_mall_amt_m6    6771 non-null   float64\n",
      " 389  pit_des_mall_amt_y1    6771 non-null   float64\n",
      " 390  pit_des_mall_amt_y2    6771 non-null   float64\n",
      " 391  pit_des_mall_amt_y3    6771 non-null   float64\n",
      " 392  pit_des_selt_amt_m3    6771 non-null   float64\n",
      " 393  pit_des_selt_amt_m6    6771 non-null   float64\n",
      " 394  pit_des_selt_amt_y1    6771 non-null   float64\n",
      " 395  pit_des_selt_amt_y2    6771 non-null   float64\n",
      " 396  pit_des_selt_amt_y3    6771 non-null   float64\n",
      " 397  pit_des_out_amt_m3     6771 non-null   float64\n",
      " 398  pit_des_out_amt_m6     6771 non-null   float64\n",
      " 399  pit_des_out_amt_y1     6771 non-null   float64\n",
      " 400  pit_des_out_amt_y2     6771 non-null   float64\n",
      " 401  pit_des_out_amt_y3     6771 non-null   float64\n",
      " 402  pit_des_oth_amt_m3     6771 non-null   float64\n",
      " 403  pit_des_oth_amt_m6     6771 non-null   float64\n",
      " 404  pit_des_oth_amt_y1     6771 non-null   float64\n",
      " 405  pit_des_oth_amt_y2     6771 non-null   float64\n",
      " 406  pit_des_oth_amt_y3     6771 non-null   float64\n",
      " 407  pit_add_air_cnt_m3     6771 non-null   float64\n",
      " 408  pit_add_air_cnt_m6     6771 non-null   float64\n",
      " 409  pit_add_air_cnt_y1     6771 non-null   float64\n",
      " 410  pit_add_air_cnt_y2     6771 non-null   float64\n",
      " 411  pit_add_air_cnt_y3     6771 non-null   float64\n",
      " 412  pit_add_non_cnt_m3     6771 non-null   float64\n",
      " 413  pit_add_non_cnt_m6     6771 non-null   float64\n",
      " 414  pit_add_non_cnt_y1     6771 non-null   float64\n",
      " 415  pit_add_non_cnt_y2     6771 non-null   float64\n",
      " 416  pit_add_non_cnt_y3     6771 non-null   float64\n",
      " 417  pit_add_buy_cnt_m3     6771 non-null   float64\n",
      " 418  pit_add_buy_cnt_m6     6771 non-null   float64\n",
      " 419  pit_add_buy_cnt_y1     6771 non-null   float64\n",
      " 420  pit_add_buy_cnt_y2     6771 non-null   float64\n",
      " 421  pit_add_buy_cnt_y3     6771 non-null   float64\n",
      " 422  pit_add_mnl_cnt_m3     6771 non-null   float64\n",
      " 423  pit_add_mnl_cnt_m6     6771 non-null   float64\n",
      " 424  pit_add_mnl_cnt_y1     6771 non-null   float64\n",
      " 425  pit_add_mnl_cnt_y2     6771 non-null   float64\n",
      " 426  pit_add_mnl_cnt_y3     6771 non-null   float64\n",
      " 427  pit_add_ech_cnt_m3     6771 non-null   float64\n",
      " 428  pit_add_ech_cnt_m6     6771 non-null   float64\n",
      " 429  pit_add_ech_cnt_y1     6771 non-null   float64\n",
      " 430  pit_add_ech_cnt_y2     6771 non-null   float64\n",
      " 431  pit_add_ech_cnt_y3     6771 non-null   float64\n",
      " 432  pit_add_oth_cnt_m3     6771 non-null   float64\n",
      " 433  pit_add_oth_cnt_m6     6771 non-null   float64\n",
      " 434  pit_add_oth_cnt_y1     6771 non-null   float64\n",
      " 435  pit_add_oth_cnt_y2     6771 non-null   float64\n",
      " 436  pit_add_oth_cnt_y3     6771 non-null   float64\n",
      " 437  pit_des_tkt_cnt_m3     6771 non-null   float64\n",
      " 438  pit_des_tkt_cnt_m6     6771 non-null   float64\n",
      " 439  pit_des_tkt_cnt_y1     6771 non-null   float64\n",
      " 440  pit_des_tkt_cnt_y2     6771 non-null   float64\n",
      " 441  pit_des_tkt_cnt_y3     6771 non-null   float64\n",
      " 442  pit_des_bag_cnt_m3     6771 non-null   float64\n",
      " 443  pit_des_bag_cnt_m6     6771 non-null   float64\n",
      " 444  pit_des_bag_cnt_y1     6771 non-null   float64\n",
      " 445  pit_des_bag_cnt_y2     6771 non-null   float64\n",
      " 446  pit_des_bag_cnt_y3     6771 non-null   float64\n",
      " 447  pit_des_upg_cnt_m3     6771 non-null   float64\n",
      " 448  pit_des_upg_cnt_m6     6771 non-null   float64\n",
      " 449  pit_des_upg_cnt_y1     6771 non-null   float64\n",
      " 450  pit_des_upg_cnt_y2     6771 non-null   float64\n",
      " 451  pit_des_upg_cnt_y3     6771 non-null   float64\n",
      " 452  pit_des_mall_cnt_m3    6771 non-null   float64\n",
      " 453  pit_des_mall_cnt_m6    6771 non-null   float64\n",
      " 454  pit_des_mall_cnt_y1    6771 non-null   float64\n",
      " 455  pit_des_mall_cnt_y2    6771 non-null   float64\n",
      " 456  pit_des_mall_cnt_y3    6771 non-null   float64\n",
      " 457  pit_des_selt_cnt_m3    6771 non-null   float64\n",
      " 458  pit_des_selt_cnt_m6    6771 non-null   float64\n",
      " 459  pit_des_selt_cnt_y1    6771 non-null   float64\n",
      " 460  pit_des_selt_cnt_y2    6771 non-null   float64\n",
      " 461  pit_des_selt_cnt_y3    6771 non-null   float64\n",
      " 462  pit_des_out_cnt_m3     6771 non-null   float64\n",
      " 463  pit_des_out_cnt_m6     6771 non-null   float64\n",
      " 464  pit_des_out_cnt_y1     6771 non-null   float64\n",
      " 465  pit_des_out_cnt_y2     6771 non-null   float64\n",
      " 466  pit_des_out_cnt_y3     6771 non-null   float64\n",
      " 467  pit_des_oth_cnt_m3     6771 non-null   float64\n",
      " 468  pit_des_oth_cnt_m6     6771 non-null   float64\n",
      " 469  pit_des_oth_cnt_y1     6771 non-null   float64\n",
      " 470  pit_des_oth_cnt_y2     6771 non-null   float64\n",
      " 471  pit_des_oth_cnt_y3     6771 non-null   float64\n",
      " 472  pit_avg_amt_m3         6771 non-null   float64\n",
      " 473  pit_avg_amt_m6         6771 non-null   float64\n",
      " 474  pit_avg_amt_y1         6771 non-null   float64\n",
      " 475  pit_avg_amt_y2         6771 non-null   float64\n",
      " 476  pit_avg_amt_y3         6771 non-null   float64\n",
      " 477  pit_avg_interval_m3    6771 non-null   float64\n",
      " 478  pit_avg_interval_m6    6771 non-null   float64\n",
      " 479  pit_avg_interval_y1    6771 non-null   float64\n",
      " 480  pit_avg_interval_y2    6771 non-null   float64\n",
      " 481  pit_avg_interval_y3    6771 non-null   float64\n",
      " 482  pit_ech_avg_amt_m3     6771 non-null   float64\n",
      " 483  pit_ech_avg_amt_m6     6771 non-null   float64\n",
      " 484  pit_ech_avg_amt_y1     6771 non-null   float64\n",
      " 485  pit_ech_avg_amt_y2     6771 non-null   float64\n",
      " 486  pit_ech_avg_amt_y3     6771 non-null   float64\n",
      " 487  pit_out_avg_amt_m3     6771 non-null   float64\n",
      " 488  pit_out_avg_amt_m6     6771 non-null   float64\n",
      " 489  pit_out_avg_amt_y1     6771 non-null   float64\n",
      " 490  pit_out_avg_amt_y2     6771 non-null   float64\n",
      " 491  pit_out_avg_amt_y3     6771 non-null   float64\n",
      " 492  pit_income_cnt_m3      6771 non-null   float64\n",
      " 493  pit_income_cnt_m6      6771 non-null   float64\n",
      " 494  pit_income_cnt_y1      6771 non-null   float64\n",
      " 495  pit_income_cnt_y2      6771 non-null   float64\n",
      " 496  pit_income_cnt_y3      6771 non-null   float64\n",
      " 497  pit_pay_cnt_m3         6771 non-null   float64\n",
      " 498  pit_pay_cnt_m6         6771 non-null   float64\n",
      " 499  pit_pay_cnt_y1         6771 non-null   float64\n",
      " 500  pit_pay_cnt_y2         6771 non-null   float64\n",
      " 501  pit_pay_cnt_y3         6771 non-null   float64\n",
      " 502  pit_income_avg_amt_m3  6771 non-null   float64\n",
      " 503  pit_income_avg_amt_m6  6771 non-null   float64\n",
      " 504  pit_income_avg_amt_y1  6771 non-null   float64\n",
      " 505  pit_income_avg_amt_y2  6771 non-null   float64\n",
      " 506  pit_income_avg_amt_y3  6771 non-null   float64\n",
      " 507  pit_pay_avg_amt_m3     6771 non-null   float64\n",
      " 508  pit_pay_avg_amt_m6     6771 non-null   float64\n",
      " 509  pit_pay_avg_amt_y1     6771 non-null   float64\n",
      " 510  pax_name               6771 non-null   object \n",
      "dtypes: float64(507), int64(3), object(1)\n",
      "memory usage: 26.4+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\2654612832.py:10: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  test2.info(verbose=True,null_counts=True)\n"
     ]
    }
   ],
   "source": [
    "# 验证集原本的空值替换为数值0，保留除了object和datetime类型的之外的特征因子\n",
    "test1['seg_route_to'] = test1['seg_route_to'].map({'JFK': 1, 'LAX':2, 'SYD':3})\n",
    "test1['seg_cabin'] = test1['seg_cabin'].map({'F': 1, 'J':2, 'W':3,'Y':4,'C':5})\n",
    "test1['seg_flight'] = test1['seg_flight'].map({'AB1000':0,'AB1001': 1,'AB1002':2,'AB1003':3, 'AB1004':4, 'AB1005':5,'AB1006':6,'AB1007': 7, 'AB1008':8,'AB1009':9, 'AB1010':10,'AB1011':11,'AB1012':12,'AB1013':13, 'AB1014':14,'AB1015':15, 'AB1016':16})\n",
    "\n",
    "test2 = test1.replace(np.nan,0)\n",
    "test2 = test2.select_dtypes(exclude=['object','datetime64[ns]'])\n",
    "test2 = test2.drop(['emd_lable'],axis=1)\n",
    "test2['pax_name']=test1['pax_name']\n",
    "test2.info(verbose=True,null_counts=True)\n",
    "# data2.to_csv('trainh.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 备份处理后的测试集以及验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_route_to</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>seg_cabin</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>ffp_nbr</th>\n",
       "      <th>often_city</th>\n",
       "      <th>cabin_hf_cnt_m3</th>\n",
       "      <th>cabin_hf_cnt_m6</th>\n",
       "      <th>...</th>\n",
       "      <th>pit_income_avg_amt_m6</th>\n",
       "      <th>pit_income_avg_amt_y1</th>\n",
       "      <th>pit_income_avg_amt_y2</th>\n",
       "      <th>pit_income_avg_amt_y3</th>\n",
       "      <th>pit_pay_avg_amt_m3</th>\n",
       "      <th>pit_pay_avg_amt_m6</th>\n",
       "      <th>pit_pay_avg_amt_y1</th>\n",
       "      <th>pit_pay_avg_amt_y2</th>\n",
       "      <th>pit_pay_avg_amt_y3</th>\n",
       "      <th>pax_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4161.0</td>\n",
       "      <td>584.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9612c51f08718e48b1361e415ef55be9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>248.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>c7ca533cd9da4c4bf3d597248f90bc6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>301.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bd2cb6b0dd56fb3de6f7c018296a07e2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>454.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65657872fe131ea7651565638dcb5683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>284.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.230000e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>722261f7b860b183da9fe0b6630b6dbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23427</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>486.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ec988e914b272ad74634c52b71e84ea8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23428</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2218.0</td>\n",
       "      <td>312.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fa23535ab2ca52589303bd265ee6d382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23429</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2218.0</td>\n",
       "      <td>312.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>623d32d20af6c9752d8eef46efe95c09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23430</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2218.0</td>\n",
       "      <td>312.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dadbf45dde7347740b0294c2c0913100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23431</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>744.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d4ca366192c096cdda1be87ad0bb89b5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23432 rows × 527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_route_to  seg_flight  seg_cabin  pax_fcny  pax_tax  emd_lable2  \\\n",
       "0                 1           6        2.0    4161.0   584.43         0.0   \n",
       "1                 1           6        2.0    1670.0   248.80         0.0   \n",
       "2                 2           9        4.0     243.0   301.31         0.0   \n",
       "3                 2           9        4.0    1362.0   454.16         0.0   \n",
       "4                 1          10        4.0     675.0   284.11         1.0   \n",
       "...             ...         ...        ...       ...      ...         ...   \n",
       "23427             3           7        4.0     807.0   486.50         0.0   \n",
       "23428             3           7        2.0    2218.0   312.90         0.0   \n",
       "23429             3           7        2.0    2218.0   312.90         0.0   \n",
       "23430             3           7        2.0    2218.0   312.90         0.0   \n",
       "23431             3           7        2.0    4900.0   744.76         0.0   \n",
       "\n",
       "            ffp_nbr  often_city  cabin_hf_cnt_m3  cabin_hf_cnt_m6  ...  \\\n",
       "0      0.000000e+00         0.0              0.0              0.0  ...   \n",
       "1      0.000000e+00         0.0              0.0              0.0  ...   \n",
       "2      0.000000e+00         0.0              0.0              0.0  ...   \n",
       "3      0.000000e+00         0.0              0.0              0.0  ...   \n",
       "4      6.230000e+11         0.0              0.0              0.0  ...   \n",
       "...             ...         ...              ...              ...  ...   \n",
       "23427  0.000000e+00         0.0              0.0              0.0  ...   \n",
       "23428  0.000000e+00         0.0              0.0              0.0  ...   \n",
       "23429  0.000000e+00         0.0              0.0              0.0  ...   \n",
       "23430  0.000000e+00         0.0              0.0              0.0  ...   \n",
       "23431  0.000000e+00         0.0              0.0              0.0  ...   \n",
       "\n",
       "       pit_income_avg_amt_m6  pit_income_avg_amt_y1  pit_income_avg_amt_y2  \\\n",
       "0                        0.0                    0.0                    0.0   \n",
       "1                        0.0                    0.0                    0.0   \n",
       "2                        0.0                    0.0                    0.0   \n",
       "3                        0.0                    0.0                    0.0   \n",
       "4                        0.0                    0.0                    0.0   \n",
       "...                      ...                    ...                    ...   \n",
       "23427                    0.0                    0.0                    0.0   \n",
       "23428                    0.0                    0.0                    0.0   \n",
       "23429                    0.0                    0.0                    0.0   \n",
       "23430                    0.0                    0.0                    0.0   \n",
       "23431                    0.0                    0.0                    0.0   \n",
       "\n",
       "       pit_income_avg_amt_y3  pit_pay_avg_amt_m3  pit_pay_avg_amt_m6  \\\n",
       "0                        0.0                 0.0                 0.0   \n",
       "1                        0.0                 0.0                 0.0   \n",
       "2                        0.0                 0.0                 0.0   \n",
       "3                        0.0                 0.0                 0.0   \n",
       "4                        0.0                 0.0                 0.0   \n",
       "...                      ...                 ...                 ...   \n",
       "23427                    0.0                 0.0                 0.0   \n",
       "23428                    0.0                 0.0                 0.0   \n",
       "23429                    0.0                 0.0                 0.0   \n",
       "23430                    0.0                 0.0                 0.0   \n",
       "23431                    0.0                 0.0                 0.0   \n",
       "\n",
       "       pit_pay_avg_amt_y1  pit_pay_avg_amt_y2  pit_pay_avg_amt_y3  \\\n",
       "0                     0.0                 0.0                 0.0   \n",
       "1                     0.0                 0.0                 0.0   \n",
       "2                     0.0                 0.0                 0.0   \n",
       "3                     0.0                 0.0                 0.0   \n",
       "4                     0.0                 0.0                 0.0   \n",
       "...                   ...                 ...                 ...   \n",
       "23427                 0.0                 0.0                 0.0   \n",
       "23428                 0.0                 0.0                 0.0   \n",
       "23429                 0.0                 0.0                 0.0   \n",
       "23430                 0.0                 0.0                 0.0   \n",
       "23431                 0.0                 0.0                 0.0   \n",
       "\n",
       "                               pax_name  \n",
       "0      9612c51f08718e48b1361e415ef55be9  \n",
       "1      c7ca533cd9da4c4bf3d597248f90bc6e  \n",
       "2      bd2cb6b0dd56fb3de6f7c018296a07e2  \n",
       "3      65657872fe131ea7651565638dcb5683  \n",
       "4      722261f7b860b183da9fe0b6630b6dbf  \n",
       "...                                 ...  \n",
       "23427  ec988e914b272ad74634c52b71e84ea8  \n",
       "23428  fa23535ab2ca52589303bd265ee6d382  \n",
       "23429  623d32d20af6c9752d8eef46efe95c09  \n",
       "23430  dadbf45dde7347740b0294c2c0913100  \n",
       "23431  d4ca366192c096cdda1be87ad0bb89b5  \n",
       "\n",
       "[23432 rows x 527 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 备份处理后的测试集\n",
    "df = data2\n",
    "df1 = df\n",
    "df1.head(23432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_route_to</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>seg_cabin</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>cabin_hf_cnt_m3</th>\n",
       "      <th>cabin_hf_cnt_m6</th>\n",
       "      <th>cabin_hf_cnt_y1</th>\n",
       "      <th>cabin_hf_cnt_y2</th>\n",
       "      <th>...</th>\n",
       "      <th>pit_pay_cnt_y3</th>\n",
       "      <th>pit_income_avg_amt_m3</th>\n",
       "      <th>pit_income_avg_amt_m6</th>\n",
       "      <th>pit_income_avg_amt_y1</th>\n",
       "      <th>pit_income_avg_amt_y2</th>\n",
       "      <th>pit_income_avg_amt_y3</th>\n",
       "      <th>pit_pay_avg_amt_m3</th>\n",
       "      <th>pit_pay_avg_amt_m6</th>\n",
       "      <th>pit_pay_avg_amt_y1</th>\n",
       "      <th>pax_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>339.0</td>\n",
       "      <td>227.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4514.0</td>\n",
       "      <td>3684.0</td>\n",
       "      <td>4016.0</td>\n",
       "      <td>2210.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21f0b1c838160ac26cb2c57660bc3fd5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>255.0</td>\n",
       "      <td>250.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21e0621a85f6db6139ff7cf2d53b4e5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>479.0</td>\n",
       "      <td>411.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197b215b23a93b19f391c422eb27f310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>400.0</td>\n",
       "      <td>571.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92b435f20c6ce2fd5acef7b6ff49b6d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>500.0</td>\n",
       "      <td>279.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a38ac8bfe0feb14c0469e2917bc74a05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2707.0</td>\n",
       "      <td>509.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d6364954adcfbd58d8beebd686a9fbdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>216000.0</td>\n",
       "      <td>360100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150b405be4282907eb7e87f992856ea1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>324.0</td>\n",
       "      <td>274.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33b02fadd0d05938b8cc3dfbc735fd10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>385.0</td>\n",
       "      <td>282.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29cb3dea4ecce778096484ff2e097f5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>533.0</td>\n",
       "      <td>153.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ded3592dc9da0c1ace02ed8e361efc23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6771 rows × 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seg_route_to  seg_flight  seg_cabin  pax_fcny    pax_tax  emd_lable2  \\\n",
       "0                1          10          4     339.0     227.81         0.0   \n",
       "1                2           8          4     255.0     250.15         0.0   \n",
       "2                1          10          4     479.0     411.21         0.0   \n",
       "3                2           9          4     400.0     571.60         0.0   \n",
       "4                1           6          4     500.0     279.66         0.0   \n",
       "...            ...         ...        ...       ...        ...         ...   \n",
       "6766             2           8          2    2707.0     509.35         0.0   \n",
       "6767             2           8          4  216000.0  360100.00         0.0   \n",
       "6768             1           6          4     324.0     274.95         0.0   \n",
       "6769             1          10          4     385.0     282.23         0.0   \n",
       "6770             2           8          4     533.0     153.53         0.0   \n",
       "\n",
       "      cabin_hf_cnt_m3  cabin_hf_cnt_m6  cabin_hf_cnt_y1  cabin_hf_cnt_y2  ...  \\\n",
       "0                 0.0              0.0              0.0              0.0  ...   \n",
       "1                 0.0              0.0              0.0              0.0  ...   \n",
       "2                 0.0              0.0              0.0              0.0  ...   \n",
       "3                 0.0              0.0              0.0              0.0  ...   \n",
       "4                 0.0              0.0              0.0              0.0  ...   \n",
       "...               ...              ...              ...              ...  ...   \n",
       "6766              0.0              0.0              0.0              0.0  ...   \n",
       "6767              0.0              0.0              0.0              0.0  ...   \n",
       "6768              0.0              0.0              0.0              0.0  ...   \n",
       "6769              0.0              0.0              0.0              0.0  ...   \n",
       "6770              0.0              0.0              0.0              0.0  ...   \n",
       "\n",
       "      pit_pay_cnt_y3  pit_income_avg_amt_m3  pit_income_avg_amt_m6  \\\n",
       "0                1.0                    0.0                 4514.0   \n",
       "1                0.0                    0.0                    0.0   \n",
       "2                0.0                    0.0                    0.0   \n",
       "3                0.0                    0.0                    0.0   \n",
       "4                0.0                    0.0                    0.0   \n",
       "...              ...                    ...                    ...   \n",
       "6766             0.0                    0.0                    0.0   \n",
       "6767             0.0                    0.0                    0.0   \n",
       "6768             0.0                    0.0                    0.0   \n",
       "6769             0.0                    0.0                    0.0   \n",
       "6770             0.0                    0.0                    0.0   \n",
       "\n",
       "      pit_income_avg_amt_y1  pit_income_avg_amt_y2  pit_income_avg_amt_y3  \\\n",
       "0                    3684.0                 4016.0            2210.454545   \n",
       "1                       0.0                    0.0               0.000000   \n",
       "2                       0.0                    0.0               0.000000   \n",
       "3                       0.0                    0.0               0.000000   \n",
       "4                       0.0                    0.0               0.000000   \n",
       "...                     ...                    ...                    ...   \n",
       "6766                    0.0                    0.0               0.000000   \n",
       "6767                    0.0                    0.0               0.000000   \n",
       "6768                    0.0                    0.0               0.000000   \n",
       "6769                    0.0                    0.0               0.000000   \n",
       "6770                    0.0                    0.0               0.000000   \n",
       "\n",
       "      pit_pay_avg_amt_m3  pit_pay_avg_amt_m6  pit_pay_avg_amt_y1  \\\n",
       "0                    0.0                 0.0                 0.0   \n",
       "1                    0.0                 0.0                 0.0   \n",
       "2                    0.0                 0.0                 0.0   \n",
       "3                    0.0                 0.0                 0.0   \n",
       "4                    0.0                 0.0                 0.0   \n",
       "...                  ...                 ...                 ...   \n",
       "6766                 0.0                 0.0                 0.0   \n",
       "6767                 0.0                 0.0                 0.0   \n",
       "6768                 0.0                 0.0                 0.0   \n",
       "6769                 0.0                 0.0                 0.0   \n",
       "6770                 0.0                 0.0                 0.0   \n",
       "\n",
       "                              pax_name  \n",
       "0     21f0b1c838160ac26cb2c57660bc3fd5  \n",
       "1     21e0621a85f6db6139ff7cf2d53b4e5d  \n",
       "2     197b215b23a93b19f391c422eb27f310  \n",
       "3     92b435f20c6ce2fd5acef7b6ff49b6d0  \n",
       "4     a38ac8bfe0feb14c0469e2917bc74a05  \n",
       "...                                ...  \n",
       "6766  d6364954adcfbd58d8beebd686a9fbdc  \n",
       "6767  150b405be4282907eb7e87f992856ea1  \n",
       "6768  33b02fadd0d05938b8cc3dfbc735fd10  \n",
       "6769  29cb3dea4ecce778096484ff2e097f5b  \n",
       "6770  ded3592dc9da0c1ace02ed8e361efc23  \n",
       "\n",
       "[6771 rows x 511 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 备份处理后的验证集\n",
    "ts = test2\n",
    "ts1 = ts\n",
    "ts1.head(23432)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为了保证验证集训练集的列数相同，将训练集多于验证集的列删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.drop(df1[['ffp_nbr', 'often_city', 'cabin_c_cnt_y2', 'cabin_c_cnt_y3',\n",
    "       'prebuy_i_cnt_y3_d30', 'prebuy_i_cnt_y3_d99', 'flt_cnt_y2',\n",
    "       'flt_cnt_y3', 'flt_leg_d_cnt_y2', 'flt_leg_d_cnt_y3',\n",
    "       'rest_cnt_y2', 'rest_cnt_y3', 'tkt_avg_interval_y2',\n",
    "       'tkt_avg_interval_y3', 'pit_pay_avg_amt_y2', 'pit_pay_avg_amt_y3']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_route_to</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>seg_cabin</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>cabin_hf_cnt_m3</th>\n",
       "      <th>cabin_hf_cnt_m6</th>\n",
       "      <th>cabin_hf_cnt_y1</th>\n",
       "      <th>cabin_hf_cnt_y2</th>\n",
       "      <th>...</th>\n",
       "      <th>pit_pay_cnt_y3</th>\n",
       "      <th>pit_income_avg_amt_m3</th>\n",
       "      <th>pit_income_avg_amt_m6</th>\n",
       "      <th>pit_income_avg_amt_y1</th>\n",
       "      <th>pit_income_avg_amt_y2</th>\n",
       "      <th>pit_income_avg_amt_y3</th>\n",
       "      <th>pit_pay_avg_amt_m3</th>\n",
       "      <th>pit_pay_avg_amt_m6</th>\n",
       "      <th>pit_pay_avg_amt_y1</th>\n",
       "      <th>pax_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4161.0</td>\n",
       "      <td>584.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9612c51f08718e48b1361e415ef55be9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>248.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>c7ca533cd9da4c4bf3d597248f90bc6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>301.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bd2cb6b0dd56fb3de6f7c018296a07e2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>454.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65657872fe131ea7651565638dcb5683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>284.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>722261f7b860b183da9fe0b6630b6dbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2707.0</td>\n",
       "      <td>509.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d6364954adcfbd58d8beebd686a9fbdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>216000.0</td>\n",
       "      <td>360100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150b405be4282907eb7e87f992856ea1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>274.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33b02fadd0d05938b8cc3dfbc735fd10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>282.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29cb3dea4ecce778096484ff2e097f5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>153.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ded3592dc9da0c1ace02ed8e361efc23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30203 rows × 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seg_route_to  seg_flight  seg_cabin  pax_fcny    pax_tax  emd_lable2  \\\n",
       "0                1           6        2.0    4161.0     584.43         0.0   \n",
       "1                1           6        2.0    1670.0     248.80         0.0   \n",
       "2                2           9        4.0     243.0     301.31         0.0   \n",
       "3                2           9        4.0    1362.0     454.16         0.0   \n",
       "4                1          10        4.0     675.0     284.11         1.0   \n",
       "...            ...         ...        ...       ...        ...         ...   \n",
       "6766             2           8        2.0    2707.0     509.35         0.0   \n",
       "6767             2           8        4.0  216000.0  360100.00         0.0   \n",
       "6768             1           6        4.0     324.0     274.95         0.0   \n",
       "6769             1          10        4.0     385.0     282.23         0.0   \n",
       "6770             2           8        4.0     533.0     153.53         0.0   \n",
       "\n",
       "      cabin_hf_cnt_m3  cabin_hf_cnt_m6  cabin_hf_cnt_y1  cabin_hf_cnt_y2  ...  \\\n",
       "0                 0.0              0.0              0.0              0.0  ...   \n",
       "1                 0.0              0.0              0.0              0.0  ...   \n",
       "2                 0.0              0.0              0.0              0.0  ...   \n",
       "3                 0.0              0.0              0.0              0.0  ...   \n",
       "4                 0.0              0.0              0.0              0.0  ...   \n",
       "...               ...              ...              ...              ...  ...   \n",
       "6766              0.0              0.0              0.0              0.0  ...   \n",
       "6767              0.0              0.0              0.0              0.0  ...   \n",
       "6768              0.0              0.0              0.0              0.0  ...   \n",
       "6769              0.0              0.0              0.0              0.0  ...   \n",
       "6770              0.0              0.0              0.0              0.0  ...   \n",
       "\n",
       "      pit_pay_cnt_y3  pit_income_avg_amt_m3  pit_income_avg_amt_m6  \\\n",
       "0                0.0                    0.0                    0.0   \n",
       "1                0.0                    0.0                    0.0   \n",
       "2                0.0                    0.0                    0.0   \n",
       "3                0.0                    0.0                    0.0   \n",
       "4                0.0                    0.0                    0.0   \n",
       "...              ...                    ...                    ...   \n",
       "6766             0.0                    0.0                    0.0   \n",
       "6767             0.0                    0.0                    0.0   \n",
       "6768             0.0                    0.0                    0.0   \n",
       "6769             0.0                    0.0                    0.0   \n",
       "6770             0.0                    0.0                    0.0   \n",
       "\n",
       "      pit_income_avg_amt_y1  pit_income_avg_amt_y2  pit_income_avg_amt_y3  \\\n",
       "0                       0.0                    0.0                    0.0   \n",
       "1                       0.0                    0.0                    0.0   \n",
       "2                       0.0                    0.0                    0.0   \n",
       "3                       0.0                    0.0                    0.0   \n",
       "4                       0.0                    0.0                    0.0   \n",
       "...                     ...                    ...                    ...   \n",
       "6766                    0.0                    0.0                    0.0   \n",
       "6767                    0.0                    0.0                    0.0   \n",
       "6768                    0.0                    0.0                    0.0   \n",
       "6769                    0.0                    0.0                    0.0   \n",
       "6770                    0.0                    0.0                    0.0   \n",
       "\n",
       "      pit_pay_avg_amt_m3  pit_pay_avg_amt_m6  pit_pay_avg_amt_y1  \\\n",
       "0                    0.0                 0.0                 0.0   \n",
       "1                    0.0                 0.0                 0.0   \n",
       "2                    0.0                 0.0                 0.0   \n",
       "3                    0.0                 0.0                 0.0   \n",
       "4                    0.0                 0.0                 0.0   \n",
       "...                  ...                 ...                 ...   \n",
       "6766                 0.0                 0.0                 0.0   \n",
       "6767                 0.0                 0.0                 0.0   \n",
       "6768                 0.0                 0.0                 0.0   \n",
       "6769                 0.0                 0.0                 0.0   \n",
       "6770                 0.0                 0.0                 0.0   \n",
       "\n",
       "                              pax_name  \n",
       "0     9612c51f08718e48b1361e415ef55be9  \n",
       "1     c7ca533cd9da4c4bf3d597248f90bc6e  \n",
       "2     bd2cb6b0dd56fb3de6f7c018296a07e2  \n",
       "3     65657872fe131ea7651565638dcb5683  \n",
       "4     722261f7b860b183da9fe0b6630b6dbf  \n",
       "...                                ...  \n",
       "6766  d6364954adcfbd58d8beebd686a9fbdc  \n",
       "6767  150b405be4282907eb7e87f992856ea1  \n",
       "6768  33b02fadd0d05938b8cc3dfbc735fd10  \n",
       "6769  29cb3dea4ecce778096484ff2e097f5b  \n",
       "6770  ded3592dc9da0c1ace02ed8e361efc23  \n",
       "\n",
       "[30203 rows x 511 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=pd.concat([df1,ts1])\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对合并后的集进行缺失值填补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 缺失值填充\n",
    "pax_fcny = dt['pax_fcny'].mode()\n",
    "dt.loc[dt['pax_fcny'].isnull(),'pax_fcny']= pax_fcny[0]\n",
    "pax_tax = dt['pax_tax'].mode()\n",
    "dt.loc[dt['pax_tax'].isnull(),'pax_tax']= pax_tax[0]\n",
    "seg_cabin=dt['seg_cabin'].mode()\n",
    "dt.loc[dt['seg_cabin'].isnull(),'seg_cabin']=seg_cabin[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 异常处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dt['emd_lable2']\n",
    "X = dt\n",
    "X1 = X.drop(['emd_lable2','pax_name'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm= MinMaxScaler()\n",
    "# 对测试集和训练集的特征值进行归一化\n",
    "X2 = mm.fit_transform(X1)\n",
    "X3=  pd.DataFrame(X2,columns=X1.columns)\n",
    "# X3.to_csv('X1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 箱线图四分法异常值替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_fill(col):\n",
    "    que = col.quantile(0.75)-col.quantile(0.25)\n",
    "    \n",
    "    up_th = col.quantile(0.75) + 1.5*que\n",
    "    low_th = col.quantile(0.25) - 1.5*que\n",
    "    def box_change(x):\n",
    "        if x > up_th:\n",
    "            return up_th\n",
    "        elif x < low_th:\n",
    "            return low_th\n",
    "        else:\n",
    "            return x\n",
    "    return col.map(box_change)\n",
    "for index in X3:\n",
    "    X3[index] = box_fill(X3[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\1425414722.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X4.insert(0,'emd_lable2',labels.values)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>seg_route_to</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>seg_cabin</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>cabin_hf_cnt_m3</th>\n",
       "      <th>cabin_hf_cnt_m6</th>\n",
       "      <th>cabin_hf_cnt_y1</th>\n",
       "      <th>cabin_hf_cnt_y2</th>\n",
       "      <th>...</th>\n",
       "      <th>pit_pay_cnt_y2</th>\n",
       "      <th>pit_pay_cnt_y3</th>\n",
       "      <th>pit_income_avg_amt_m3</th>\n",
       "      <th>pit_income_avg_amt_m6</th>\n",
       "      <th>pit_income_avg_amt_y1</th>\n",
       "      <th>pit_income_avg_amt_y2</th>\n",
       "      <th>pit_income_avg_amt_y3</th>\n",
       "      <th>pit_pay_avg_amt_m3</th>\n",
       "      <th>pit_pay_avg_amt_m6</th>\n",
       "      <th>pit_pay_avg_amt_y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30202</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30203 rows × 510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emd_lable2  seg_route_to  seg_flight  seg_cabin  pax_fcny   pax_tax  \\\n",
       "0             0.0           0.0      0.3750        0.8  0.000596  0.000809   \n",
       "1             0.0           0.0      0.3750        0.8  0.000392  0.000344   \n",
       "2             0.0           0.5      0.5625        0.8  0.000057  0.000417   \n",
       "3             0.0           0.5      0.5625        0.8  0.000319  0.000629   \n",
       "4             1.0           0.0      0.6250        0.8  0.000158  0.000393   \n",
       "...           ...           ...         ...        ...       ...       ...   \n",
       "30198         0.0           0.5      0.5000        0.8  0.000596  0.000705   \n",
       "30199         0.0           0.5      0.5000        0.8  0.000596  0.001018   \n",
       "30200         0.0           0.0      0.3750        0.8  0.000076  0.000381   \n",
       "30201         0.0           0.0      0.6250        0.8  0.000090  0.000391   \n",
       "30202         0.0           0.5      0.5000        0.8  0.000125  0.000213   \n",
       "\n",
       "       cabin_hf_cnt_m3  cabin_hf_cnt_m6  cabin_hf_cnt_y1  cabin_hf_cnt_y2  \\\n",
       "0                  0.0              0.0              0.0              0.0   \n",
       "1                  0.0              0.0              0.0              0.0   \n",
       "2                  0.0              0.0              0.0              0.0   \n",
       "3                  0.0              0.0              0.0              0.0   \n",
       "4                  0.0              0.0              0.0              0.0   \n",
       "...                ...              ...              ...              ...   \n",
       "30198              0.0              0.0              0.0              0.0   \n",
       "30199              0.0              0.0              0.0              0.0   \n",
       "30200              0.0              0.0              0.0              0.0   \n",
       "30201              0.0              0.0              0.0              0.0   \n",
       "30202              0.0              0.0              0.0              0.0   \n",
       "\n",
       "       ...  pit_pay_cnt_y2  pit_pay_cnt_y3  pit_income_avg_amt_m3  \\\n",
       "0      ...             0.0             0.0                    0.0   \n",
       "1      ...             0.0             0.0                    0.0   \n",
       "2      ...             0.0             0.0                    0.0   \n",
       "3      ...             0.0             0.0                    0.0   \n",
       "4      ...             0.0             0.0                    0.0   \n",
       "...    ...             ...             ...                    ...   \n",
       "30198  ...             0.0             0.0                    0.0   \n",
       "30199  ...             0.0             0.0                    0.0   \n",
       "30200  ...             0.0             0.0                    0.0   \n",
       "30201  ...             0.0             0.0                    0.0   \n",
       "30202  ...             0.0             0.0                    0.0   \n",
       "\n",
       "       pit_income_avg_amt_m6  pit_income_avg_amt_y1  pit_income_avg_amt_y2  \\\n",
       "0                        0.0                    0.0                    0.0   \n",
       "1                        0.0                    0.0                    0.0   \n",
       "2                        0.0                    0.0                    0.0   \n",
       "3                        0.0                    0.0                    0.0   \n",
       "4                        0.0                    0.0                    0.0   \n",
       "...                      ...                    ...                    ...   \n",
       "30198                    0.0                    0.0                    0.0   \n",
       "30199                    0.0                    0.0                    0.0   \n",
       "30200                    0.0                    0.0                    0.0   \n",
       "30201                    0.0                    0.0                    0.0   \n",
       "30202                    0.0                    0.0                    0.0   \n",
       "\n",
       "       pit_income_avg_amt_y3  pit_pay_avg_amt_m3  pit_pay_avg_amt_m6  \\\n",
       "0                        0.0                 0.0                 0.0   \n",
       "1                        0.0                 0.0                 0.0   \n",
       "2                        0.0                 0.0                 0.0   \n",
       "3                        0.0                 0.0                 0.0   \n",
       "4                        0.0                 0.0                 0.0   \n",
       "...                      ...                 ...                 ...   \n",
       "30198                    0.0                 0.0                 0.0   \n",
       "30199                    0.0                 0.0                 0.0   \n",
       "30200                    0.0                 0.0                 0.0   \n",
       "30201                    0.0                 0.0                 0.0   \n",
       "30202                    0.0                 0.0                 0.0   \n",
       "\n",
       "       pit_pay_avg_amt_y1  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  \n",
       "...                   ...  \n",
       "30198                 0.0  \n",
       "30199                 0.0  \n",
       "30200                 0.0  \n",
       "30201                 0.0  \n",
       "30202                 0.0  \n",
       "\n",
       "[30203 rows x 510 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4 = pd.DataFrame(X3,columns=X1.columns)\n",
    "X4.insert(0,'emd_lable2',labels.values)\n",
    "X4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆分训练集以及验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>seg_route_to</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>seg_cabin</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>cabin_hf_cnt_m3</th>\n",
       "      <th>cabin_hf_cnt_m6</th>\n",
       "      <th>cabin_hf_cnt_y1</th>\n",
       "      <th>cabin_hf_cnt_y2</th>\n",
       "      <th>...</th>\n",
       "      <th>pit_pay_cnt_y2</th>\n",
       "      <th>pit_pay_cnt_y3</th>\n",
       "      <th>pit_income_avg_amt_m3</th>\n",
       "      <th>pit_income_avg_amt_m6</th>\n",
       "      <th>pit_income_avg_amt_y1</th>\n",
       "      <th>pit_income_avg_amt_y2</th>\n",
       "      <th>pit_income_avg_amt_y3</th>\n",
       "      <th>pit_pay_avg_amt_m3</th>\n",
       "      <th>pit_pay_avg_amt_m6</th>\n",
       "      <th>pit_pay_avg_amt_y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23429</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23430</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23432 rows × 510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emd_lable2  seg_route_to  seg_flight  seg_cabin  pax_fcny   pax_tax  \\\n",
       "0             0.0           0.0      0.3750        0.8  0.000596  0.000809   \n",
       "1             0.0           0.0      0.3750        0.8  0.000392  0.000344   \n",
       "2             0.0           0.5      0.5625        0.8  0.000057  0.000417   \n",
       "3             0.0           0.5      0.5625        0.8  0.000319  0.000629   \n",
       "4             1.0           0.0      0.6250        0.8  0.000158  0.000393   \n",
       "...           ...           ...         ...        ...       ...       ...   \n",
       "23427         0.0           1.0      0.4375        0.8  0.000189  0.000674   \n",
       "23428         0.0           1.0      0.4375        0.8  0.000520  0.000433   \n",
       "23429         0.0           1.0      0.4375        0.8  0.000520  0.000433   \n",
       "23430         0.0           1.0      0.4375        0.8  0.000520  0.000433   \n",
       "23431         0.0           1.0      0.4375        0.8  0.000596  0.001018   \n",
       "\n",
       "       cabin_hf_cnt_m3  cabin_hf_cnt_m6  cabin_hf_cnt_y1  cabin_hf_cnt_y2  \\\n",
       "0                  0.0              0.0              0.0              0.0   \n",
       "1                  0.0              0.0              0.0              0.0   \n",
       "2                  0.0              0.0              0.0              0.0   \n",
       "3                  0.0              0.0              0.0              0.0   \n",
       "4                  0.0              0.0              0.0              0.0   \n",
       "...                ...              ...              ...              ...   \n",
       "23427              0.0              0.0              0.0              0.0   \n",
       "23428              0.0              0.0              0.0              0.0   \n",
       "23429              0.0              0.0              0.0              0.0   \n",
       "23430              0.0              0.0              0.0              0.0   \n",
       "23431              0.0              0.0              0.0              0.0   \n",
       "\n",
       "       ...  pit_pay_cnt_y2  pit_pay_cnt_y3  pit_income_avg_amt_m3  \\\n",
       "0      ...             0.0             0.0                    0.0   \n",
       "1      ...             0.0             0.0                    0.0   \n",
       "2      ...             0.0             0.0                    0.0   \n",
       "3      ...             0.0             0.0                    0.0   \n",
       "4      ...             0.0             0.0                    0.0   \n",
       "...    ...             ...             ...                    ...   \n",
       "23427  ...             0.0             0.0                    0.0   \n",
       "23428  ...             0.0             0.0                    0.0   \n",
       "23429  ...             0.0             0.0                    0.0   \n",
       "23430  ...             0.0             0.0                    0.0   \n",
       "23431  ...             0.0             0.0                    0.0   \n",
       "\n",
       "       pit_income_avg_amt_m6  pit_income_avg_amt_y1  pit_income_avg_amt_y2  \\\n",
       "0                        0.0                    0.0                    0.0   \n",
       "1                        0.0                    0.0                    0.0   \n",
       "2                        0.0                    0.0                    0.0   \n",
       "3                        0.0                    0.0                    0.0   \n",
       "4                        0.0                    0.0                    0.0   \n",
       "...                      ...                    ...                    ...   \n",
       "23427                    0.0                    0.0                    0.0   \n",
       "23428                    0.0                    0.0                    0.0   \n",
       "23429                    0.0                    0.0                    0.0   \n",
       "23430                    0.0                    0.0                    0.0   \n",
       "23431                    0.0                    0.0                    0.0   \n",
       "\n",
       "       pit_income_avg_amt_y3  pit_pay_avg_amt_m3  pit_pay_avg_amt_m6  \\\n",
       "0                        0.0                 0.0                 0.0   \n",
       "1                        0.0                 0.0                 0.0   \n",
       "2                        0.0                 0.0                 0.0   \n",
       "3                        0.0                 0.0                 0.0   \n",
       "4                        0.0                 0.0                 0.0   \n",
       "...                      ...                 ...                 ...   \n",
       "23427                    0.0                 0.0                 0.0   \n",
       "23428                    0.0                 0.0                 0.0   \n",
       "23429                    0.0                 0.0                 0.0   \n",
       "23430                    0.0                 0.0                 0.0   \n",
       "23431                    0.0                 0.0                 0.0   \n",
       "\n",
       "       pit_pay_avg_amt_y1  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  \n",
       "...                   ...  \n",
       "23427                 0.0  \n",
       "23428                 0.0  \n",
       "23429                 0.0  \n",
       "23430                 0.0  \n",
       "23431                 0.0  \n",
       "\n",
       "[23432 rows x 510 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=X4.loc[:23431]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>seg_route_to</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>seg_cabin</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>cabin_hf_cnt_m3</th>\n",
       "      <th>cabin_hf_cnt_m6</th>\n",
       "      <th>cabin_hf_cnt_y1</th>\n",
       "      <th>cabin_hf_cnt_y2</th>\n",
       "      <th>...</th>\n",
       "      <th>pit_pay_cnt_y2</th>\n",
       "      <th>pit_pay_cnt_y3</th>\n",
       "      <th>pit_income_avg_amt_m3</th>\n",
       "      <th>pit_income_avg_amt_m6</th>\n",
       "      <th>pit_income_avg_amt_y1</th>\n",
       "      <th>pit_income_avg_amt_y2</th>\n",
       "      <th>pit_income_avg_amt_y3</th>\n",
       "      <th>pit_pay_avg_amt_m3</th>\n",
       "      <th>pit_pay_avg_amt_m6</th>\n",
       "      <th>pit_pay_avg_amt_y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6771 rows × 510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emd_lable2  seg_route_to  seg_flight  seg_cabin  pax_fcny   pax_tax  \\\n",
       "0            0.0           0.0      0.6250        0.8  0.000079  0.000315   \n",
       "1            0.0           0.5      0.5000        0.8  0.000060  0.000346   \n",
       "2            0.0           0.0      0.6250        0.8  0.000112  0.000569   \n",
       "3            0.0           0.5      0.5625        0.8  0.000094  0.000791   \n",
       "4            0.0           0.0      0.3750        0.8  0.000117  0.000387   \n",
       "...          ...           ...         ...        ...       ...       ...   \n",
       "6766         0.0           0.5      0.5000        0.8  0.000596  0.000705   \n",
       "6767         0.0           0.5      0.5000        0.8  0.000596  0.001018   \n",
       "6768         0.0           0.0      0.3750        0.8  0.000076  0.000381   \n",
       "6769         0.0           0.0      0.6250        0.8  0.000090  0.000391   \n",
       "6770         0.0           0.5      0.5000        0.8  0.000125  0.000213   \n",
       "\n",
       "      cabin_hf_cnt_m3  cabin_hf_cnt_m6  cabin_hf_cnt_y1  cabin_hf_cnt_y2  ...  \\\n",
       "0                 0.0              0.0              0.0              0.0  ...   \n",
       "1                 0.0              0.0              0.0              0.0  ...   \n",
       "2                 0.0              0.0              0.0              0.0  ...   \n",
       "3                 0.0              0.0              0.0              0.0  ...   \n",
       "4                 0.0              0.0              0.0              0.0  ...   \n",
       "...               ...              ...              ...              ...  ...   \n",
       "6766              0.0              0.0              0.0              0.0  ...   \n",
       "6767              0.0              0.0              0.0              0.0  ...   \n",
       "6768              0.0              0.0              0.0              0.0  ...   \n",
       "6769              0.0              0.0              0.0              0.0  ...   \n",
       "6770              0.0              0.0              0.0              0.0  ...   \n",
       "\n",
       "      pit_pay_cnt_y2  pit_pay_cnt_y3  pit_income_avg_amt_m3  \\\n",
       "0                0.0             0.0                    0.0   \n",
       "1                0.0             0.0                    0.0   \n",
       "2                0.0             0.0                    0.0   \n",
       "3                0.0             0.0                    0.0   \n",
       "4                0.0             0.0                    0.0   \n",
       "...              ...             ...                    ...   \n",
       "6766             0.0             0.0                    0.0   \n",
       "6767             0.0             0.0                    0.0   \n",
       "6768             0.0             0.0                    0.0   \n",
       "6769             0.0             0.0                    0.0   \n",
       "6770             0.0             0.0                    0.0   \n",
       "\n",
       "      pit_income_avg_amt_m6  pit_income_avg_amt_y1  pit_income_avg_amt_y2  \\\n",
       "0                       0.0                    0.0                    0.0   \n",
       "1                       0.0                    0.0                    0.0   \n",
       "2                       0.0                    0.0                    0.0   \n",
       "3                       0.0                    0.0                    0.0   \n",
       "4                       0.0                    0.0                    0.0   \n",
       "...                     ...                    ...                    ...   \n",
       "6766                    0.0                    0.0                    0.0   \n",
       "6767                    0.0                    0.0                    0.0   \n",
       "6768                    0.0                    0.0                    0.0   \n",
       "6769                    0.0                    0.0                    0.0   \n",
       "6770                    0.0                    0.0                    0.0   \n",
       "\n",
       "      pit_income_avg_amt_y3  pit_pay_avg_amt_m3  pit_pay_avg_amt_m6  \\\n",
       "0                       0.0                 0.0                 0.0   \n",
       "1                       0.0                 0.0                 0.0   \n",
       "2                       0.0                 0.0                 0.0   \n",
       "3                       0.0                 0.0                 0.0   \n",
       "4                       0.0                 0.0                 0.0   \n",
       "...                     ...                 ...                 ...   \n",
       "6766                    0.0                 0.0                 0.0   \n",
       "6767                    0.0                 0.0                 0.0   \n",
       "6768                    0.0                 0.0                 0.0   \n",
       "6769                    0.0                 0.0                 0.0   \n",
       "6770                    0.0                 0.0                 0.0   \n",
       "\n",
       "      pit_pay_avg_amt_y1  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "...                  ...  \n",
       "6766                 0.0  \n",
       "6767                 0.0  \n",
       "6768                 0.0  \n",
       "6769                 0.0  \n",
       "6770                 0.0  \n",
       "\n",
       "[6771 rows x 510 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1=X4.loc[23432:]\n",
    "ts1=ts1.reset_index(drop = True)\n",
    "ts1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过采样处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1['emd_lable2']\n",
    "x = df1\n",
    "x = x.drop(['emd_lable2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 21957), (1.0, 21957)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(x, y)\n",
    "sorted(Counter(y_resampled).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\399592528.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  gc['emd_lable2']=y_resampled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_route_to</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>seg_cabin</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>cabin_hf_cnt_m3</th>\n",
       "      <th>cabin_hf_cnt_m6</th>\n",
       "      <th>cabin_hf_cnt_y1</th>\n",
       "      <th>cabin_hf_cnt_y2</th>\n",
       "      <th>cabin_hf_cnt_y3</th>\n",
       "      <th>...</th>\n",
       "      <th>pit_pay_cnt_y3</th>\n",
       "      <th>pit_income_avg_amt_m3</th>\n",
       "      <th>pit_income_avg_amt_m6</th>\n",
       "      <th>pit_income_avg_amt_y1</th>\n",
       "      <th>pit_income_avg_amt_y2</th>\n",
       "      <th>pit_income_avg_amt_y3</th>\n",
       "      <th>pit_pay_avg_amt_m3</th>\n",
       "      <th>pit_pay_avg_amt_m6</th>\n",
       "      <th>pit_pay_avg_amt_y1</th>\n",
       "      <th>emd_lable2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43909</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43910</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43911</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43912</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43913</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43914 rows × 510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_route_to  seg_flight  seg_cabin  pax_fcny   pax_tax  \\\n",
       "0               0.0      0.3750        0.8  0.000596  0.000809   \n",
       "1               0.0      0.3750        0.8  0.000392  0.000344   \n",
       "2               0.5      0.5625        0.8  0.000057  0.000417   \n",
       "3               0.5      0.5625        0.8  0.000319  0.000629   \n",
       "4               0.0      0.6250        0.8  0.000158  0.000393   \n",
       "...             ...         ...        ...       ...       ...   \n",
       "43909           0.0      0.6250        0.8  0.000098  0.000415   \n",
       "43910           0.0      0.6250        0.8  0.000166  0.000628   \n",
       "43911           0.5      0.5000        0.8  0.000040  0.000365   \n",
       "43912           0.0      0.3750        0.8  0.000178  0.000629   \n",
       "43913           0.0      0.3750        0.8  0.000315  0.000317   \n",
       "\n",
       "       cabin_hf_cnt_m3  cabin_hf_cnt_m6  cabin_hf_cnt_y1  cabin_hf_cnt_y2  \\\n",
       "0                  0.0              0.0              0.0              0.0   \n",
       "1                  0.0              0.0              0.0              0.0   \n",
       "2                  0.0              0.0              0.0              0.0   \n",
       "3                  0.0              0.0              0.0              0.0   \n",
       "4                  0.0              0.0              0.0              0.0   \n",
       "...                ...              ...              ...              ...   \n",
       "43909              0.0              0.0              0.0              0.0   \n",
       "43910              0.0              0.0              0.0              0.0   \n",
       "43911              0.0              0.0              0.0              0.0   \n",
       "43912              0.0              0.0              0.0              0.0   \n",
       "43913              0.0              0.0              0.0              0.0   \n",
       "\n",
       "       cabin_hf_cnt_y3  ...  pit_pay_cnt_y3  pit_income_avg_amt_m3  \\\n",
       "0                  0.0  ...             0.0                    0.0   \n",
       "1                  0.0  ...             0.0                    0.0   \n",
       "2                  0.0  ...             0.0                    0.0   \n",
       "3                  0.0  ...             0.0                    0.0   \n",
       "4                  0.0  ...             0.0                    0.0   \n",
       "...                ...  ...             ...                    ...   \n",
       "43909              0.0  ...             0.0                    0.0   \n",
       "43910              0.0  ...             0.0                    0.0   \n",
       "43911              0.0  ...             0.0                    0.0   \n",
       "43912              0.0  ...             0.0                    0.0   \n",
       "43913              0.0  ...             0.0                    0.0   \n",
       "\n",
       "       pit_income_avg_amt_m6  pit_income_avg_amt_y1  pit_income_avg_amt_y2  \\\n",
       "0                        0.0                    0.0                    0.0   \n",
       "1                        0.0                    0.0                    0.0   \n",
       "2                        0.0                    0.0                    0.0   \n",
       "3                        0.0                    0.0                    0.0   \n",
       "4                        0.0                    0.0                    0.0   \n",
       "...                      ...                    ...                    ...   \n",
       "43909                    0.0                    0.0                    0.0   \n",
       "43910                    0.0                    0.0                    0.0   \n",
       "43911                    0.0                    0.0                    0.0   \n",
       "43912                    0.0                    0.0                    0.0   \n",
       "43913                    0.0                    0.0                    0.0   \n",
       "\n",
       "       pit_income_avg_amt_y3  pit_pay_avg_amt_m3  pit_pay_avg_amt_m6  \\\n",
       "0                        0.0                 0.0                 0.0   \n",
       "1                        0.0                 0.0                 0.0   \n",
       "2                        0.0                 0.0                 0.0   \n",
       "3                        0.0                 0.0                 0.0   \n",
       "4                        0.0                 0.0                 0.0   \n",
       "...                      ...                 ...                 ...   \n",
       "43909                    0.0                 0.0                 0.0   \n",
       "43910                    0.0                 0.0                 0.0   \n",
       "43911                    0.0                 0.0                 0.0   \n",
       "43912                    0.0                 0.0                 0.0   \n",
       "43913                    0.0                 0.0                 0.0   \n",
       "\n",
       "       pit_pay_avg_amt_y1  emd_lable2  \n",
       "0                     0.0         0.0  \n",
       "1                     0.0         0.0  \n",
       "2                     0.0         0.0  \n",
       "3                     0.0         0.0  \n",
       "4                     0.0         1.0  \n",
       "...                   ...         ...  \n",
       "43909                 0.0         1.0  \n",
       "43910                 0.0         1.0  \n",
       "43911                 0.0         1.0  \n",
       "43912                 0.0         1.0  \n",
       "43913                 0.0         1.0  \n",
       "\n",
       "[43914 rows x 510 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc=X_resampled\n",
    "gc['emd_lable2']=y_resampled\n",
    "gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行模型训练，筛选出对目标列比较有影响的数据列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =gc['emd_lable2']\n",
    "x = gc\n",
    "x = x.drop(['emd_lable2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.71463\n",
      "[1]\ttrain-auc:0.71577\n",
      "[2]\ttrain-auc:0.74497\n",
      "[3]\ttrain-auc:0.74952\n",
      "[4]\ttrain-auc:0.75141\n",
      "[5]\ttrain-auc:0.75482\n",
      "[6]\ttrain-auc:0.75541\n",
      "[7]\ttrain-auc:0.75431\n",
      "[8]\ttrain-auc:0.75693\n",
      "[9]\ttrain-auc:0.75795\n",
      "[10]\ttrain-auc:0.75691\n",
      "[11]\ttrain-auc:0.75673\n",
      "[12]\ttrain-auc:0.75678\n",
      "[13]\ttrain-auc:0.75802\n",
      "[14]\ttrain-auc:0.75802\n",
      "[15]\ttrain-auc:0.75835\n",
      "[16]\ttrain-auc:0.76074\n",
      "[17]\ttrain-auc:0.76002\n",
      "[18]\ttrain-auc:0.75954\n",
      "[19]\ttrain-auc:0.75956\n",
      "[20]\ttrain-auc:0.76032\n",
      "[21]\ttrain-auc:0.76103\n",
      "[22]\ttrain-auc:0.76146\n",
      "[23]\ttrain-auc:0.76264\n",
      "[24]\ttrain-auc:0.76262\n",
      "[25]\ttrain-auc:0.76250\n",
      "[26]\ttrain-auc:0.76312\n",
      "[27]\ttrain-auc:0.76323\n",
      "[28]\ttrain-auc:0.76431\n",
      "[29]\ttrain-auc:0.76467\n",
      "[30]\ttrain-auc:0.76490\n",
      "[31]\ttrain-auc:0.76580\n",
      "[32]\ttrain-auc:0.76559\n",
      "[33]\ttrain-auc:0.76531\n",
      "[34]\ttrain-auc:0.76548\n",
      "[35]\ttrain-auc:0.76552\n",
      "[36]\ttrain-auc:0.76608\n",
      "[37]\ttrain-auc:0.76592\n",
      "[38]\ttrain-auc:0.76598\n",
      "[39]\ttrain-auc:0.76618\n",
      "[40]\ttrain-auc:0.76610\n",
      "[41]\ttrain-auc:0.76604\n",
      "[42]\ttrain-auc:0.76571\n",
      "[43]\ttrain-auc:0.76620\n",
      "[44]\ttrain-auc:0.76695\n",
      "[45]\ttrain-auc:0.76719\n",
      "[46]\ttrain-auc:0.76732\n",
      "[47]\ttrain-auc:0.76735\n",
      "[48]\ttrain-auc:0.76704\n",
      "[49]\ttrain-auc:0.76722\n",
      "Precesion: 0.6506\n",
      "Recall: 0.8182\n",
      "F1-score: 0.7248\n",
      "Accuracy: 0.6916\n",
      "AUC: 0.7655\n",
      "测试集每个样本的得分\n",
      " [0.52984726 0.52984726 0.51310325 ... 0.5179212  0.5173812  0.3871667 ]\n",
      "测试集每棵树所属的节点数\n",
      " [[25. 25. 35. ... 36. 27. 30.]\n",
      " [25. 25. 35. ... 36. 27. 30.]\n",
      " [26. 26. 31. ... 30. 28. 18.]\n",
      " ...\n",
      " [25. 25. 31. ... 36. 27. 29.]\n",
      " [25. 25. 31. ... 36. 27. 29.]\n",
      " [35. 35. 11. ... 45. 42. 11.]]\n",
      "特征的重要性\n",
      " [[0.0136334  0.02872669 0.         ... 0.         0.         0.00479232]\n",
      " [0.0138292  0.02802103 0.         ... 0.         0.         0.00479232]\n",
      " [0.05849835 0.05226862 0.         ... 0.         0.         0.00479232]\n",
      " ...\n",
      " [0.0285146  0.04067595 0.         ... 0.         0.         0.00479232]\n",
      " [0.02862707 0.03746989 0.         ... 0.         0.         0.00479232]\n",
      " [0.00484158 0.01310175 0.         ... 0.         0.         0.00479232]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Arial Unicode MS'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['Arial Unicode MS'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "# XGBoost训练过程\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,train_test_split,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error,roc_auc_score\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# xgboost模型初始化设置\n",
    "dtrain=xgb.DMatrix(X_train,label=y_train)\n",
    "dtest=xgb.DMatrix(X_test)\n",
    "watchlist = [(dtrain,'train')]\n",
    "\n",
    "# booster:\n",
    "params={'booster':'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'max_depth':5,\n",
    "        'lambda':10,\n",
    "        'subsample':0.75,\n",
    "        'colsample_bytree':0.75,\n",
    "        'min_child_weight':2,\n",
    "        'eta': 0.025,\n",
    "        'seed':0,\n",
    "        'nthread':8,\n",
    "        'gamma':0.15,\n",
    "        'learning_rate' : 0.01}\n",
    "\n",
    "# 建模与预测：50棵树\n",
    "bst=xgb.train(params,dtrain,num_boost_round=50,evals=watchlist)\n",
    "ypred=bst.predict(dtest)\n",
    " \n",
    "# 设置阈值、评价指标\n",
    "y_pred = (ypred >= 0.5)*1\n",
    "print ('Precesion: %.4f' %metrics.precision_score(y_test,y_pred))\n",
    "print ('Recall: %.4f' % metrics.recall_score(y_test,y_pred))\n",
    "print ('F1-score: %.4f' %metrics.f1_score(y_test,y_pred))\n",
    "print ('Accuracy: %.4f' % metrics.accuracy_score(y_test,y_pred))\n",
    "print ('AUC: %.4f' % metrics.roc_auc_score(y_test,ypred))\n",
    "\n",
    "ypred = bst.predict(dtest)\n",
    "print(\"测试集每个样本的得分\\n\",ypred)\n",
    "ypred_leaf = bst.predict(dtest, pred_leaf=True)\n",
    "print(\"测试集每棵树所属的节点数\\n\",ypred_leaf)\n",
    "ypred_contribs = bst.predict(dtest, pred_contribs=True)\n",
    "print(\"特征的重要性\\n\",ypred_contribs )\n",
    "\n",
    "xgb.plot_importance(bst,height=0.7,title='Feature importance', ylabel='features',xlabel='weight')\n",
    "plt.rc('font', family='Arial Unicode MS', size=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将训练集以及验证集的重要特征选取出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>avg_dist_cnt_y3</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>tkt_3y_amt</th>\n",
       "      <th>dist_cnt_y3</th>\n",
       "      <th>seat_walkway_cnt_y3</th>\n",
       "      <th>dist_i_cnt_y3</th>\n",
       "      <th>pref_month_y3_1</th>\n",
       "      <th>tkt_i_amt_y3</th>\n",
       "      <th>emd_lable2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.347172</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.754508</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43909</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.411954</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43910</th>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.700813</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>0.057040</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43911</th>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43912</th>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>0.075018</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.075018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43913</th>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.821526</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43914 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pax_tax  pax_fcny  avg_dist_cnt_y3  seg_flight  tkt_3y_amt  \\\n",
       "0      0.000809  0.000596         0.000000      0.3750    0.001236   \n",
       "1      0.000344  0.000392         0.347172      0.3750    0.001236   \n",
       "2      0.000417  0.000057         0.000000      0.5625    0.001236   \n",
       "3      0.000629  0.000319         0.754508      0.5625    0.007383   \n",
       "4      0.000393  0.000158         0.000000      0.6250    0.007466   \n",
       "...         ...       ...              ...         ...         ...   \n",
       "43909  0.000415  0.000098         0.411954      0.6250    0.001236   \n",
       "43910  0.000628  0.000166         0.700813      0.6250    0.008580   \n",
       "43911  0.000365  0.000040         0.000000      0.5000    0.001236   \n",
       "43912  0.000629  0.000178         0.000000      0.3750    0.008580   \n",
       "43913  0.000317  0.000315         0.821526      0.3750    0.001236   \n",
       "\n",
       "       dist_cnt_y3  seat_walkway_cnt_y3  dist_i_cnt_y3  pref_month_y3_1  \\\n",
       "0         0.000000             0.000000       0.000000         0.000000   \n",
       "1         0.000000             0.000000       0.000000         0.166667   \n",
       "2         0.000000             0.000000       0.000000         0.000000   \n",
       "3         0.030705             0.006993       0.030705         0.625000   \n",
       "4         0.040664             0.017483       0.040664         0.000000   \n",
       "...            ...                  ...            ...              ...   \n",
       "43909     0.000000             0.000000       0.000000         0.625000   \n",
       "43910     0.057040             0.006993       0.055707         0.625000   \n",
       "43911     0.000000             0.000000       0.000000         0.000000   \n",
       "43912     0.075018             0.006993       0.075018         0.000000   \n",
       "43913     0.000000             0.000000       0.000000         0.625000   \n",
       "\n",
       "       tkt_i_amt_y3  emd_lable2  \n",
       "0          0.002445         0.0  \n",
       "1          0.010668         0.0  \n",
       "2          0.002445         0.0  \n",
       "3          0.010668         0.0  \n",
       "4          0.002445         1.0  \n",
       "...             ...         ...  \n",
       "43909      0.010668         1.0  \n",
       "43910      0.010668         1.0  \n",
       "43911      0.002445         1.0  \n",
       "43912      0.002445         1.0  \n",
       "43913      0.010668         1.0  \n",
       "\n",
       "[43914 rows x 11 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc=gc.loc[0:,['pax_tax','pax_fcny','avg_dist_cnt_y3','seg_flight','tkt_3y_amt','dist_cnt_y3','seat_walkway_cnt_y3','dist_i_cnt_y3','pref_month_y3_1','tkt_i_amt_y3','emd_lable2']]\n",
    "gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>avg_dist_cnt_y3</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>tkt_3y_amt</th>\n",
       "      <th>dist_cnt_y3</th>\n",
       "      <th>seat_walkway_cnt_y3</th>\n",
       "      <th>dist_i_cnt_y3</th>\n",
       "      <th>pref_month_y3_1</th>\n",
       "      <th>tkt_i_amt_y3</th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>pax_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.393975</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21f0b1c838160ac26cb2c57660bc3fd5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21e0621a85f6db6139ff7cf2d53b4e5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.609106</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197b215b23a93b19f391c422eb27f310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.04216</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>0.04216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92b435f20c6ce2fd5acef7b6ff49b6d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a38ac8bfe0feb14c0469e2917bc74a05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d6364954adcfbd58d8beebd686a9fbdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150b405be4282907eb7e87f992856ea1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33b02fadd0d05938b8cc3dfbc735fd10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29cb3dea4ecce778096484ff2e097f5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ded3592dc9da0c1ace02ed8e361efc23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6771 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pax_tax  pax_fcny  avg_dist_cnt_y3  seg_flight  tkt_3y_amt  \\\n",
       "0     0.000315  0.000079         0.393975      0.6250    0.001236   \n",
       "1     0.000346  0.000060         0.000000      0.5000    0.001236   \n",
       "2     0.000569  0.000112         0.609106      0.6250    0.001236   \n",
       "3     0.000791  0.000094         0.000000      0.5625    0.004045   \n",
       "4     0.000387  0.000117         0.000000      0.3750    0.001236   \n",
       "...        ...       ...              ...         ...         ...   \n",
       "6766  0.000705  0.000596         0.000000      0.5000    0.001236   \n",
       "6767  0.001018  0.000596         0.000000      0.5000    0.001236   \n",
       "6768  0.000381  0.000076         0.000000      0.3750    0.001236   \n",
       "6769  0.000391  0.000090         0.000000      0.6250    0.001236   \n",
       "6770  0.000213  0.000125         0.000000      0.5000    0.001236   \n",
       "\n",
       "      dist_cnt_y3  seat_walkway_cnt_y3  dist_i_cnt_y3  pref_month_y3_1  \\\n",
       "0         0.00000             0.000000        0.00000         0.416667   \n",
       "1         0.00000             0.000000        0.00000         0.000000   \n",
       "2         0.00000             0.000000        0.00000         0.625000   \n",
       "3         0.04216             0.017483        0.04216         0.000000   \n",
       "4         0.00000             0.000000        0.00000         0.000000   \n",
       "...           ...                  ...            ...              ...   \n",
       "6766      0.00000             0.000000        0.00000         0.000000   \n",
       "6767      0.00000             0.000000        0.00000         0.000000   \n",
       "6768      0.00000             0.000000        0.00000         0.000000   \n",
       "6769      0.00000             0.000000        0.00000         0.000000   \n",
       "6770      0.00000             0.000000        0.00000         0.000000   \n",
       "\n",
       "      tkt_i_amt_y3  emd_lable2                          pax_name  \n",
       "0         0.010668         0.0  21f0b1c838160ac26cb2c57660bc3fd5  \n",
       "1         0.002445         0.0  21e0621a85f6db6139ff7cf2d53b4e5d  \n",
       "2         0.004551         0.0  197b215b23a93b19f391c422eb27f310  \n",
       "3         0.002445         0.0  92b435f20c6ce2fd5acef7b6ff49b6d0  \n",
       "4         0.002445         0.0  a38ac8bfe0feb14c0469e2917bc74a05  \n",
       "...            ...         ...                               ...  \n",
       "6766      0.002445         0.0  d6364954adcfbd58d8beebd686a9fbdc  \n",
       "6767      0.002445         0.0  150b405be4282907eb7e87f992856ea1  \n",
       "6768      0.002445         0.0  33b02fadd0d05938b8cc3dfbc735fd10  \n",
       "6769      0.002445         0.0  29cb3dea4ecce778096484ff2e097f5b  \n",
       "6770      0.002445         0.0  ded3592dc9da0c1ace02ed8e361efc23  \n",
       "\n",
       "[6771 rows x 12 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1=ts1.loc[0:,['pax_tax','pax_fcny','avg_dist_cnt_y3','seg_flight','tkt_3y_amt','dist_cnt_y3','seat_walkway_cnt_y3','dist_i_cnt_y3','pref_month_y3_1','tkt_i_amt_y3']]\n",
    "ts1['emd_lable2']=ts['emd_lable2']\n",
    "ts1['pax_name']=ts['pax_name']\n",
    "ts1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看训练集和验证集的列情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43914 entries, 0 to 43913\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   pax_tax              43914 non-null  float64\n",
      " 1   pax_fcny             43914 non-null  float64\n",
      " 2   avg_dist_cnt_y3      43914 non-null  float64\n",
      " 3   seg_flight           43914 non-null  float64\n",
      " 4   tkt_3y_amt           43914 non-null  float64\n",
      " 5   dist_cnt_y3          43914 non-null  float64\n",
      " 6   seat_walkway_cnt_y3  43914 non-null  float64\n",
      " 7   dist_i_cnt_y3        43914 non-null  float64\n",
      " 8   pref_month_y3_1      43914 non-null  float64\n",
      " 9   tkt_i_amt_y3         43914 non-null  float64\n",
      " 10  emd_lable2           43914 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 3.7 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\3236422622.py:1: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  gc.info(verbose=True,null_counts=True)\n"
     ]
    }
   ],
   "source": [
    "gc.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6771 entries, 0 to 6770\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   pax_tax              6771 non-null   float64\n",
      " 1   pax_fcny             6771 non-null   float64\n",
      " 2   avg_dist_cnt_y3      6771 non-null   float64\n",
      " 3   seg_flight           6771 non-null   float64\n",
      " 4   tkt_3y_amt           6771 non-null   float64\n",
      " 5   dist_cnt_y3          6771 non-null   float64\n",
      " 6   seat_walkway_cnt_y3  6771 non-null   float64\n",
      " 7   dist_i_cnt_y3        6771 non-null   float64\n",
      " 8   pref_month_y3_1      6771 non-null   float64\n",
      " 9   tkt_i_amt_y3         6771 non-null   float64\n",
      " 10  emd_lable2           6771 non-null   float64\n",
      " 11  pax_name             6771 non-null   object \n",
      "dtypes: float64(11), object(1)\n",
      "memory usage: 634.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaokexin\\AppData\\Local\\Temp\\ipykernel_840\\3421281719.py:1: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  ts1.info(verbose=True,null_counts=True)\n"
     ]
    }
   ],
   "source": [
    "ts1.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看处理完的训练集以及验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>avg_dist_cnt_y3</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>tkt_3y_amt</th>\n",
       "      <th>dist_cnt_y3</th>\n",
       "      <th>seat_walkway_cnt_y3</th>\n",
       "      <th>dist_i_cnt_y3</th>\n",
       "      <th>pref_month_y3_1</th>\n",
       "      <th>tkt_i_amt_y3</th>\n",
       "      <th>emd_lable2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.347172</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.754508</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pax_tax  pax_fcny  avg_dist_cnt_y3  seg_flight  tkt_3y_amt  dist_cnt_y3  \\\n",
       "0  0.000809  0.000596         0.000000      0.3750    0.001236     0.000000   \n",
       "1  0.000344  0.000392         0.347172      0.3750    0.001236     0.000000   \n",
       "2  0.000417  0.000057         0.000000      0.5625    0.001236     0.000000   \n",
       "3  0.000629  0.000319         0.754508      0.5625    0.007383     0.030705   \n",
       "4  0.000393  0.000158         0.000000      0.6250    0.007466     0.040664   \n",
       "\n",
       "   seat_walkway_cnt_y3  dist_i_cnt_y3  pref_month_y3_1  tkt_i_amt_y3  \\\n",
       "0             0.000000       0.000000         0.000000      0.002445   \n",
       "1             0.000000       0.000000         0.166667      0.010668   \n",
       "2             0.000000       0.000000         0.000000      0.002445   \n",
       "3             0.006993       0.030705         0.625000      0.010668   \n",
       "4             0.017483       0.040664         0.000000      0.002445   \n",
       "\n",
       "   emd_lable2  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         1.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>avg_dist_cnt_y3</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>tkt_3y_amt</th>\n",
       "      <th>dist_cnt_y3</th>\n",
       "      <th>seat_walkway_cnt_y3</th>\n",
       "      <th>dist_i_cnt_y3</th>\n",
       "      <th>pref_month_y3_1</th>\n",
       "      <th>tkt_i_amt_y3</th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>pax_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.393975</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21f0b1c838160ac26cb2c57660bc3fd5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21e0621a85f6db6139ff7cf2d53b4e5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.609106</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197b215b23a93b19f391c422eb27f310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.04216</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>0.04216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92b435f20c6ce2fd5acef7b6ff49b6d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a38ac8bfe0feb14c0469e2917bc74a05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pax_tax  pax_fcny  avg_dist_cnt_y3  seg_flight  tkt_3y_amt  dist_cnt_y3  \\\n",
       "0  0.000315  0.000079         0.393975      0.6250    0.001236      0.00000   \n",
       "1  0.000346  0.000060         0.000000      0.5000    0.001236      0.00000   \n",
       "2  0.000569  0.000112         0.609106      0.6250    0.001236      0.00000   \n",
       "3  0.000791  0.000094         0.000000      0.5625    0.004045      0.04216   \n",
       "4  0.000387  0.000117         0.000000      0.3750    0.001236      0.00000   \n",
       "\n",
       "   seat_walkway_cnt_y3  dist_i_cnt_y3  pref_month_y3_1  tkt_i_amt_y3  \\\n",
       "0             0.000000        0.00000         0.416667      0.010668   \n",
       "1             0.000000        0.00000         0.000000      0.002445   \n",
       "2             0.000000        0.00000         0.625000      0.004551   \n",
       "3             0.017483        0.04216         0.000000      0.002445   \n",
       "4             0.000000        0.00000         0.000000      0.002445   \n",
       "\n",
       "   emd_lable2                          pax_name  \n",
       "0         0.0  21f0b1c838160ac26cb2c57660bc3fd5  \n",
       "1         0.0  21e0621a85f6db6139ff7cf2d53b4e5d  \n",
       "2         0.0  197b215b23a93b19f391c422eb27f310  \n",
       "3         0.0  92b435f20c6ce2fd5acef7b6ff49b6d0  \n",
       "4         0.0  a38ac8bfe0feb14c0469e2917bc74a05  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、 进行算法建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = gc['emd_lable2']\n",
    "X = gc\n",
    "X = X.drop(['emd_lable2'],axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost 参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:09:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[09:09:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[09:10:02] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[09:10:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[09:10:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[09:10:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[09:11:04] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[09:11:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[09:11:36] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_840\\3150708839.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_child_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolsample_btree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdac\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best score:%0.3f'\u001b[0m\u001b[1;33m%\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best parameters set:%s'\u001b[0m\u001b[1;33m%\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1469\u001b[0m                 \u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m             )\n\u001b[1;32m-> 1471\u001b[1;33m             train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0m\u001b[0;32m   1472\u001b[0m                 \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\n\u001b[0;32m    447\u001b[0m     way.\"\"\"\n\u001b[1;32m--> 448\u001b[1;33m     train_dmatrix = create_dmatrix(\n\u001b[0m\u001b[0;32m    449\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_evaluation_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainingCallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvalsLog\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    741\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[0;32m    744\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_from_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m         return _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[0m\u001b[0;32m    971\u001b[0m                                feature_names, feature_types)\n\u001b[0;32m    972\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     )\n\u001b[1;32m--> 420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_from_numpy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_from_numpy_array\u001b[1;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     _check_call(\n\u001b[1;32m--> 214\u001b[1;33m         _LIB.XGDMatrixCreateFromDense(\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[0m_array_interface\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_test={'n_estimators':np.arange(120,200,10)}\n",
    "dac=xgb.XGBClassifier(learning_rate=0.01,max_depth=5,min_child_weight=1,gamma=0.1,subsample=1.0,colsample_btree=1.0)\n",
    "gs=GridSearchCV(dac,param_grid=param_test,scoring='roc_auc',cv=5)\n",
    "gs.fit(X_train,y_train)\n",
    "print('Best score:%0.3f'% gs.best_score_)\n",
    "print('Best parameters set:%s'% gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:40:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:41:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:41:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:41:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:42:03] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:42:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:42:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:42:55] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:43:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:43:35] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:43:56] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:44:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:44:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:45:01] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:45:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:45:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:46:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:46:27] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:46:49] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:47:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:47:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:47:51] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:48:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:48:33] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:48:54] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:49:14] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:49:33] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:49:52] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:50:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:50:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:50:52] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:51:12] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:51:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:51:54] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:52:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:52:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:52:50] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:53:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:53:34] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:54:12] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:54:31] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:54:51] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:55:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:55:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:55:56] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:56:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:56:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:57:07] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:57:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:57:56] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:58:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:58:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:59:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[14:59:38] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:00:04] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:00:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:00:54] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:01:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:01:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:02:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:02:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:02:57] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:03:24] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:03:52] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:04:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:04:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:05:08] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:05:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:06:06] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:06:31] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:06:57] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:07:25] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:07:52] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:08:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:08:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:09:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:09:36] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:10:01] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:10:27] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:10:54] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:11:22] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:11:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:12:22] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:12:51] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:13:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:13:51] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:14:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:14:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:15:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:15:55] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:16:33] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:17:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:18:03] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:18:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:19:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:20:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:21:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:21:54] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:22:23] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:22:55] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:23:22] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:23:49] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:24:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:24:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:25:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:26:08] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:26:33] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:27:00] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:27:27] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:27:54] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:28:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:28:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:29:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:29:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:30:12] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:30:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:31:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:31:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:31:56] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:32:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:32:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:33:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:33:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:34:06] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:34:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:35:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:35:31] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:35:58] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:36:25] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:36:52] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:37:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:37:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:38:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:38:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:39:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:39:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:40:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:40:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n",
      "[15:41:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_btree\" } are not used.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3248\\3983747784.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmode1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m190\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolsample_btree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best score:%0.3f\"\u001b[0m\u001b[1;33m%\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters set:%s\"\u001b[0m\u001b[1;33m%\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1488\u001b[0m             )\n\u001b[0;32m   1489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1490\u001b[1;33m             self._Booster = train(\n\u001b[0m\u001b[0;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_test={'max_depth': np.arange(3,10,1),'min_child_weight': np.arange(0.1,1,0.1)}\n",
    "mode1=xgb.XGBClassifier(n_estimators=190,learning_rate=0.01,gamma=0.1,subsample=1.0,colsample_btree=1.0)\n",
    "gs=GridSearchCV(mode1,param_grid=param_test, scoring='roc_auc', cv=5)\n",
    "gs.fit(X_train,y_train)\n",
    "print(\"Best score:%0.3f\"% gs. best_score_)\n",
    "print(\"Best parameters set:%s\"% gs. best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:02:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:02:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_btree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:03:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best score:0.723\n",
      "Best parameters set:{'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "param_test={'gamma': np.arange(0.1,1.801,0.1)}\n",
    "mode1=xgb.XGBClassifier(n_estimators=190,max_depth=7, min_child_weight=0.8,learning_rate=0.01,subsample=1.0,colsample_btree=1.0)\n",
    "gs=GridSearchCV(mode1,param_grid=param_test, scoring='roc_auc', cv=5)\n",
    "gs.fit(x_train,y_train)\n",
    "print(\"Best score:%0.3f\"% gs. best_score_)\n",
    "print(\"Best parameters set:%s\"% gs. best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:04:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:04:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:04:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best score:0.725\n",
      "Best parameters set:{'colsubsample_bytree': 0.5, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "param_test={'subsample': np.arange(0.5,1,0.1), 'colsubsample_bytree': np.arange(0.5,1,0.1)}\n",
    "mode1=xgb.XGBClassifier(n_estimators=190,max_depth=7, min_child_weight=0.8,learning_rate=0.01,gamma=0.1)\n",
    "gs=GridSearchCV(mode1,param_grid=param_test, scoring='roc_auc', cv=5)\n",
    "gs.fit(x_train,y_train)\n",
    "print(\"Best score:%0.3f\"% gs.best_score_)\n",
    "print(\"Best parameters set:%s\"% gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:05:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:05:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:05:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best score:0.720\n",
      "Best parameters set:{'nthread': 1}\n"
     ]
    }
   ],
   "source": [
    "param_test={'nthread': np.arange(1,20,1)}\n",
    "mode1=xgb.XGBClassifier(max_depth=7, min_child_weight=0.8,colsubsample_bytree= 0.5, subsample=0.5,n_estimators=190,gamma=0.1)\n",
    "gs=GridSearchCV(mode1,param_grid=param_test, scoring='roc_auc', cv=5)\n",
    "gs.fit(x_train,y_train)\n",
    "print(\"Best score:%0.3f\"% gs.best_score_)\n",
    "print(\"Best parameters set:%s\"% gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsubsample_bytree, nestimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best score:0.729\n",
      "Best parameters set:{'learning_rate': 0.09000000000000001, 'nestimators': 190}\n"
     ]
    }
   ],
   "source": [
    "param_test={'learning_rate': np.arange(0.05,0.1,0.01),'nestimators': np.arange(190,300,20)}\n",
    "mode1=xgb.XGBClassifier(max_depth=7, min_child_weight=0.8,colsubsample_bytree= 0.5, subsample=0.5,gamma=0.1,nthread=1)\n",
    "gs=GridSearchCV(mode1,param_grid=param_test, scoring='roc_auc', cv=5)\n",
    "gs.fit(x_train,y_train)\n",
    "print(\"Best score:%0.3f\"% gs.best_score_)\n",
    "print(\"Best parameters set:%s\"% gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_clf = XGBClassifier(learning_rate=0.01,\n",
    "#                         n_estimators=100,         # 树的个数--1000棵树建立xgboost\n",
    "#                         max_depth=5,               # 树的深度\n",
    "#                         min_child_weight = 1,      # 叶子节点最小权重\n",
    "#                         gamma=0.,                  # 惩罚项中叶子结点个数前的参数\n",
    "#                         subsample=1.0,             # 随机选择80%样本建立决策树\n",
    "#                         colsample_btree=1.0,       # 随机选择80%特征建立决策树\n",
    "#                         objective='binary:logistic'# 指定损失函数\n",
    "#                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9698273846503132\n",
      "f1_score : 0.9703824256493909\n",
      "recall : 0.9883863438086639\n",
      "precision : 0.953036104534097\n",
      "auc_score : 0.9698272103073509\n"
     ]
    }
   ],
   "source": [
    "clf = xgb_clf = XGBClassifier(learning_rate=0.3,\n",
    "                        n_estimators=190,         # 树的个数--1000棵树建立xgboost\n",
    "                        max_depth=9,               # 树的深度\n",
    "                        min_child_weight = 0.5,      # 叶子节点最小权重\n",
    "                        gamma=0.5,                  # 惩罚项中叶子结点个数前的参数\n",
    "                        subsample=0.7,             # 随机选择80%样本建立决策树\n",
    "#                         colsample_btree=0.8,       # 随机选择80%特征建立决策树\n",
    "                        objective='binary:logistic',# 指定损失函数\n",
    "                        scale_pos_weight = 1,\n",
    "                        max_delta_step = 1,\n",
    "                       eval_metric = 'logloss'\n",
    "#                            eval_metric =   'mlogloss'\n",
    "                                                  \n",
    "                       )\n",
    "folds = 4\n",
    "skfolds = StratifiedKFold(n_splits=folds,random_state=200,shuffle=True)\n",
    "\n",
    "accuracy_count = 0.0\n",
    "precision_count = 0.0\n",
    "recall_count = 0.0\n",
    "f1_count = 0.0\n",
    "auc_count = 0.0\n",
    "\n",
    "for train_index,test_index in skfolds.split(X,labels):\n",
    "    clone_clf = clone(clf)\n",
    "    X_train_folds = X[train_index]\n",
    "    y_train_folds = labels[train_index]\n",
    "    X_test_fold = X[test_index]\n",
    "    y_test_fold = labels[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds,y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred==y_test_fold)\n",
    "    accuracy = n_correct/len(y_pred)\n",
    "    accuracy_count += accuracy\n",
    "\n",
    "    precision = precision_score(y_test_fold,y_pred)\n",
    "    precision_count += precision\n",
    "    \n",
    "    recall = recall_score(y_test_fold,y_pred)\n",
    "    recall_count += recall\n",
    "    f1score = f1_score(y_test_fold,y_pred)\n",
    "    f1_count += f1score \n",
    "    \n",
    "    aucscore = roc_auc_score(y_test_fold,y_pred)\n",
    "    auc_count += aucscore\n",
    "    \n",
    "    \n",
    "    \n",
    "#得到交叉验证后的平均结果\n",
    "print(\"accuracy : \" + str(accuracy_count/folds))\n",
    "print(\"f1_score : \"+ str(f1_count/folds))\n",
    "print(\"recall : \"+ str(recall_count/folds))\n",
    "print(\"precision : \"+ str(precision_count/folds))\n",
    "print(\"auc_score : \"+ str(auc_count/folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC曲线绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_fpr, base_tpr, _ = roc_curve(y_test_fold, [1 for _ in range(len(y_test_fold))])\n",
    "model_fpr, model_tpr, _ = roc_curve(y_test_fold, y_pred)\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "plt.legend();\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=0.5, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.3, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=1, max_depth=9,\n",
       "              max_leaves=None, min_child_weight=0.5, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=190, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内部测试后，用ts1数据实际预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3097454 , 0.13346457, 0.47956467, ..., 0.        , 0.66666667,\n",
       "        1.        ],\n",
       "       [0.34012033, 0.1003937 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55910806, 0.18858268, 0.74143282, ..., 0.        , 1.        ,\n",
       "        0.25614578],\n",
       "       ...,\n",
       "       [0.37384004, 0.12755906, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.3837384 , 0.1515748 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.20874945, 0.20984252, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = ts1.drop(['pax_name','emd_lable2'],axis=1).values\n",
    "X1 = mm.fit_transform(X1)\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2=clf.predict(X1)\n",
    "prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9926364e-01, 7.3637516e-04],\n",
       "       [5.2370459e-01, 4.7629541e-01],\n",
       "       [9.9960220e-01, 3.9780902e-04],\n",
       "       ...,\n",
       "       [3.6346495e-01, 6.3653505e-01],\n",
       "       [8.0036139e-01, 1.9963858e-01],\n",
       "       [5.2370459e-01, 4.7629541e-01]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction3=clf.predict_proba(X1)\n",
    "prediction3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_=np.array(prediction3[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将预测值和测试数据索引构造表，输出csv上传，查看成绩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pax_name</th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21f0b1c838160ac26cb2c57660bc3fd5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21e0621a85f6db6139ff7cf2d53b4e5d</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197b215b23a93b19f391c422eb27f310</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92b435f20c6ce2fd5acef7b6ff49b6d0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a38ac8bfe0feb14c0469e2917bc74a05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>d6364954adcfbd58d8beebd686a9fbdc</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>150b405be4282907eb7e87f992856ea1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>33b02fadd0d05938b8cc3dfbc735fd10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>29cb3dea4ecce778096484ff2e097f5b</td>\n",
       "      <td>0</td>\n",
       "      <td>0.199639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>ded3592dc9da0c1ace02ed8e361efc23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6771 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              pax_name  emd_lable2  probability\n",
       "0     21f0b1c838160ac26cb2c57660bc3fd5           0     0.000736\n",
       "1     21e0621a85f6db6139ff7cf2d53b4e5d           0     0.476295\n",
       "2     197b215b23a93b19f391c422eb27f310           0     0.000398\n",
       "3     92b435f20c6ce2fd5acef7b6ff49b6d0           1     0.582250\n",
       "4     a38ac8bfe0feb14c0469e2917bc74a05           1     0.636535\n",
       "...                                ...         ...          ...\n",
       "6766  d6364954adcfbd58d8beebd686a9fbdc           0     0.476295\n",
       "6767  150b405be4282907eb7e87f992856ea1           0     0.476295\n",
       "6768  33b02fadd0d05938b8cc3dfbc735fd10           1     0.636535\n",
       "6769  29cb3dea4ecce778096484ff2e097f5b           0     0.199639\n",
       "6770  ded3592dc9da0c1ace02ed8e361efc23           0     0.476295\n",
       "\n",
       "[6771 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame({'pax_name': ts1.pax_name, 'emd_lable2': prediction2,'probability':prediction_})\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emd_lable2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emd_lable2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4942</td>\n",
       "      <td>0</td>\n",
       "      <td>4942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1829</td>\n",
       "      <td>1829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4942</td>\n",
       "      <td>1829</td>\n",
       "      <td>6771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "emd_lable2     0     1   All\n",
       "emd_lable2                  \n",
       "0           4942     0  4942\n",
       "1              0  1829  1829\n",
       "All         4942  1829  6771"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclass = pd.crosstab(t.emd_lable2,t.emd_lable2,margins=True)\n",
    "pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pax_name</th>\n",
       "      <th>emd_lable2</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>bb876c4c72ed13acd160d2d12dca8d49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.742195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>e7489c6a1c3273141d9640aa7e7c8647</td>\n",
       "      <td>1</td>\n",
       "      <td>0.742195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>9193384ef490f9a93db516f631f365c0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.742195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>40e2e343afa1119500307219f6162473</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2d0664b41b077709ab04b2e557024967</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>5d765c62f2f3c2fcb6260c55822cd45b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>41e7849fd7ac9e60a5a0cfb0b3bdf9b9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>66dbc956b18c75b4fa97203a8b77436a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>4ff4768b357c43b1d9b8e1bc1f1043b1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6157</th>\n",
       "      <td>824f35db668186e157a1b299c1e703e0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              pax_name  emd_lable2  probability\n",
       "3799  bb876c4c72ed13acd160d2d12dca8d49           1     0.742195\n",
       "627   e7489c6a1c3273141d9640aa7e7c8647           1     0.742195\n",
       "4220  9193384ef490f9a93db516f631f365c0           1     0.742195\n",
       "3774  40e2e343afa1119500307219f6162473           1     0.692539\n",
       "406   2d0664b41b077709ab04b2e557024967           1     0.692539\n",
       "...                                ...         ...          ...\n",
       "6195  5d765c62f2f3c2fcb6260c55822cd45b           1     0.636535\n",
       "6190  41e7849fd7ac9e60a5a0cfb0b3bdf9b9           1     0.636535\n",
       "6183  66dbc956b18c75b4fa97203a8b77436a           1     0.636535\n",
       "6173  4ff4768b357c43b1d9b8e1bc1f1043b1           1     0.636535\n",
       "6157  824f35db668186e157a1b299c1e703e0           1     0.636535\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t[t['emd_lable2'].isin([1])]\n",
    "t = t.sort_values(by='probability',ascending=False)\n",
    "t1 = t.head(500)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导出表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
